¿Qué es la informática en la nube?
La informática en la nube es la distribución de recursos de TI bajo demanda a través de Internet mediante un esquema de pago por uso. En lugar de comprar, poseer y mantener servidores y centros de datos físicos, puede acceder a servicios tecnológicos, como capacidad informática, almacenamiento y bases de datos, en función de sus necesidades a través de un proveedor de la nube como Amazon Web Services (AWS).


Tipos de informática en la nube
Los tres tipos principales de informática en la nube son: infraestructura como servicio, plataforma como servicio y software como servicio. Cada tipo ofrece diferentes niveles de control, flexibilidad y administración para que pueda seleccionar el conjunto de servicios correcto para sus necesidades. 
Más información 

Infraestructura como servicio (IaaS)
La IaaS incluye los bloques de creación básicos para la TI basada en la nube. Generalmente, provee acceso a características de conexión en red, equipos (virtuales o en hardware exclusivo) y espacio de almacenamiento de datos. La IaaS le ofrece el mayor nivel de flexibilidad y control de administración en relación con sus recursos de TI. Es similar a los recursos de TI que muchos desarrolladores y departamentos de TI ya conocen. 


Plataforma como servicio (PaaS)
La PaaS elimina la necesidad de administrar la infraestructura subyacente (normalmente hardware y sistemas operativos) y permite enfocarse en la implementación y administración de aplicaciones. Esto contribuye a mejorar el nivel de eficiencia, ya que no debe preocuparse por el aprovisionamiento de recursos, la planificación de la capacidad, el mantenimiento del software, la implementación de parches ni ninguna de las demás arduas tareas que conlleva la ejecución de su aplicación. 


Software como servicio (SaaS)
El SaaS le proporciona un producto completo que el proveedor del servicio ejecuta y administra. En la mayoría de los casos, quienes hablan de SaaS en realidad se refieren a aplicaciones de usuario final (como el email basado en la Web). Con una solución basada en SaaS, ya no debe pensar en cómo mantener el servicio ni en cómo administrar la infraestructura subyacente. Solamente debe pensar en cómo utilizar ese software en particular. 

//

AWS
Amazon Web Services (AWS) es la plataforma en la nube más adoptada y completa en el mundo, que ofrece más de 200 servicios integrales de centros de datos a nivel global. Millones de clientes, incluso las empresas emergentes que crecen más rápido, las compañías más grandes y los organismos gubernamentales líderes, están usando AWS para reducir los costos, aumentar su agilidad e innovar de forma más rápida.

Gracias a nuestra alianza somos socios de formación de AWS. Solo los socios de formación técnica de AWS (ATP) cuentan con la confianza de AWS para ofrecer, impartir o incorporar la formación oficial de AWS.

Este contenido está disponible en Español.

Este curso está dirigido a personas que quieren obtener conocimientos generales de la nube de Amazon Web Services (AWS) incluso sin tener una formación técnica específica. Aprenderás sobre conceptos de la nube de AWS, sus servicios, la seguridad, la arquitectura, los precios y el soporte de AWS para desarrollar tus conocimientos sobre la nube. Este curso también sirve como preparación para el examen de AWS Certified Cloud Practitioner

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Resumir los beneficios de AWS.
Describir las diferencias entre la entrega bajo demanda y las implementaciones en la nube.
Resumir el modelo de precios de pago por uso.

Modelos basicos:

1) CLIENTE-SERVIDOR
-CONCEPTO CLAVE:
"SOLO PAGAS POR LO QUE USAS"

VALOR CLAVE:
-"PAGAS POR LO QUE NECESITAS"

Comencemos con un concepto clave en AWS: la noción de que solo se paga por lo que se usa.



Este principio es lógico para quien tenga una cafetería. Solo se paga a los empleados cuando están trabajando en la tienda. Las horas no laborales, Rudy y Morgan no las cobran. El propietario de la tienda decide cuántos camareros necesita y luego paga por las horas que trabajan. Por ejemplo, la cafetería va a lanzar pronto una nueva bebida: la Pumpkin Monster Spice. Previendo este lanzamiento, podría contratar y tener una docena de camareros todo el día para atender un posible aumento inesperado de clientes en algún momento. Pero lo cierto es que, durante la mayor parte del día, no hay suficientes clientes para justificar tantos salarios.

Y es precisamente eso lo que sucede en las instalaciones de los centros de datos. No podemos chasquear los dedos y triplicar la capacidad. En AWS no se paga por adelantado. Y no tienes que preocuparte por limitaciones en cuanto a la capacidad.

Cuando necesites instancias o camareros, solo hay que hacer clic en un botón y ahí están. Cuando no los necesites, haz otro clic. Desaparecerán y dejarás de pagar por ellos. Igual que no se paga a los empleados por las horas que no trabajan. 

Por lo tanto, pagar solo por lo necesario pasa a ser uno de los muchos valores clave por los que utilizar AWS en tu empresa. Y por eso estamos aquí, para ayudarte a comprender cómo AWS puede mejorar la gestión de tu negocio. 

RESUMEN:
En informática, un cliente puede ser un navegador web o una aplicación de escritorio con la que una persona interactúa para realizar peticiones a los servidores informáticos. Un servidor puede ser servicios como Amazon Elastic Cloud Compute (Amazon EC2), un tipo de servidor virtual.

Por ejemplo, supongamos que un cliente pide un artículo de noticias, la puntuación de un juego en línea o un vídeo divertido. El servidor evalúa los detalles de esta petición y corresponde a ella devolviendo la información al cliente.



//
INFORMATICA EN LA NUBE:
Antes de profundizar en los componentes de AWS, empecemos con una definición práctica de "nube". La informática en la nube es la entrega bajo demanda de recursos de TI a través de internet con precios de pago por uso. Vayamos por partes. La entrega bajo demanda quiere decir que AWS alberga solo los recursos necesarios para cuando hagan falta. No es necesario solicitarlos con antelación. Imagina que, de pronto, necesitas 300 servidores virtuales. Bastaría con un par de clics para tenerlos. O necesitas 2000 TB de almacenamiento. Tampoco hace falta solicitarlos de antemano, solo usas el almacenamiento necesario cuando lo necesitas. ¿Que ya no lo necesitas? Igual de rápido puedes devolverlo y dejar de pagar al instante. Este tipo de flexibilidad no es posible cuando administras tus propios centros de datos. 

La idea de los recursos de TI es, en realidad, una parte importante de la filosofía de AWS. A menudo nos preguntan por qué AWS tiene tantos productos y la respuesta es muy sencilla: porque las empresas los necesitan. Si distintas empresas tienen los mismos elementos de TI, entonces nada las diferencia. 

Un ejemplo sería una base de datos MySQL. Si tu empresa administra una, ¿el hecho de instalar el motor de MySQL hace que tu empresa sea mejor que los competidores? Probablemente no. ¿Guardas las copias de seguridad de manera que te hace mejor que otras empresas de tu vertical? De nuevo, probablemente no. Pero los datos de la base de datos sí que son diferentes. La forma en que creas las tablas y administras las estructuras te diferencia por completo de la competencia. Pero el motor es solo el motor.

En AWS, lo llamamos trabajo pesado intrascendente de TI. Tareas comunes, a menudo repetitivas, que requieren mucho tiempo. AWS quiere ayudarte con estas tareas para que puedas centrarte en lo que os hace únicos. En Internet parece muy sencillo, pero implica que a esos recursos se accede mediante una consola web segura o de manera programática. 

No necesitas contratos adicionales ni llamadas comerciales. Con los precios de pago por uso, destacamos de nuevo lo que hemos explicado aquí en la cafetería. Si tienes una tienda, no tienes empleados las 24 horas del día ni tantos como los que necesitas en horas punta. De hecho, en algunos periodos puede que ni los necesites. Entonces, ¿por qué pagar por entornos para desarrolladores, por ejemplo, los fines de semana, si no trabajan los fines de semana?

//
Antes de profundizar en los componentes de AWS, empecemos con una definición práctica de "nube". La informática en la nube es la entrega bajo demanda de recursos de TI a través de internet con precios de pago por uso. Vayamos por partes. La entrega bajo demanda quiere decir que AWS alberga solo los recursos necesarios para cuando hagan falta. No es necesario solicitarlos con antelación. Imagina que, de pronto, necesitas 300 servidores virtuales. Bastaría con un par de clics para tenerlos. O necesitas 2000 TB de almacenamiento. Tampoco hace falta solicitarlos de antemano, solo usas el almacenamiento necesario cuando lo necesitas. ¿Que ya no lo necesitas? Igual de rápido puedes devolverlo y dejar de pagar al instante. Este tipo de flexibilidad no es posible cuando administras tus propios centros de datos. 

La idea de los recursos de TI es, en realidad, una parte importante de la filosofía de AWS. A menudo nos preguntan por qué AWS tiene tantos productos y la respuesta es muy sencilla: porque las empresas los necesitan. Si distintas empresas tienen los mismos elementos de TI, entonces nada las diferencia. 

Un ejemplo sería una base de datos MySQL. Si tu empresa administra una, ¿el hecho de instalar el motor de MySQL hace que tu empresa sea mejor que los competidores? Probablemente no. ¿Guardas las copias de seguridad de manera que te hace mejor que otras empresas de tu vertical? De nuevo, probablemente no. Pero los datos de la base de datos sí que son diferentes. La forma en que creas las tablas y administras las estructuras te diferencia por completo de la competencia. Pero el motor es solo el motor.

En AWS, lo llamamos trabajo pesado intrascendente de TI. Tareas comunes, a menudo repetitivas, que requieren mucho tiempo. AWS quiere ayudarte con estas tareas para que puedas centrarte en lo que os hace únicos. En Internet parece muy sencillo, pero implica que a esos recursos se accede mediante una consola web segura o de manera programática. 

No necesitas contratos adicionales ni llamadas comerciales. Con los precios de pago por uso, destacamos de nuevo lo que hemos explicado aquí en la cafetería. Si tienes una tienda, no tienes empleados las 24 horas del día ni tantos como los que necesitas en horas punta. De hecho, en algunos periodos puede que ni los necesites. Entonces, ¿por qué pagar por entornos para desarrolladores, por ejemplo, los fines de semana, si no trabajan los fines de semana?

//
Modelos de implementación para informática en la nube:

Al seleccionar una estrategia para la nube, la empresa debe tener en cuenta factores como los componentes necesarios de las aplicaciones en la nube, las herramientas de gestión de recursos preferidas y los requisitos de infraestructura de TI heredados.
Los tres modelos de implementación de informática en la nube están basados en la nube, en las instalaciones o son híbridos. 
Selecciona la pestaña correspondiente a la categoría de la que desees obtener más información.

//
- BASADA EN LA NUBE

Lanza todas las partes de la aplicación en la nube.
Migra las aplicaciones existentes a la nube.
Diseña y crea nuevas aplicaciones en la nube.
En un modelo de implementación basado en la nube, puedes migrar aplicaciones existentes a la nube o diseñar y crear nuevas aplicaciones directamente allí. Puedes crearlas en una infraestructura de bajo nivel que requiera que el personal de TI las administre. Otra posibilidad es crearlas utilizando servicios de nivel superior que reduzcan los requisitos de administración, arquitectura y escalado de la infraestructura principal.

Por ejemplo, una empresa podría crear una aplicación compuesta por servidores virtuales, bases de datos y componentes de red que estén completamente basados en la nube.

-BASADA EN LAS INSTALACIONES:

Implementa recursos mediante herramientas de virtualización y administración de recursos.
Aumenta la utilización de los recursos mediante el uso de tecnologías de virtualización y administración de aplicaciones.
La implementación en las instalaciones también se conoce como implementación de nube privada. En este modelo, los recursos se implementan en las instalaciones mediante herramientas de virtualización y administración de recursos.

Por ejemplo, puede que tengas aplicaciones que se ejecutan con tecnología que se encuentra en tu centro de datos en las instalaciones. Aunque este modelo se parece mucho a la infraestructura de TI heredada, su incorporación de tecnologías de virtualización y administración de aplicaciones ayuda a aumentar la utilización de los recursos.

-IMPLEMENTACIÓN HÍBRIDA:
Conecta los recursos basados en la nube a la infraestructura en las instalaciones.
Integra recursos basados en la nube con aplicaciones de TI heredadas.
En una implementación híbrida, los recursos basados en la nube se conectan a la infraestructura en las instalaciones. Puede que desees utilizar esta estrategia en diversas situaciones. Por ejemplo, tienes aplicaciones heredadas que se mantienen mejor en las instalaciones o las regulaciones gubernamentales exigen que tu empresa mantenga ciertos registros en las instalaciones.

Por ejemplo, supongamos que una empresa quiere utilizar servicios en la nube que puedan automatizar el procesamiento y el análisis de datos por lotes. Sin embargo, tienes varias aplicaciones heredadas que es más adecuado tener en las instalaciones y no se migrarán a la nube. Con una implementación híbrida, la empresa podría mantener las aplicaciones heredadas en las instalaciones y beneficiarse de los servicios de datos y análisis que se ejecutan en la nube.

//  Beneficios de la informática en la nube:

1) PASAR DE GASTO INICIAL A GASTO VARIABLE:
Los gastos iniciales corresponden a los centros de datos, a los servidores físicos y a otros recursos en los que tendrías que invertir antes de utilizarlos. Gasto variable significa que solo se paga por los recursos informáticos que se consumen, en lugar de invertir mucho en centros de datos y servidores antes de saber cuál va a ser su uso.

Al adoptar una estrategia de informática en la nube que ofrece el beneficio del gasto variable, las empresas pueden implementar soluciones innovadoras a la vez que ahorran costes.

2) Cero inversion en mantener y operar centros de datos:
La informática en los centros de datos suele requerir que se invierta más tiempo y dinero en administrar la infraestructura y los servidores. 
Un beneficio de la informática en la nube es la capacidad de centrarse menos en estas tareas y mucho más en sus aplicaciones y clientes.

3) Sin calcular capacidades:
Con la informática en la nube, no tienes que predecir cuánta capacidad de infraestructura necesitarás antes de implementar una aplicación. 

Por ejemplo, puedes lanzar instancias de Amazon EC2 cuando sea necesario y pagar solo por el tiempo de computación que utilices. En lugar de pagar por los recursos no utilizados o tener que lidiar con una capacidad limitada, puedes acceder solo a la capacidad que necesites. También puedes escalar horizontal o verticalmente según la demanda.

4) Aprovechar las economias de escala masiva:
Si utilizas la informática en la nube, podrás lograr un coste variable inferior al que obtendrías por tu cuenta.

Puesto que el uso de cientos de miles de clientes se puede agregar en la nube, los proveedores, como AWS, pueden lograr mayores economías de escala. La economía de escala se traduce en precios de pago por uso inferiores.

5) Aumentar la velocidad y agilidad:
La flexibilidad de la informática en la nube facilita el desarrollo y la implementación de aplicaciones.

Esta flexibilidad te proporciona más tiempo para experimentar e innovar. Cuando se computa en centros de datos, puede llevar semanas obtener recursos nuevos necesarios. En cambio, la informática en la nube permite acceder a nuevos recursos en cuestión de minutos.

6) Globalizarse en minutos:
La presencia global de la nube de AWS permite implementar aplicaciones a clientes de todo el mundo rápidamente, al tiempo que les proporciona baja latencia. Esto significa que, aunque te encuentres en una parte del mundo diferente a la de tus clientes, ellos pueden acceder a tus aplicaciones con retrasos mínimos. 

Más adelante en este curso verás la infraestructura global de AWS con más detalle. Examinarás algunos de los servicios que puedes utilizar para proporcionar contenido a clientes de todo el mundo.


///////////////////////////////////////////////////////////////////////////////////////////////

Introducción al  MODULO 2
////////////////////////////////////////////////////////////////////////////////////

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:
Describir los beneficios de Amazon EC2 a nivel básico.
Identificar los distintos tipos de instancias de Amazon EC2.
Diferenciar entre las distintas opciones de facturación de Amazon EC2.
Resumir los beneficios de Amazon EC2 Auto Scaling.
Resumir los beneficios de Elastic Load Balancing.
Dar un ejemplo de los usos de Elastic Load Balancing.
Resumir las diferencias entre Amazon Simple Notification Service (Amazon SNS) y Amazon Simple Queue Service (Amazon SQS).
Resumir las opciones de computación adicionales de AWS.

//
En este vídeo explicaremos a grandes rasgos un servicio llamado Amazon Elastic Compute Cloud (EC2). Recordemos la cafetería. Los empleados son una metáfora del modelo cliente-servidor en el que un cliente envía una solicitud al servidor, el servidor trabaja y luego envía una respuesta. (Ring) Ese ejemplo se aplica a la cafetería. Pero la misma idea se aplica a otras empresas. Tu empresa, ya sea de sanidad, de fabricación, de seguros o de transmisión de vídeo a millones de usuarios de todo el mundo también utiliza este modelo para entregar productos, recursos o datos a usuarios finales. Además, necesitarás servidores para potenciar tu negocio y tus aplicaciones. Necesitas capacidad de computación en bruto para alojar las aplicaciones y proporcionar la potencia de computación necesarias para la actividad empresarial. Cuando se trabaja con AWS, esos servidores son virtuales. Y los servidores que se utilizan para tener acceso a servidores virtuales se denominan EC2. 
El uso de EC2 en computación es flexible, rentable y rápido en comparación con administrar tus propios servidores en las instalaciones de un centro de datos. Se necesita mucho tiempo y dinero para poner todo en marcha con recursos basados en instalaciones. Cuando tienes tu propia flota de servidores físicos, primero tienes que investigar mucho para ver qué tipo de servidores quieres comprar y cuántos necesitarás. Luego, comprar ese hardware. Esperar varias semanas o meses a que un proveedor te entregue esos servidores. Luego, los llevas a un centro de datos propio o alquilado para instalarlos, almacenarlos, apilarlos y conectarlos. Después, te aseguras de que estén protegidos, encendidos y listos para su uso. Solo entonces podrás empezar a alojar las aplicaciones en estos servidores. Lo peor es que, una vez comprados, te los tendrás que quedar, los uses o no. 

Con EC2 es mucho más fácil empezar. AWS ya se ha encargado de la parte difícil. AWS ya ha creado y protegido los centros de datos. AWS ya ha comprado los servidores, los ha almacenado, apilado y ya están listos para su uso en línea. AWS opera constantemente una capacidad de computación inmensa. Y puedes usar la que necesites cuando la necesites. Es tan fácil como solicitar las instancias EC2 que desees para lanzarlas e iniciarlas, listas para su uso en unos minutos. Una vez que hayan terminado, puedes detener o terminar fácilmente las instancias EC2. No tienes que atarte a servidores que no necesites o no quieras. Su uso puede variar considerablemente, y solo pagarás por lo que utilices. Porque con EC2 solo pagas por instancias de ejecución, no por las detenidas o terminadas. 

EC2 se ejecuta en máquinas de alojamiento físicas administradas por AWS con tecnología de virtualización. Cuando activas una instancia EC2, no usas necesariamente un alojamiento completo solo para tu empresa, sino que compartes el alojamiento con varias instancias más, también conocidas como máquinas virtuales. Además, un hipervisor que se ejecuta en la máquina de alojamiento es responsable de compartir los recursos físicos subyacentes entre las máquinas virtuales. Compartir hardware subyacente así se denomina tenencia múltiple. El hipervisor es responsable de coordinar dicha tenencia y AWS la administra. El hipervisor aisla las máquinas virtuales entre sí, ya que comparten recursos del alojamiento. Así, las instancias EC2 están protegidas. Aunque compartan recursos, una instancia EC2 no sabe si hay otra en ese alojamiento. Están protegidas y separadas entre sí. 

Por suerte, esto no es algo que haya que configurar manualmente. Pero es importante conocer el concepto de tenencia múltiple y saber a grandes rasgos cómo funciona. EC2 proporciona gran flexibilidad y control. No solo es posible activar nuevos servidores o desconectarlos a voluntad, sino que también tienes la flexibilidad y el control de la configuración de esas instancias. 

Al aprovisionar una instancia EC2, puedes elegir el sistema operativo basado en Windows o Linux. Puedes aprovisionar miles de instancias EC2 bajo demanda con una combinación de sistemas operativos y configuraciones para potenciar las diferentes aplicaciones de tu empresa. 

Además del sistema operativo, también configuras qué software quieres ejecutar en la instancia. Ya sean tus propias aplicaciones empresariales internas, aplicaciones web simples o complejas, bases de datos o software de terceros como paquetes de software para empresas, tienes control total sobre lo que ocurre en esa instancia. También se puede modificar su tamaño. Puedes comenzar con una instancia pequeña y, cuando veas que la aplicación en ejecución está llegando a su límite en ese servidor, darle a esa instancia más memoria y más CPU. Es lo que llamamos escalar verticalmente una instancia. 

Básicamente, puede ampliar o reducir las instancias siempre que lo necesites. También es posible controlar el tema redes en EC2. Por lo tanto, el tipo de solicitudes que se envían al servidor y si la accesibilidad es pública o privada es cuestión de elección. 

Abarcaremos esto en detalle más adelante en el curso. Las máquinas virtuales no son ninguna novedad. Pero aprovisionar instancias EC2 así permite a los programadores y empresas innovar más rápido. Gracias a AWS, adquirir servidores es mucho más sencillo y rentable con este modelo de computación como servicio. Hay mucho más que aprender sobre EC2. Hemos hablado de la virtualización y los tipos de software que pueden ejecutarse en una instancia EC2. Pero también hay más opciones que puedes configurar con EC2.

// Amazon Elastic Compute Cloud (Amazon EC2):
Amazon Elastic Compute Cloud (Amazon EC2) proporciona capacidad de computación segura y redimensionable en la nube como instancias de Amazon EC2. 

Imagina que eres responsable de la arquitectura de los recursos de tu empresa y necesitas dar soporte a nuevos sitios web. Con los recursos tradicionales en las instalaciones, esto es lo que toca hacer:

Gastar dinero por adelantado para comprar hardware.
Esperar a que te entreguen los servidores.
Instalar los servidores en tu centro de datos físico.
Realizar todas las configuraciones necesarias.
En cambio, con una instancia de Amazon EC2 puedes utilizar un servidor virtual para iniciar aplicaciones en la nube de AWS.

Puedes aprovisionar y lanzar una instancia de Amazon EC2 en cuestión de minutos.
Puedes dejar de usarla cuando hayas terminado de lanzar una carga de trabajo.
Solo pagas por el tiempo de computación que utilizas cuando una instancia está en uso, no cuando se detiene o finaliza.
Puedes ahorrar costes pagando solo por la capacidad del servidor que necesite o desee.

//
Amazon Elastic Compute Cloud (Amazon EC2) proporciona capacidad de computación segura y redimensionable en la nube como instancias de Amazon EC2. 

Imagina que eres responsable de la arquitectura de los recursos de tu empresa y necesitas dar soporte a nuevos sitios web. Con los recursos tradicionales en las instalaciones, esto es lo que toca hacer:

Gastar dinero por adelantado para comprar hardware.
Esperar a que te entreguen los servidores.
Instalar los servidores en tu centro de datos físico.
Realizar todas las configuraciones necesarias.
En cambio, con una instancia de Amazon EC2 puedes utilizar un servidor virtual para iniciar aplicaciones en la nube de AWS.

Puedes aprovisionar y lanzar una instancia de Amazon EC2 en cuestión de minutos.
Puedes dejar de usarla cuando hayas terminado de lanzar una carga de trabajo.
Solo pagas por el tiempo de computación que utilizas cuando una instancia está en uso, no cuando se detiene o finaliza.
Puedes ahorrar costes pagando solo por la capacidad del servidor que necesite o desee.

//
Cómo funciona Amazon EC2
Para más información, selecciona el marcador correspondiente:
1-LANZAR
2- CONECTAR
3-USAR

//
Si queremos que el negocio funcione con la máxima eficiencia, tenemos que asegurarnos de que cada empleado tiene las habilidades necesarias para su labor. Del mismo modo que nuestra cafetería tiene distintos tipos de empleados, AWS tiene varios tipos de instancias EC2 que puedes activar e implementar en tu entorno de AWS. 

Cada tipo de instancia se agrupa en una familia de instancias y se optimiza para ciertos tipos de tareas. Los tipos de instancias ofrecen distintas combinaciones de CPU, memoria, almacenamiento y capacidad de red, y te otorgan la flexibilidad de elegir la combinación de recursos adecuada para tus aplicaciones. Las diferentes familias de instancias EC2 son las siguientes: de propósito general, de computación optimizada, de memoria optimizada, de computación acelerada y optimizadas para el almacenamiento. 

Las instancias de propósito general ofrecen un buen equilibro de recursos de computación, de memoria y de redes. Además, se pueden utilizar para diversas cargas de trabajo, como servicios web o repositorios de código. 

Las de computación optimizada son ideales para tareas de computación intensivas, como servicios de juegos, la computación de alto rendimiento (en inglés, HPC) e incluso modelado científico. 

Las instancias de memoria optimizada también son adecuadas para tareas que requieran un uso intensivo de dicho recurso. Las de computación acelerada son ideales para cálculos con números de comas flotantes, procesamiento de gráficos o coincidencia de patrones de datos, ya que utilizan aceleradores de hardware. 

Por último, las optimizadas para el almacenamiento son adecuadas para… ¿Lo adivinas? Cargas de trabajo de alta exigencia para datos almacenados localmente. 

Ahora, si lo aplicamos de nuevo a la cafetería, el cajero sería una instancia EC2 de memoria optimizada; los camareros, instancias de computación optimizada; y, el experto en café, una instancia de computación acelerada. Esos son los tipos de instancias EC2.

// Tipos de instancias de Amazon EC2:

Los tipos de instancias de Amazon EC2 están optimizados para distintas tareas. Al seleccionar un tipo de instancia, ten en cuenta las necesidades específicas de tus cargas de trabajo y aplicaciones. Esto podría incluir requisitos para capacidades de computación, memoria o almacenamiento.

Para más información, selecciona el símbolo + que aparece junto a cada categoría.

// INSTANCIAS DE PROPOSITO GENERAL:

Las instancias de propósito general proporcionan un equilibrio entre recursos de computación, memoria y redes. Puedes utilizarlas para diversas cargas de trabajo, tales como:

Servidores de aplicaciones.
Servidores de juegos.
Servidores de backend de aplicaciones para empresas.
Bases de datos pequeñas y medianas.
Supongamos que tienes una aplicación en la que las necesidades de recursos para la computación, memoria y redes son aproximadamente equivalentes. Puedes decidir iniciarla en una instancia de propósito general porque la aplicación no requiere optimización en ningún área de recursos única.

// INSTANCIAS DE COMPUTACION OPTIMIZADA:

Las instancias de computación optimizada son ideales para aplicaciones vinculadas a la computación que se benefician de procesadores de alto rendimiento. Al igual que las instancias de propósito general, puedes utilizar instancias de computación optimizada para cargas de trabajo como servidores web, aplicaciones o juegos.
Sin embargo, la diferencia es que las aplicaciones de computación optimizada son ideales para servidores web de alto rendimiento, servidores de aplicaciones de uso intensivo de computación y servidores de juegos dedicados. También puedes utilizar este tipo de instancias para cargas de trabajo de procesamiento por lotes que requieran procesar muchas transacciones en un solo grupo.

// INSTANCIAS OPTIMIZADAS DE MEMORIA:

Las instancias optimizadas de memoria están diseñadas para ofrecer un rendimiento rápido para cargas de trabajo que procesan grandes conjuntos de datos en la memoria. En computación, la memoria es un área de almacenamiento temporal. Contiene todos los datos e instrucciones que necesita una unidad central de procesamiento (CPU) para poder completar acciones. Para poder iniciar un programa o una aplicación de ordenador, debe cargarse desde el almacenamiento a la memoria. Este proceso de precarga proporciona a la CPU acceso directo al programa informático.

Supongamos que tienes una carga de trabajo que requiere que se carguen previamente grandes cantidades de datos antes de iniciar una aplicación. En este escenario, puede tratarse de una base de datos de alto rendimiento o de una carga de trabajo que implique procesar en tiempo real una gran cantidad de datos no estructurados. En este tipo de casos prácticos, considera la posibilidad de utilizar una instancia optimizada de memoria. Estas permiten llevar a cabo cargas de trabajo con altas necesidades de memoria y obtener un excelente rendimiento.

// INSTANCIAS DE COMPUTACION ACELERADA:

Las instancias de computación acelerada utilizan aceleradores de hardware o coprocesadores para realizar algunas funciones de la forma más eficiente posible en el software que se inicia en las CPU. Algunos ejemplos de estas funciones incluyen cálculos con números de coma flotante, procesamiento de gráficos y coincidencia de patrones de datos.

En informática, un acelerador de hardware es un componente que puede acelerar el procesamiento de datos. Las instancias de computación acelerada son ideales para cargas de trabajo como aplicaciones gráficas, streaming de juegos y streaming de aplicaciones.


//  Instancias optimizadas para el almacenamiento:

Las instancias optimizadas para el almacenamiento están diseñadas para cargas de trabajo que requieren acceso de lectura y escritura alto y secuencial a grandes conjuntos de datos en el almacenamiento local. Algunos ejemplos de cargas de trabajo adecuadas para este tipo de instancias incluyen sistemas de archivos distribuidos, aplicaciones de data warehousing y sistemas de procesamiento de transacciones en línea de alta frecuencia (OLTP).

En informática, el término operaciones de entrada/salida por segundo (IOPS) es una métrica que mide el rendimiento de un dispositivo de almacenamiento. Indica cuántas operaciones de entrada o salida diferentes puede realizar un dispositivo en un segundo. Las instancias optimizadas para el almacenamiento están diseñadas para ofrecer decenas de miles de IOPS aleatorias y de baja latencia a las aplicaciones. 

Puede pensar en las operaciones de entrada como datos introducidos en un sistema, como los registros introducidos en una base de datos. Una operación de salida son datos generados por un servidor. Un ejemplo de salida podría ser el análisis realizado en los registros de una base de datos. Si tiene una aplicación que tiene un alto requisito de IOPS, una instancia optimizada para el almacenamiento puede proporcionar un mejor rendimiento en comparación con otros tipos de instancias no optimizadas para este tipo de caso práctico.


/// PRECIOS:
Hemos hablado de los tipos de instancias EC2, pero no de cuánto cuestan. No te preocupes. Para EC2, tenemos varias opciones de facturación disponibles. 

La primera, que es la que la mayoría de las personas conoce, es la de bajo demanda. Con ella solo pagas por el tiempo de ejecución de las instancias. Puede ser por hora o por segundo según el tipo de instancia y el sistema operativo que se ejecute. Además, no requiere que te comprometas a largo plazo ni que hagas pagos adelantados. Este tipo de precios suele estar indicado cuando comienzas y quieres aumentar el servicio para probar cargas de trabajo y tantear. No necesitas ningún contrato previo ni comunicarte con AWS para usar los precios bajo demanda. También sirve como referencia para ver tu uso medio, lo que nos lleva a la siguiente opción de precios: el plan de ahorro. 

Este plan ofrece precios bajos por usar EC2 a cambio de comprometerte a realizar un uso constante medido en dólares por hora durante un término de 1 o 3 años. Este modelo de precios flexible puede ahorrarte hasta un 72 % en el uso de computación de AWS. Esto permite una reducción en el precio por uso de EC2, sea cual sea la familia de instancias, tamaño, SO, tenencia o región de AWS. Esto también se aplica al uso de AWS Fargate y AWS Lambda, que son opciones de computación sin servidor de las que hablaremos en este curso. 

Otra opción son las instancias reservadas. Son ideales para cargas de trabajo con estado estable o con un uso predecible. Ofrecen un ahorro de hasta un 75 % frente a los precios bajo demanda. Puedes optar a un descuento al comprometerte a un periodo de 1 o 3 años y pagarlo de cualquiera de estas tres maneras: pago total anticipado, que se hace al formalizar el compromiso; pago parcial anticipado, que consiste en pagar una parte tras la formalización; y sin pago inicial, que consiste en no pagar nada al principio. 

Otra opción son las instancias de spot, que te permiten solicitar capacidad de computación extra de Amazon EC2 por hasta el 90 % del precio bajo demanda. El inconveniente es que AWS puede recuperar la instancia en cualquier momento que lo necesite y te manda una advertencia de 2 minutos para finalizar el trabajo y guardar el estado. Puedes seguir después si es necesario. Si eliges instancias de spot, asegúrate de que las cargas de trabajo se pueden interrumpir. Un ejemplo son las cargas de trabajo por lotes. 

Por último, tenemos hosts dedicados, que son alojamientos físicos dedicados para su uso en EC2. Se suelen usar para cumplir ciertos requisitos de conformidad y la tenencia de ese alojamiento no se comparte con nadie.

//
Precios de Amazon EC2:

Con Amazon EC2, solo pagas por el tiempo de computación que utilizas. Amazon EC2 ofrece diversas opciones de precios para distintos casos prácticos. Por ejemplo, si tu caso práctico puede soportar interrupciones, puedes ahorrar con las instancias de spot. También puedes ahorrar si te comprometes de forma anticipada y bloqueas un nivel mínimo de uso con las instancias reservadas.

Para más información, selecciona el símbolo + que aparece junto a cada categoría.

//  instancias bajo demanda:

Las instancias bajo demanda son ideales para cargas de trabajo irregulares a corto plazo que no se pueden interrumpir. No se aplican costes iniciales ni contratos mínimos. Las instancias se inician continuamente hasta que las detienes y solo pagas por el tiempo de computación que usas.

Algunos ejemplos de casos prácticos para instancias bajo demanda incluyen el desarrollo y la prueba de aplicaciones, y el arranque de aplicaciones que tienen patrones de uso impredecibles. Las instancias bajo demanda no se recomiendan para cargas de trabajo que duran un año o más porque estas cargas de trabajo pueden experimentar un mayor ahorro de costes mediante instancias reservadas.

// Los planes de ahorro de Amazon EC2:

AWS ofrece planes de ahorro para varios servicios de computación, incluido Amazon EC2. Los planes de ahorro de Amazon EC2 te permiten reducir los costes de computación si te comprometes a un uso de computación constante durante un periodo de 1 o 3 años. El compromiso durante este periodo se traduce en un ahorro de hasta un 72 % en comparación con los costes bajo demanda.

Cualquier uso que no supere el compromiso se cobra según la tarifa del plan de ahorro con descuento (por ejemplo, 10 USD la hora). El uso que supere el compromiso se cobra según las tarifas bajo demanda habituales.

Más adelante en el curso, verás AWS Cost Explorer, una herramienta que te permitirá visualizar, comprender y administrar los costes y el uso de AWS a lo largo del tiempo. Si estás barajando opciones de planes de ahorro, AWS Cost Explorer puede analizar tu uso de Amazon EC2 durante los últimos 7, 30 o 60 días. AWS Cost Explorer también ofrece recomendaciones personalizadas para planes de ahorro. Estas recomendaciones realizan una estimación de cuánto podrías ahorrar en los costes mensuales de Amazon EC2, según el uso previo de Amazon EC2 y el importe del compromiso por hora en un plan de ahorro de 1 o 3 años.

// Instancias reservadas:
–
Las instancias reservadas son un descuento de facturación que se aplica al uso de instancias bajo demanda en tu cuenta. Puedes comprar instancias reservadas estándar y convertibles para un periodo de 1 o 3 años, e instancias reservadas programadas para un periodo de 1 año. Lograrás un mayor ahorro de costes con la opción de 3 años.

Al final de un periodo de instancia reservada, puedes seguir utilizando la instancia de Amazon EC2 sin interrupción. Sin embargo, se te cobrarán tarifas bajo demanda hasta que realices una de las siguientes acciones:

Terminar la instancia.
Adquirir una nueva instancia reservada que coincida con los atributos de instancia (tipo de instancia, región, tenencia y plataforma).

//Instancias de spot:
–
Las instancias de spot son ideales para cargas de trabajo con horarios de inicio y fin flexibles, o que pueden soportar interrupciones. Estas instancias utilizan la capacidad de computación de Amazon EC2 no utilizada y ofrecen ahorro de costes con hasta un 90 % de descuento en los precios bajo demanda.

Supongamos que tienes un trabajo de procesamiento en segundo plano que puede iniciarse y detenerse según sea necesario (como el trabajo de procesamiento de datos de una encuesta de clientes). Lo deseable es iniciar y detener el trabajo de procesamiento sin que afecte a las operaciones generales de la empresa. Si realizas una petición de spot y la capacidad de Amazon EC2 está disponible, se lanzará la instancia de spot. Sin embargo, si realizas una petición de spot y la capacidad de Amazon EC2 no está disponible, la petición no se realizará correctamente hasta que la capacidad esté disponible. La capacidad no disponible puede retrasar el lanzamiento del trabajo de procesamiento en segundo plano.

Después de lanzar una instancia de spot, si la capacidad ya no está disponible o aumenta la demanda de dichas instancias, es posible que la instancia se interrumpa. Puede que esto no suponga ningún problema para el trabajo de procesamiento en segundo plano. Sin embargo, en el ejemplo anterior de desarrollo y prueba de aplicaciones, lo más probable es que desees evitar interrupciones inesperadas. Por lo tanto, elige otro tipo de instancia EC2 más adecuado para esas tareas.

//Hosts dedicados:
–
Los hosts dedicados son servidores físicos con capacidad de instancias de Amazon EC2 totalmente dedicada a su uso. 

Puedes utilizar las licencias de software existentes por socket, por núcleo o por VM para ayudar a mantener la conformidad de las licencias. Puedes comprar reservas de hosts dedicados y hosts dedicados bajo demanda. De todas las opciones de Amazon EC2 cubiertas, los hosts dedicados son los más caros.

// ESCALADO.
Ahora conoces mejor los conceptos básicos de EC2 y su utilidad ante cualquier necesidad de computación y cómo preparar café. Bueno, metafóricamente hablando. El café representa lo que producen las instancias. Ahora hablaremos de otros de los principales beneficios de AWS: la escalabilidad y la elasticidad. O cómo la capacidad aumenta o disminuye según las necesidades empresariales.

¿Centros de datos en instalaciones? Si tu empresa es como el 99 % de las empresas del mundo, las cargas de trabajo con clientes varían con el tiempo. Puede que varíen durante 24 horas, o que haya periodos en los que hay demanda y semanas en las que no hay. Si estás creando un centro de datos, la pregunta es la siguiente: ¿cuánto hardware es ideal comprar? Si compras por la cantidad media, por el uso medio, en general no desperdiciarás dinero. Pero cuando lleguen los picos de trabajo, no tendrás el hardware necesario para atender a los clientes, sobre todo en los momentos críticos, cuando esperas conseguir más resultados.

Sin embargo, si compras la carga máxima, puede que tengas clientes satisfechos, pero durante la mayor parte del año tendrán recursos sin usar. Lo que significa que su uso medio será muy bajo. He visto centros de datos con un uso medio inferior al 10 % solo por temor a perder la demanda máxima. Entonces, ¿cómo se resuelve el problema en las instalaciones? La verdad es que no se puede. Aquí es donde AWS cambia el esquema por completo.

¿Y si pudieras aprovisionar tu carga de trabajo según la demanda que hubiera con exactitud las 24 horas? Tendrías clientes satisfechos porque siempre podrían obtener los servicios que desean, y tus directores financieros estarían contentos porque habrían obtenido el ROI que necesitan tus empresas.

Así es como funciona: Morgan está en la barra recibiendo pedidos en un sistema desacoplado. Como Morgan no lo hace todo, necesitamos a alguien que prepare las bebidas. Parece que será Rudy. Ahora, el primer problema que resolver es anticiparnos a un desastre. Una vez, Werner Vogels dijo algo muy sabio: "Todo falla siempre; planifica los errores y nada fallará". Es decir, preguntémonos qué pasaría si perdiéramos la instancia que acepta nuestros pedidos. No podríamos seguir atendiendo hasta que otra persona trabajara en la línea. Vaya, otra instancia en marcha.

Aquí es donde AWS lo facilita todo. Con el mismo método programático usado para crear la Morgan original, podemos crear una segunda Morgan. Así, si una falla, ya tenemos a otra en primera línea para aceptar pedidos. Los clientes nunca quedan desatendidos. Y no olvidemos el backend. Despidamos también a nuestras instancias de procesamiento. Eso es suficiente para la capacidad operativa habitual. Creamos un sistema altamente disponible sin ningún punto de error. Mientras el número de clientes en línea sea constante, vamos bien. Pero sabemos que eso va a cambiar. Así que veamos qué pasaría si aumentan la cantidad de clientes y la demanda.

Escalabilidad

La escalabilidad implica comenzar solo con los recursos que se necesitan y diseñar la arquitectura para responder automáticamente a la demanda cambiante mediante el escalado horizontal o vertical. Como resultado, solo se paga por los recursos que se utilizan. No hay que preocuparse por la falta de capacidad de computación para satisfacer las necesidades de los clientes.

Si quisieras que el proceso de escalado se realizara automáticamente, ¿qué servicio de AWS utilizarías? El servicio de AWS que proporciona esta funcionalidad para las instancias de Amazon EC2 es Amazon EC2 Auto Scaling.

Amazon EC2 Auto Scaling

Si has intentado acceder a un sitio web que no cargaba y donde se agotaba el tiempo de espera con frecuencia, es posible que el sitio web recibiera más peticiones que las que podía manejar. Esta situación se parece a esperar en una larga fila para pedir en una cafetería con solo un camarero para todos los clientes.

Amazon EC2 Auto Scaling te permite agregar o eliminar automáticamente instancias de Amazon EC2 en respuesta a la demanda cambiante de las aplicaciones. Al escalar automáticamente las instancias horizontal y verticalmente según sea necesario, puedes mantener una mayor sensación de disponibilidad de las aplicaciones.

En Amazon EC2 Auto Scaling, puedes utilizar dos estrategias: escalado dinámico y escalado predictivo.

El escalado dinámico responde a la demanda cambiante. 
El escalado predictivo programa automáticamente el número correcto de instancias de Amazon EC2 en función de la demanda prevista.

//
Hay dos formas de gestionar el aumento de la demanda: el escalado vertical y el horizontal. El vertical consiste en agregar potencia a las máquinas que están en uso, lo que tendría sentido en ciertos casos, pero pensémoslo bien. Cuando aumenta el número de clientes, una instancia mayor de Morgan no puede aceptar más rápido el pedido de cada cliente. Porque eso depende más de cada cliente que de Morgan. 

Quiero un espreso. Eh, espera, ¿es orgánico? ¿Tienes leche de soja? Pues, no lo sé. ¿Hay té? 

Lo que necesitamos son más Morgans. (Murmullos) ¿Clientes? (Sonido de replicación) ¡Vaya!  Las instancias de procesamiento parecen estar a punto de sobrecargarse. Vamos a escalarlas también. 

La pregunta es más que obvia: ¿por qué hay más instancias que aceptan los pedidos que personas que los preparan? 

En este caso, la cantidad de trabajo que se puede hacer es mayor que la cantidad de pedidos que las máquinas pueden enviar. Sin trabajos pendientes, no necesitas agregar más instancias de empleados. Esa es una de las grandes ventajas de desacoplar el sistema: que puedes dedicar exactamente la potencia adecuada a cada parte del proceso en lugar de aprovisionar en exceso para resolver un problema aparte. Bien, parece que hemos resuelto la urgencia. 

Ahora veamos dónde AWS marca una diferencia importante para tu empresa. Todos estos empleados adicionales que no están haciendo nada, si no los necesitan, mándalos a casa (detén las instancias). (Clics) Amazon EC2 Auto Scaling: agrega instancias en función de la demanda y retíralas cuando ya no las necesiten. Esto quiere decir que cada momento tendrás el número adecuado de instancias. Clientes satisfechos. Director financiero satisfecho. Arquitectura satisfecha.


//
Ejemplo: Amazon EC2 Auto Scaling

En la nube, la potencia de computación es un recurso programático, por lo que puedes adoptar una estrategia más flexible del problema del escalado. Al agregar Amazon EC2 Auto Scaling a una aplicación, puedes agregar nuevas instancias a la aplicación cuando sea necesario y terminarlas cuando ya no sea necesario.

Supongamos que te estás preparando para lanzar una aplicación en instancias de Amazon EC2. Al configurar el tamaño de tu grupo de Auto Scaling, puedes establecer el número mínimo de instancias de Amazon EC2 en uno. Esto significa que, en todo momento, debe haber al menos una instancia de Amazon EC2 en uso.

Al crear un grupo de Auto Scaling, puedes establecer el número mínimo de instancias de Amazon EC2. La capacidad mínima es el número de instancias de Amazon EC2 que se lanzan inmediatamente después de crear el grupo de Auto Scaling. En este ejemplo, el grupo de Auto Scaling tiene una capacidad mínima de una instancia de Amazon EC2.

A continuación, puedes establecer la capacidad deseada en dos instancias de Amazon EC2 aunque tu aplicación necesite al menos una única instancia de Amazon EC2 para iniciar.

La tercera configuración que puedes establecer en un grupo de Auto Scaling es la capacidad máxima. Por ejemplo, puedes configurar el grupo de Auto Scaling para que se escale horizontalmente en respuesta al aumento de la demanda, pero solo hasta un máximo de cuatro instancias de Amazon EC2.

Como Amazon EC2 Auto Scaling utiliza instancias de Amazon EC2, solo pagarás por las instancias que utilices cuando las uses. Ahora tienes una arquitectura rentable que proporciona la mejor experiencia de cliente a la vez que reduces los gastos.


/// Dirección de tráfico con Elastic Load Balancing: 

Hemos resuelto el problema de escalado con Amazon EC2 Auto Scaling. Pero ahora tenemos un problema de tráfico, ¿no? Veamos la situación. Cuando los clientes llegan a la cafetería, ahora hay tres cajas en las que pueden hacer sus pedidos. Pero, por raro que parezca, la mayoría hace una sola fila, lo que ocasiona una distribución desigual de clientes, aunque otras cajas están esperando pedidos paradas sin hacer nada. Los clientes entran y no saben bien a quién hacer su pedido. Ayudaría mucho que añadiéramos un anfitrión. 

Un anfitrión espera en la puerta y cuando los clientes entran en la cafetería, les dice a qué fila deben ir para hacer su pedido. El anfitrión observa el ritmo de los pedidos en las cajas y cuenta el número de personas de la fila de cada caja. Después, dirige a los nuevos clientes a la caja con la fila más corta o la más rápida para equilibrar las filas de las cajas y poder atender a los clientes con la máxima eficiencia. 

La misma idea se aplica al entorno de AWS. Cuando varias instancias EC2 están usando el mismo programa para cumplir el mismo propósito y aparece una solicitud, ¿cómo sabe esa solicitud a qué instancia EC2 ir? ¿Cómo puedes asegurarte de que la carga de trabajo sea uniforme entre las instancias EC2 para que no se apoye solo a una mientras las demás no están haciendo nada? Necesitas una forma de dirigir solicitudes a instancias para procesar esa solicitud. Lo que necesitas para resolverlo se denomina equilibrio de carga. 

Un equilibrador de carga es una aplicación que recibe solicitudes y las dirige a las instancias para procesarlas. Hay muchos equilibradores de carga de terceros que funcionan muy bien en AWS. Si tienes uno que te gusta y que hace exactamente lo que necesitas, puedes seguir usándolo. En ese caso, serán tus equipos de operaciones los que deban instalar, administrar, actualizar, escalar y gestionar la tolerancia a fallos y la disponibilidad. Es factible. Probablemente solo necesitas distribuir correctamente el tráfico en un sistema de alto rendimiento, rentable, de alta disponibilidad y escalable automáticamente, que se configure una vez y ya no requiera más atención. 

Te presento Elastic Load Balancing. Elastic Load Balancing (ELB) es uno de los principales Managed Services de los que hablaremos. Está diseñado para gestionar el trabajo pesado intrascendente del equilibrio de carga. Para ilustrar este punto, necesito ampliar un poco el enfoque. Para empezar, Elastic Load Balancing es un constructo regional en el que profundizaremos en vídeos posteriores. Pero el valor clave que supone es que, como se inicia a nivel regional en lugar de en instancias EC2 individuales, el servicio está altamente disponible  sin que tengas que hacer nada. 

ELB se escala automáticamente. A medida que crece el tráfico, ELB está diseñado para gestionar el rendimiento adicional sin cambiar el coste por hora. Cuando se escala horizontalmente su flota de EC2 automáticamente y cada instancia entra en línea, Elastic Load Balancing recibe el aviso de que ya puede encargarse del tráfico y se pone a ello. Una vez que la flota se escala, primero ELB detiene todo el tráfico nuevo y espera a que se completen las solicitudes existentes para liberar espacio. Una vez lo hacen, el motor de escalado automático puede terminar las instancias sin interrumpir el servicio a los clientes existentes. 

ELB no solo se usa en el tráfico externo. Veamos el nivel de pedido y cómo se comunica con el de producción. En este momento, cada instancia de frontend conoce cada instancia de backend. Y, si entra en línea una nueva instancia de backend en esta misma arquitectura, se tendría que indicar a cada instancia de frontend que ahora puede aceptar tráfico. Esto ya es bastante complicado con solo media docena de instancias. Imagina que tienes potencialmente cientos de instancias en ambos niveles y que cada nivel cambia constantemente en función de la demanda. Mantener la conexión en red de manera eficiente es imposible. 

También podemos resolver este caos de tráfico de backend con un ELB. Dado que ELB es regional, es una única URL que cada instancia de frontend utiliza. A continuación, ELB dirige el tráfico al backend que tiene las solicitudes con menor prioridad. Si el backend se escala, una vez que la nueva instancia está lista, solo le dice a ELB que puede ocuparse del tráfico y se pone a trabajar. El frontend no sabe y no le importa cuántas instancias backend están en uso. Esto sí es una arquitectura desacoplada. 

ELB puede hacer más cosas. Hablaremos de ello más adelante, pero esto es todo por ahora. La clave es usar la herramienta adecuada para el trabajo correcto, que es uno de los motivos por los que AWS ofrece tantos servicios diferentes. Por ejemplo, la comunicación de backend. Hay muchas formas de hacerlo y ELB es solo uno de esos métodos. Pasemos a hablar de otros servicios que podrían ser incluso mejores para algunas arquitecturas.


//
Elastic Load Balancing

Elastic Load Balancing es el servicio de AWS que distribuye automáticamente el tráfico entrante de aplicaciones entre varios recursos, como instancias de Amazon EC2. 

Un equilibrador de carga actúa como un único punto de contacto para todo el tráfico web entrante a tu grupo de Auto Scaling. Esto significa que, al agregar o eliminar instancias de Amazon EC2 en respuesta a la cantidad de tráfico entrante, estas peticiones se dirigen primero al equilibrador de carga. A continuación, las peticiones se distribuyen entre varios recursos que las gestionarán. Por ejemplo, si tienes varias instancias de Amazon EC2, Elastic Load Balancing distribuye la carga de trabajo entre las distintas instancias para que ninguna de ellas se vea sobrecargada. 

Aunque Elastic Load Balancing y Amazon EC2 Auto Scaling son servicios independientes, colaboran para garantizar que las aplicaciones que se inician en Amazon EC2 puedan proporcionar un alto rendimiento y disponibilidad.

Ejemplo: Elastic Load Balancing

// Periodo de baja demanda

Este es un ejemplo de cómo funciona Elastic Load Balancing. Supongamos que solo unos cuantos clientes han venido a la cafetería para hacer pedidos. 

Si solo hay algunas cajas registradoras abiertas, eso coincide con la demanda de clientes que necesitan servicio. Es menos probable que la cafetería tenga cajas registradoras abiertas sin clientes. En este ejemplo, puedes pensar en las cajas registradoras como si fueran instancias de Amazon EC2.

// Periodo de alta demanda

A lo largo del día, a medida que aumenta el número de clientes, la cafetería abre más cajas registradoras para atenderles. En el diagrama, el grupo de Auto Scaling representa esto.

Además, un empleado de la cafetería dirige a los clientes a la caja registradora más adecuada para que el número de pedidos se distribuya uniformemente entre las cajas registradoras abiertas. Puedes pensar en este empleado de la cafetería como un equilibrador de carga.

// Mensajería y cola:

Hablemos de mensajería y colas. En la cafetería, los cajeros reciben los pedidos de los clientes y los baristas preparan los pedidos. El cajero recibe cada pedido apuntándolo en un papel que entrega al barista. El barista toma el papel y prepara el pedido. Con el siguiente pedido, el proceso se repite. Esto funciona muy bien siempre y cuando el cajero y el barista estén sincronizados. Pero ¿y si el cajero le pasara el pedido a un barista que estuviera de descanso u ocupado con otro pedido? Se formaría un atasco en la caja hasta que el barista estuviera listo para aceptar el pedido. En cierto momento, puede que el pedido quede en espera para que el cajero pueda atender al próximo cliente. 



Es un proceso deficiente porque si el cajero o el barista no están sincronizados, el proceso se vería afectado, lo que ralentiza la recepción de pedidos y ocasiona fallos de procesamiento. Una mejora en el proceso sería introducir algún tipo de buffer o cola en el sistema. En lugar de entregar el pedido directamente al barista, el cajero publicaría el pedido en algún tipo de buffer, como un tablón de comandas. 



Esta idea de colocar mensajes en un buffer se denomina mensajería y cola. Así como el cajero envía pedidos al barista, las aplicaciones se envían mensajes entre sí para comunicarse. La comunicación entre aplicaciones directamente, como el cajero y el barista, se llama acoplamiento ajustado. 



Un rasgo distintivo de la arquitectura de acoplamiento ajustado es que, si un solo componente falla o cambia, causa problemas en otros componentes o incluso en todo el sistema. Por ejemplo, si la aplicación A envía mensajes directamente a la aplicación B, y la aplicación B tiene un fallo y no puede aceptar esos mensajes, la aplicación A también comenzará a tener errores. Así es ese tipo de arquitectura. 



Una arquitectura más fiable es la de acoplamiento débil. En ella, si un componente falla, se aísla y, por lo tanto, no ocasiona errores en cascada en todo el sistema. Si codificamos la aplicación para utilizar una arquitectura de acoplamiento más débil, funcionaría más o menos así: 



Al igual que nuestro cajero y barista, introducimos un buffer entre los dos. En este caso, introducimos una cola de mensajes. La aplicación A envía mensajes a la cola y la aplicación B los procesa. Si la aplicación B falla, la aplicación A sigue funcionando sin problemas. Los mensajes que se envían aún pueden enviarse a la cola y permanecer allí hasta que finalmente se procesen. Así funciona el acoplamiento débil. Esto es lo que queremos para las arquitecturas de AWS. Y esto me lleva a dos servicios de AWS que pueden ser útiles en este sentido. 



Amazon Simple Queue Service (SQS) y Amazon Simple Notification Service (SNS). Pero, antes de profundizar en ambos, voy a pedir un café para llevar en el sitio web de nuestra cafetería. Hecho. Muy bien, bueno. Ahora debería recibir un mensaje cuando el pedido esté listo. 

Primero, hablemos de Amazon SQS. SQS permite enviar, almacenar y recibir mensajes entre componentes de software a cualquier volumen. Todo esto sin perder mensajes ni necesitar que haya otros servicios disponibles. Los mensajes serían como pedidos de café y, el tablón de comandas, una cola de SQS. Los mensajes tienen el nombre de la persona, el pedido de café y la hora en que se pidió. Los datos incluidos en el mensaje se denominan cargas y están protegidos hasta la entrega. Los mensajes se colocan en la cola de SQS hasta que se procesan. AWS administra la infraestructura subyacente para que pueda alojar esas colas. Se escalan automáticamente, son fiables y fáciles de configurar y usar. 



Amazon SNS es similar porque se utiliza para enviar mensajes a los servicios, pero también puede enviar notificaciones a usuarios finales. Lo hace de un modo distinto, llamado modelo de publicación/suscripción o modelo pub/sub. Eso significa que puedes crear algo llamado "tema SNS", que no es más que un canal para enviar mensajes. Luego, puedes vincular a los suscriptores con ese tema y, finalmente, publicar mensajes para esos suscriptores. En la práctica, significa que puedes enviar un mensaje a un tema y ese mensaje se difundirá entre todos los suscriptores a la vez. Los suscriptores pueden ser puntos de enlace, como colas de SQS, funciones Lambda de AWS o enlaces web HTTPS o HTTP. 



Además, SNS puede utilizarse para difundir las notificaciones a usuarios finales mediante push a móviles, SMS y correo electrónico. Volviendo a la cafetería: podríamos enviar una notificación cuando el pedido de un cliente esté listo. Podría ser un simple SMS o un mensaje push al móvil para avisar de que pueden recogerlo. (sonido de mensaje) De hecho, acabo de recibir un mensaje en mi teléfono. Parece que mi pedido está listo. ¡Nos vemos!

//Aplicaciones monolíticas y microservicios

Las aplicaciones están formadas de varios componentes. Los componentes se comunican entre sí para transmitir datos, satisfacer solicitudes y mantener la aplicación en uso. 

Supongamos que tienes una aplicación con componentes estrechamente acoplados. Estos componentes pueden incluir bases de datos, servidores, interfaz de usuario, lógica empresarial, etc. Este tipo de arquitectura puede considerarse una aplicación monolítica. 

En esta estrategia de arquitectura de aplicaciones, si falla un componente, otros componentes fallan y, probablemente, toda la aplicación fallará.

-- Para ayudar a mantener la disponibilidad de las aplicaciones cuando falla un componente, puedes diseñar tu aplicación mediante la estrategia de microservicios.

En una estrategia de microservicios, los componentes de la aplicación están acoplados débilmente. En este caso, si falla un solo componente, los demás componentes siguen funcionando porque están comunicados entre sí. El acoplamiento débil evita que toda la aplicación falle. 

Cuando diseñes aplicaciones en AWS, puedes adoptar la estrategia de microservicios con servicios y componentes que cumplan diferentes funciones. Dos servicios facilitan la integración de aplicaciones: Amazon Simple Notification Service (Amazon SNS) y Amazon Simple Queue Service (Amazon SQS).

--Amazon Simple Notification Service (Amazon SNS)

Amazon Simple Notification Service (Amazon SNS) es un servicio de publicación/suscripción. Mediante temas de Amazon SNS, un editor publica mensajes a los suscriptores. Esto es similar a la cafetería: el cajero pasa los pedidos de café al camarero para que prepare las consumiciones.

En Amazon SNS, los suscriptores pueden ser servidores web, direcciones de correo electrónico, funciones de AWS Lambda u otras opciones.

//Amazon Simple Queue Service (Amazon SQS)

Amazon Simple Queue Service (Amazon SQS) es un servicio de cola de mensajes. 

Con Amazon SQS, puedes enviar, almacenar y recibir mensajes entre componentes de software, sin perder mensajes y sin necesidad de que otros servicios estén disponibles. En Amazon SQS, una aplicación envía mensajes a una cola. Un usuario o un servicio extrae un mensaje de la cola, lo procesa y, a continuación, lo elimina de la cola.


///Servicios de computación adicionales:

Las instancias EC2 son máquinas virtuales que puedes poner en marcha en pocos pasos en AWS. EC2 es ideal para todo tipo de casos prácticos, como lanzar servidores web básicos o clústeres informáticos de alto rendimiento, entre otros usos. 

Dicho esto, aunque EC2 es increíblemente flexible, fiable y escalable, según tus casos prácticos, lo mejor es buscar opciones adecuadas para tus capacidades de computación. EC2 requiere que configures y administres tu flota de instancias con el tiempo. Cuando utilizas EC2, debes encargarte de parchear tus instancias si surgen nuevos paquetes de software, configurar el escalado de esas instancias y asegurarte de haber estructurado tus soluciones para que estén alojadas y cuenten con una alta disponibilidad. Si bien no supone tanta administración como la que requeriría alojarlas en las instalaciones, sigue habiendo determinados procesos al respecto. 

Quizá te preguntes qué otros servicios de computación de AWS son más prácticos en términos de administración. Aquí es donde entra en juego el término sin servidor. AWS ofrece varias soluciones de computación sin servidor. Sin servidor significa que no se puede ver ni acceder a la infraestructura o a las instancias subyacentes que alojan sus aplicaciones. Toda la administración del entorno subyacente, en cuanto a aprovisionamiento, escalado, alta disponibilidad y mantenimiento se hace desde AWS. Solo tienes que centrarte en la aplicación mientras AWS se encarga del resto. 

AWS Lambda es una solución de computación sin servidor. Lambda es un servicio que permite cargar tu código en lo que se llama función Lambda. Configura un desencadenador y el servicio lo espera. Cuando se detecta el desencadenador, el código se inicia automáticamente en un entorno administrado del que no tienes que preocuparte porque se escala solo, es altamente disponible y AWS se encarga de su mantenimiento. Ya tengas 1 o 1000 desencadenadores entrantes, Lambda ampliará las funciones para satisfacer la demanda. Lambda está diseñado para iniciar código en menos de 15 minutos, no para procesos de uso extensivo como el aprendizaje profundo. Es mejor para procesos rápidos, como backend web, gestión de solicitudes o servicios de procesamiento de informes de gastos de backend, donde cada invitación tarda menos de 15 minutos en completarse. 

Si aún no quieres disponer de un servidor o necesitas acceso al entorno subyacente y deseas eficiencia y portabilidad, es mejor usar servicios de contenedores, como Amazon Elastic Container Service, también llamado ECS, o Amazon Elastic Kubernetes Service, también llamado EKS. 

Ambos servicios son herramientas de organización de contenedores. Antes de profundizar en esto, un contenedor en este caso es un contenedor Docker. Docker es una plataforma muy usada que utiliza la virtualización a nivel de sistema operativo para entregar software en contenedores. Un contenedor es un paquete de código que incluye tu aplicación, sus dependencias y cualquier configuración que necesite lanzar. Estos contenedores se lanzan en instancias EC2 y de forma aislada entre sí, como las máquinas virtuales. Pero, en este caso, el host es una instancia EC2. Al usar contenedores Docker en AWS, necesitas procesos para comenzar, detener, reiniciar y supervisar los contenedores que se lanzan no solo en una instancia EC2, sino en un conjunto, lo que se denomina clúster. 

El proceso de realizar estas tareas se denomina organización de contenedores y es muy complicado hacerlo por tu propia cuenta. Hay herramientas de organización que ayudan a administrar contenedores. ECS sirve para ayudarte a lanzar tus aplicaciones en contenedores a escala y ahorrarte la molestia de administrar el software de aprovisionamiento. EKS es similar, pero dispone de herramientas y características diferentes. 

Tanto Amazon ECS como Amazon EKS pueden lanzarse en EC2. Pero si no tienes pensado usar EC2 para alojar los contenedores porque no necesitas acceso al SO subyacente o no quieres administrar esas instancias EC2, puedes utilizar una plataforma de computación llamada AWS Fargate. Fargate es una plataforma sin servidor para ECS o EKS. Ha sonado muy técnico y puede parecer confuso, así que voy a explicarlo. 

Si tienes pensado alojar aplicaciones tradicionales y quieres acceso completo al sistema operativo subyacente, como Linux o Windows, la opción adecuada es EC2. Si deseas alojar funciones de inicio breve, aplicaciones de servicios o basadas en eventos y no deseas administrar el entorno subyacente, Lambda es una buena opción. Para llevar a cabo cargas de trabajo basadas en contenedores Docker en AWS, primero debes elegir la herramienta de aprovisionamiento. ¿Quieres utilizar ECS o EKS de Amazon? Después de elegir la herramienta, debes elegir la plataforma. ¿Quieres lanzar los contenedores en instancias EC2 administradas por ti mismo? ¿O en un entorno sin servidor, como AWS Fargate, que lo administra en tu lugar? 

Estas son algunas soluciones de computación en AWS y hay muchas más. Consulta en las notas más información sobre los servicios de computación de AWS y las demás opciones que no he mencionado aquí.

// Computación sin servidor:
Anteriormente en este módulo has podido conocer Amazon EC2, un servicio que permite lanzar servidores virtuales en la nube. Si tienes aplicaciones que deseas iniciar en Amazon EC2, debes hacer lo siguiente:


1
Aprovisionar las instancias (servidores virtuales).

2
Cargar el código.

3
Seguir administrando las instancias mientras la aplicación está en uso.

El término "sin servidor" significa que el código se inicia en servidores, pero no es necesario aprovisionar ni administrar dichos servidores. Con la computación sin servidor, puedes centrarte más en innovar con productos y características nuevas, y no en el mantenimiento de los servidores.

Otro beneficio es la flexibilidad de escalar aplicaciones sin servidor automáticamente. La computación sin servidor puede ajustar la capacidad de las aplicaciones modificando las unidades de consumo, como el rendimiento y la memoria. 

Un servicio de AWS para la computación sin servidor es AWS Lambda.

AWS Lambda:

AWS Lambda es un servicio que permite iniciar código sin necesidad de aprovisionar ni administrar servidores. 

Cuando se utiliza AWS Lambda, solo se paga por el tiempo de computación que se consume. Los cargos solo se aplican cuando el código está en funcionamiento. También se puede iniciar código para prácticamente cualquier tipo de aplicación o servicio backend, todo sin necesidad de administración. 

Por ejemplo, una función Lambda sencilla podría implicar cambiar automáticamente el tamaño de las imágenes cargadas en la nube de AWS. En este caso, la función se activa cuando se carga una nueva imagen.

// Cómo funciona AWS Lambda:

Subes tu código a Lambda.

El código se configura para que se active desde una fuente de eventos, como servicios de AWS, aplicaciones móviles o puntos de enlace HTTP.

Lambda inicia el código solo cuando se activa.

Solo se paga por el tiempo de computación utilizado. En el ejemplo anterior de cambio de tamaño de imágenes, solo se pagaría por el tiempo de computación empleado en cargar imágenes nuevas. Al cargar las imágenes, Lambda inicia código para la función de cambio de tamaño de imagen.

//
En AWS, también puedes crear y lanzar aplicaciones en contenedores.

//
Contenedores

Los contenedores proporcionan una forma estándar de empaquetar el código y las dependencias de tu aplicación en un solo objeto. También puedes utilizarlos para procesos y flujos de trabajo en los que existan requisitos esenciales de seguridad, fiabilidad y escalabilidad.

//Resumen
Los servicios de organización de contenedores ayudan a implementar, administrar y escalar las aplicaciones en contenedores. A continuación, obtendrás información sobre dos servicios que facilitan la organización en contenedores: Amazon Elastic Container Service y Amazon Elastic Kubernetes Service.

//Amazon Elastic Container Service (Amazon ECS)

Amazon Elastic Container Service (Amazon ECS) es un sistema de administración de contenedores altamente escalable y de alto rendimiento que permite lanzar y escalar aplicaciones en contenedores en AWS. 

Amazon ECS admite contenedores Docker. Docker es una plataforma de software que permite crear, probar e implementar aplicaciones rápidamente. AWS admite el uso de Docker Community Edition (de código abierto) y Docker Enterprise Edition (de suscripción). Con Amazon ECS, puedes utilizar las llamadas a la API para lanzar y detener aplicaciones habilitadas para Docker.

Amazon Elastic Kubernetes Service (Amazon EKS)

Amazon Elastic Kubernetes Service (Amazon EKS) es un servicio totalmente administrado que se puede utilizar para lanzar Kubernetes en AWS. 

Kubernetes es un software de código abierto que permite implementar y administrar aplicaciones en contenedores a escala. Una gran comunidad de voluntarios mantiene Kubernetes y AWS colabora activamente en dicha comunidad. A medida que se publican nuevas características y funcionalidades para las aplicaciones de Kubernetes, se pueden aplicar fácilmente estas actualizaciones a las aplicaciones administradas por Amazon EKS.

// AWS Fargate:

AWS Fargate es un motor de computación sin servidor para contenedores. Funciona tanto con Amazon ECS como con Amazon EKS. 

Con AWS Fargate no es necesario aprovisionar ni administrar servidores. AWS Fargate administra la infraestructura de servidores por ti. Puedes centrarte más en innovar y desarrollar tus aplicaciones y solo pagarás por los recursos necesarios para lanzar tus contenedores.

/////
Resumen del módulo 2:

En el módulo 2 se han tratado los siguientes conceptos:

Tipos de instancias de Amazon EC2 y opciones de precios.
Amazon EC2 Auto Scaling.
Elastic Load Balancing.
Servicios de AWS para mensajería, contenedores y computación sin servidor.


///////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 3
////////////////////////////////////////////////////////////////////////////////////
Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Resumir los beneficios de la infraestructura global de AWS.
Describir el concepto básico de zonas de disponibilidad.
Describir los beneficios de las ubicaciones perimetrales y Amazon CloudFront.
Comparar los distintos métodos de aprovisionamiento de los servicios de AWS.

//
Quiero hablarte de la alta disponibilidad. Imaginemos que unos clientes quieren ir a la cafetería, pero hoy no es un día como cualquier otro. Hoy, un desfile va a pasar por nuestra calle para celebrar las migraciones maravillosas que se han hecho a la nube correctamente. Y va a pasar justo delante de la cafetería. Es genial. ¿A quién no le gusta mirar carrozas, globos, y que tiren caramelos por la calle? Pero no es tan genial porque mientras el desfile pasa por la calle, nuestros clientes, que vienen a tomar café, se tienen que desviar y no pueden pasar por la cafetería. Esto reduce las ventas y hace que los clientes no estén satisfechos. 



Por suerte, lo teníamos previsto. Hace mucho tiempo pensamos qué pasaría si, por alguna razón, nuestros clientes no pudieran entrar temporalmente en la cafetería. Es decir, ¿y si hubiera un desfile, una inundación o algún otro acontecimiento que les impidiese entrar? Bueno, no importa el motivo, tenemos que estar más que disponibles para nuestros clientes. 



Así que te contaré un secreto. Este no es el único establecimiento que tenemos. La cafetería es una cadena y tenemos locales por toda la ciudad. De esa forma, si hay un desfile por la calle o un corte de luz en nuestra zona, no pasa nada. Los clientes pueden tomarse un café si visitan una de nuestras tiendas a solo unas calles de aquí. Seguimos obteniendo beneficios y ellos se llevan su café. Todos ganamos. 



AWS ha hecho algo similar con la forma en que se configura la infraestructura global de AWS. No basta con tener un centro de datos gigante donde se encuentren todos los recursos. Si algo le ocurriera a ese centro de datos, como un corte de luz o un desastre natural, todas las aplicaciones se caerían a la vez. Se necesita una alta disponibilidad y tolerancia a errores. Resulta que ni siquiera basta con tener dos centros de datos gigantes. En cambio, AWS opera en todo tipo de áreas diferentes del mundo denominadas regiones. Vamos a profundizar sobre esto en los próximos vídeos. Mientras tanto, me quedo aquí tranquilo porque sé que mi empresa cuenta con una alta disponibilidad sin importar cuántos desfiles bloqueen la calle.

 - Creación de una huella global:
Para comprender la infraestructura global de AWS, piensa en la cafetería. Si algo, como un desfile, una inundación o un corte de energía, afecta a un sitio, los clientes pueden ir a por su café a otro sitio cercano.

La infraestructura global de AWS funciona de forma parecida.

//
Para comprender la infraestructura global de AWS, quiero empezar por tus necesidades empresariales básicas. (ráfaga de aire) Tienes una aplicación que lanzar, contenido que almacenar o datos que analizar. En resumen, tienes algo que almacenar y usar en algún lugar. Antes, las empresas tenían que lanzar aplicaciones en sus propios centros de datos porque no había otra opción. Ahora que pueden contar con AWS, empresas como la tuya pueden lanzarlas en centros de datos que no sean de su propiedad. 

Pero el tema va más allá de eso. Realmente, hay un problema fundamental con cualquier centro de datos, independientemente del creador o el propietario. Puede ocurrir algo que te haga perder la conexión con esas instalaciones. Si tienes un centro de datos propio, tienes que responder la pregunta de qué harías si ocurriera un desastre en las instalaciones. Podrías tener un segundo centro de datos, pero los precios inmobiliarios podrían ser un impedimento, además de todo el gasto duplicado de hardware, empleados, electricidad, climatización y seguridad. La mayoría de las empresas acaban guardando copias de seguridad donde sea con la esperanza de que no ocurra ningún desastre. Y la esperanza no es un buen plan. 

AWS responde a la pregunta de qué hacer ante un desastre: crear sus centros de datos en grupos grandes llamados "regiones". Ahora veremos cómo está planteado. 

En todo el mundo, (zumbido) AWS crea regiones para estar más cerca de la demanda de tráfico de la empresa. Ubicaciones como París, Tokio, São Paulo, Dublín u Ohio. En cada región, tenemos varios centros de datos con todos los servicios de computación, almacenamiento y otros necesarios para lanzar sus aplicaciones. Las regiones se pueden conectar entre sí a través de una red de fibra de alta velocidad controlada por AWS, una operación verdaderamente global de punto a punto si es necesario. (Zumbido) Antes de entrar en la arquitectura de la creación de cada región, es importante que sepas que, como decisor de tu empresa, puedes elegir qué regiones quieres usar. Cada región está aislada de las demás, en el sentido de que ningún dato entra ni sale de tu entorno en esa región si no concedes explícitamente permiso para traspasar esos datos. Es una decisión fundamental de seguridad que hay que tomar. 

Imaginemos que tienes que cumplir la norma de conformidad gubernamental de que tu información financiera en Fráncfort no puede salir de Alemania. Pues es así como funciona AWS de modo predeterminado. Lo guardado en la región de Fráncfort no sale de esa región, como los datos de la región de Londres tampoco salen nunca de allí, o los de Sídney nunca salen de allí, salvo que solicites explícitamente, con las credenciales y los permisos correctos, que se exporten los datos. 

La soberanía de los datos regionales es parte del diseño básico de las regiones de AWS. Y los datos quedan sujetos a las leyes y estatutos locales del país donde se encuentra la región. Sabiendo esto, que tus datos y tus aplicaciones, están y se lanzan en una región, una de las primeras decisiones que debes tomar es qué región elegir. Hay cuatro factores empresariales que tener en cuenta al elegir una región. 

Primero: conformidad. Antes de cualquier otro factor, primero debes tener en cuenta los requisitos de conformidad. ¿Alguno de ellos dictamina que los datos deben estar alojados en Reino Unido? Entonces hay que elegir la región de Londres. Punto. El resto de las opciones no importan. O digamos que debes alojarlos en territorio chino. En ese caso, hay que elegir una de nuestras regiones de China. Sin embargo, la mayoría de las empresas no se rigen por regulaciones tan estrictas. Así que, si no estás sujeto a controles normativos o de conformidad que supediten a una región, puedes considerar otros factores. 

Segundo: proximidad. La cercanía a tus clientes es importante porque la velocidad de la luz sigue siendo una ley universal. Si la mayoría de tus clientes viven en Singapur, es recomendable que elijas la región de Singapur. Puedes elegir la de Virginia, pero el tiempo que tarda en enviarse la información, o la latencia, entre Estados Unidos y Singapur siempre será un factor. La computación cuántica está en desarrollo, pero todavía falta mucho para las redes cuánticas. El tiempo que tarda la luz en viajar por todo el mundo siempre se debe tener en cuenta. Ubicarse cerca de sus clientes suele ser lo correcto. 

Tercero: características disponibles. A veces, puede que la región más cercana no tenga todas las características de AWS que deseas. Pero este es uno de los aspectos interesantes de AWS. Innovamos constantemente para nuestros clientes. Cada año, AWS lanza miles de características y productos para responder a las peticiones y necesidades de los clientes. Sin embargo, a veces, esos servicios necesitan mucho hardware físico nuevo que AWS tiene que crear para que el servicio funcione. Y, a veces, eso significa que tenemos que crear el servicio región a región. Supongamos que tus desarrolladores quisieran probar Amazon Braket, la nueva plataforma de computación cuántica. En ese caso, tendrían que escoger las regiones con el hardware ya instalado. ¿Cabría esperar que esté en todas las regiones en algún momento? Es bueno tener esperanza, pero si quieres usarlo hoy, podría ser un factor decisivo. 

Cuarto: precios. Incluso cuando el hardware es el mismo en varias regiones, es más caro operar en algunas ubicaciones como Brasil. Debido a la fiscalidad de Brasil, a AWS le cuesta mucho más operar los mismos servicios allí que en muchos otros países. Una carga de trabajo en São Paulo podría ser, digamos, un 50 % más cara de lanzar que en Oregón, en Estados Unidos. Muchos factores influyen en el precio, por lo que AWS ofrece precios granulares muy transparentes de los que seguiré hablando en esta clase. Pero debes saber que cada región tiene una hoja de precios distinta. Si el presupuesto es clave para ti, aunque tus clientes estén en Brasil, sería recomendable que operes en otro país. Insisto, si el precio es un factor decisivo. 

Repasemos los cuatro factores clave para elegir región: conformidad, proximidad, características disponibles y precios. Cuando volvamos, veremos las peculiaridades de las regiones.

//Selección de una región

Al determinar la región adecuada para tus servicios, datos y aplicaciones, ten en cuenta los siguientes cuatro factores empresariales. 

Para obtener más información, selecciona el símbolo + que aparece junto a cada categoría.

// Conformidad con los requisitos legales y de gestión de datos
–
Según tu empresa y tu ubicación, es posible que tengas que ejecutar los datos en áreas específicas. Por ejemplo, si tu empresa requiere que todos tus datos se encuentren dentro de los límites del Reino Unido, elegiría la región de Londres. 

No todas las empresas tienen regulaciones de datos relacionadas con la ubicación, por lo que es posible que tengas que centrarte más en los otros tres factores.

// Proximidad a tus clientes
–
Seleccionar una región cercana a tus clientes te ayudará a enviarles contenido más rápido. Por ejemplo, tu empresa tiene sede en Washington, DC, y muchos de tus clientes viven en Singapur. Puedes considerar la posibilidad de ejecutar tu infraestructura en la región de Virginia del Norte para estar cerca de la sede de la empresa y ejecutar tus aplicaciones desde la región de Singapur.

// Servicios disponibles dentro de una región
–
A veces, es posible que la región más cercana no tenga todas las características que deseas ofrecer a los clientes. AWS innova con frecuencia creando nuevos servicios y ampliando las características de los servicios existentes. No obstante, para que los nuevos servicios puedan estar disponibles en todo el mundo, a veces es necesario que AWS desarrolle hardware físico región a región. 

Supongamos que tus desarrolladores quieren crear una aplicación que utilice Amazon Braket (plataforma de computación cuántica de AWS). En este curso, Amazon Braket aún no está disponible en todas las regiones de AWS del mundo, por lo que tus desarrolladores tendrían que ejecutarlo en una de las regiones que ya lo ofrecen.

// Precios
–
Supongamos que estás pensando ejecutar aplicaciones tanto en Estados Unidos como en Brasil. Por cómo está establecida la estructura tributaria de Brasil, podría costar un 50 % más ejecutar la misma carga de trabajo en la región de São Paulo que en la región de Oregón. Sabrás con más detalle que varios factores determinan los precios, pero por ahora no olvides que el coste de los servicios puede variar de una región a otra.

/////////////
Si una región es donde están todas las partes de tus aplicaciones, podríamos pensar que eso no resuelve el problema que presentamos en el último vídeo. Voy a replantear el problema. No es recomendable ejecutar la aplicación en un solo lugar porque esas instalaciones pueden fallar por motivos inevitables. 

Quizá pienses: "si quiero proteger mi negocio ante desastres, no puede estar en un solo lugar". Tienes toda la razón. AWS opina igual. Por eso, nuestras regiones no tienen una sola ubicación. Para empezar, AWS tiene centros de datos, muchos centros de datos, en todo el mundo y cada región está compuesta por varios centros de datos. AWS denomina a un solo centro de datos o a un grupo de centros de datos zona de disponibilidad, o AZ. Cada zona de disponibilidad es uno o más centros de datos distintos con alimentación, redes y conectividad redundantes. Al lanzar una instancia de Amazon EC2, esta lanza una máquina virtual en un hardware físico instalado en una zona de disponibilidad. Esto significa que cada región consta de varias zonas de disponibilidad aisladas y físicamente independientes dentro de una región geográfica. 

Pero no creamos zonas de disponibilidad una junto a otra porque, si se produjera un incidente a gran escala, como un desastre natural, podrías perder la conectividad a todo en esa zona de disponibilidad. Qué ocurre en caso de desastre es un tema importante y, si sabes sobre planificación de recuperación de desastres, puede que tengas una idea de adónde quiero llegar. 

Si solo ejecutas una instancia EC2, solo se ejecuta en un sitio físico o en una zona de disponibilidad. Si ocurre un desastre a gran escala, ¿tus aplicaciones seguirían ejecutándose y sirviendo a tu empresa? La solución obvia es ejecutar varias instancias EC2, tal y como mostramos en el ejemplo anterior de escalado. Pero lo fundamental es no ejecutarlas en las mismas instalaciones. Ni siquiera las ejecutes en la misma calle, aléjalas lo más que puedas antes de que la velocidad de la luz te indique que te detengas si quieres una comunicación de baja latencia. Resulta que la velocidad de la luz nos permitirá separar estas zonas de disponibilidad a decenas de km entre sí y mantener una latencia de menos de 10 milisegundos entre esas zonas. Si se produce un desastre, tus aplicaciones no se inmutarán, ya que este desastre solo habrá afectado a una parte de tu capacidad. 

Como hemos visto en la última sección, puedes aumentar rápidamente la capacidad en el resto de las zonas de disponibilidad, lo que permite que tus empresas sigan funcionando sin interrupciones. También, al usar AWS te recomendamos que uses al menos dos zonas de disponibilidad de una región. Es decir, que implementes tu infraestructura de modo redundante en dos AZ diferentes. 

Además, las regiones son más que lugares para ejecutar EC2. Muchos de los servicios de AWS se ejecutan a nivel de región, es decir, se ejecutan de forma síncrona en varias AZ sin que tengas que hacer nada. Veámoslo con ELB, algo de lo que ya hemos hablado. Es un constructo regional. Se ejecuta en todas las AZ comunicándose con las instancias EC2 que se ejecutan en una zona de disponibilidad específica. Los servicios regionales son de por sí altamente disponibles sin coste adicional y sin que tengas que hacer nada. 

Si tus planes incluyen alta disponibilidad, debes saber que todos los servicios de ámbito regional ya tienen esa característica. Cuando volvamos, hablaremos de salir de las regiones para encontrar soluciones adicionales.

///////
Zonas de disponibilidad :
///////

Una zona de disponibilidad es un centro de datos único o un grupo de centros de datos dentro de una región. Las zonas de disponibilidad están ubicadas a decenas de kilómetros de distancia entre sí. Esto está lo suficientemente cerca como para tener baja latencia (el tiempo transcurrido entre el momento en que se solicita y se recibe el contenido) entre las zonas de disponibilidad. Sin embargo, si se produce un desastre en una parte de la región, están lo suficientemente separadas como para reducir la posibilidad de que se vean afectadas varias zonas de disponibilidad.

//////
Lanzar instancias de Amazon EC2 en varias zonas de disponibilidad:
Supongamos que lanzas una aplicación en una única instancia de Amazon EC2 en la región del Norte de California. La instancia se lanza en la zona de disponibilidad us-west-1a. Si us-west-1a fallara, perderías tu instancia.

/// 
Instancias de Amazon EC2 en varias zonas de disponibilidad:
Una práctica recomendada consiste en lanzar aplicaciones en al menos dos zonas de disponibilidad de una región. En este ejemplo, puedes elegir lanzar una segunda instancia de Amazon EC2 en us-west-1b.

/// 
Error en la zona de disponibilidad :
Si us-west-1a fallara, tu aplicación seguiría en funcionamiento en us-west-1b.

///////////
Resumen
La planificación de errores y la implementación de aplicaciones en varias zonas de disponibilidad son una parte importante de la creación de una arquitectura resistente y de alta disponibilidad.

/////////////////
Ubicaciones perimetrales
///////////////
Una muy buena característica de la infraestructura global de AWS es cómo está diseñada para ayudarte a atender mejor a tus clientes. Recordemos que, para elegir región, uno de los principales criterios es la proximidad a tus clientes, pero ¿qué pasa si tienes clientes en todo el mundo o en ciudades alejadas de una de nuestras regiones? Volvamos a la cafetería. Si tienes una buena cartera de clientes en una ciudad nueva, puedes construir un local satélite para atender a esos clientes. 

No necesitas construir una nueva sede. Llevemos el ejemplo a las TI: si tienes clientes en Bombay que necesitan acceder a tus datos, pero los datos se alojan en la región de Tokio, en lugar de hacer que todos los clientes de Bombay envíen solicitudes a Tokio para acceder a los datos, es mejor tener una copia local o almacenarla en caché en Bombay. Para almacenar en caché copias de datos más cerca de los clientes en todo el mundo, se usan las redes de entrega de contenido (CDN). 

Las CDN se usan habitualmente y la nuestra se llama Amazon CloudFront. Amazon CloudFront es un servicio que ayuda a entregar datos, vídeo, aplicaciones y API a clientes de todo el mundo con baja latencia y altas velocidades de transferencia. Amazon CloudFront utiliza ubicaciones perimetrales en todo el mundo para acelerar la comunicación con los usuarios, sin importar dónde se encuentren. Además, son independientes de las regiones. De este modo, puedes enviar contenido desde una región a numerosas ubicaciones perimetrales en todo el mundo para comunicarte y entregar contenido más rápido. 

Las ubicaciones perimetrales de AWS no solo se usan con CloudFront. Utilizan un servicio de nombres de dominio, o DNS, conocido como Amazon Route 53. Ayudamos a dirigir a los clientes hacia las ubicaciones web correctas, con una latencia baja y fiable. 

Pero ¿qué pasa si tu empresa quiere usar servicios de AWS en sus instalaciones? Pues que pueden. AWS ofrece ese servicio. Se llama AWS Outposts y consiste en que AWS instala una miniregión totalmente operativa en el centro de datos de tu empresa. Es de AWS, que también la opera, con toda la funcionalidad de AWS, pero aislada en tus instalaciones. No es lo que la mayoría necesita, pero si tienes cuestiones específicas que solo se pueden resolver en tus instalaciones, esta puede ser una opción adecuada. (Suspira) 

Bien. podemos decir mucho más sobre la infraestructura global de AWS, pero vamos a dejarlo así. Repasemos los puntos clave. Primero: las regiones son áreas aisladas geográficamente en las que puedes acceder a los servicios para que tu empresa funcione. Segundo: las regiones contienen zonas de disponibilidad, que te permiten usar instalaciones separadas físicamente por decenas de kilómetros y, a la vez, mantener tus aplicaciones unificadas lógicamente. Las zonas de disponibilidad ayudan a ofrecer alta disponibilidad y a recuperarse de desastres sin que tengas que hacer nada. Y tercero: las ubicaciones perimetrales de AWS utilizan Amazon CloudFront para acercar el contenido a tus clientes, sin importar en qué parte del mundo estén.


///////
Ubicaciones perimetrales

Una ubicación perimetral es un sitio que Amazon CloudFront utiliza para almacenar copias de tu contenido más cerca de tus clientes para una entrega más rápida.

Selecciona cada marcador para obtener más información.

/////////
Cómo aprovisionar recursos de AWS
////////
Hemos hablado de varios recursos de AWS y de la infraestructura global de AWS. Puede que te preguntes: "¿cómo se interactúa con estos servicios?" La respuesta es: "con las API". En AWS, todo es una llamada a API. Una API es una interfaz de programación de aplicaciones. Esto significa que hay modos predeterminados de interactuar con los servicios de AWS. Puedes invocar o hacer llamadas a estas API para aprovisionar, configurar y administrar recursos de AWS. 

Por ejemplo, puedes lanzar una instancia EC2 o crear una función de AWS Lambda. Cada una sería una solicitud y una llamada distinta a la API de AWS. Puedes usar la AWS Management Console, la interfaz de línea de comandos de AWS, los kits de desarrollo de software u otras herramientas, como AWS CloudFormation, para crear y enviar solicitudes a las API y, así, generar y gestionar recursos de AWS. 

Primero, hablemos de la AWS Management Console. Se basa en el navegador y con ella puedes administrar los recursos de AWS de forma visual y sencilla. Es ideal para empezar e ir aprendiendo sobre los servicios. También es útil para crear entornos de prueba, ver facturas de AWS o el seguimiento, y trabajar con otros recursos no técnicos. Esta consola será seguramente el primer lugar al que irás cuando estés aprendiendo sobre AWS. 

Sin embargo, cuando tengas en marcha un entorno de producción, es mejor no contar tanto con el estilo visual de la consola a la hora de crear y administrar tus recursos de AWS. Por ejemplo, para crear una instancia EC2, debes hacer clic en varias pantallas, definir la configuración que quieras y, después, lanzar la instancia. Si más tarde quieres lanzar otra instancia EC2, tendrías que volver a la consola y hacer clic de nuevo en esas pantallas para ponerla en marcha. Si el aprovisionamiento lo hacen personas manualmente, aumenta la probabilidad de que haya errores. Es muy fácil olvidarse de marcar una casilla de verificación o escribir mal algo cuando se hace todo manualmente. 

La solución es utilizar herramientas para crear scripts que hagan llamadas a la API o programarlas. Una de esas herramientas es AWS Command Line Interface (CLI). La CLI permite hacer llamadas a la API mediante el terminal de tu equipo. Es distinto del estilo de navegación visual de la AWS Management Console. Escribir comandos con la CLI permite crear acciones codificables y repetibles. Así, puedes escribir y usar comandos para lanzar una instancia EC2. Si quieres lanzar otra, puedes volver a usar el comando ya escrito. Esto reduce la probabilidad de que haya errores humanos. Y puedes hacer que los scripts se lancen automáticamente, por ejemplo, según una programación o que los active otro proceso. 

La automatización es clave para que la implementación en la nube sea correcta y predecible a lo largo del tiempo. Otra forma de interactuar con AWS es a través de los kits de desarrollo de software (SDK) de AWS. Los SDK permiten interactuar con los recursos de AWS mediante lenguajes de programación. Esto facilita a los desarrolladores crear programas que utilizan AWS sin tener que usar las API de bajo nivel, y que no tengan que crear recursos manualmente como acabo de explicar. Profundizaremos en eso luego.


//////
Formas de interactuar con los servicios de AWS:

Para obtener más información sobre una categoría, selecciona la pestaña correspondiente.

//////
AWS Management Console:
//////
AWS Management Console es una interfaz basada en la web para acceder y administrar los servicios de AWS. Puedes acceder rápidamente a los servicios utilizados recientemente y buscar otros servicios por nombre, palabra clave o acrónimo. La consola incluye asistentes y flujos de trabajo automatizados que pueden simplificar el proceso de realización de tareas.

También puedes utilizar la aplicación móvil de AWS Console para realizar tareas como supervisar recursos, ver alarmas y acceder a la información de facturación. En la aplicación móvil de AWS Management Console pueden permanecer iniciadas varias identidades al mismo tiempo.

///// 
AWS Command Line Interface (AWS CLI) :

Para ahorrar tiempo al realizar peticiones de API, puedes utilizar AWS Command Line Interface (AWS CLI). AWS CLI te permite controlar varios servicios de AWS directamente desde la línea de comando en una herramienta. AWS CLI está disponible para los usuarios en Windows, macOS y Linux. 

Mediante AWS CLI, puedes automatizar las acciones que realizan tus servicios y aplicaciones mediante scripts. Por ejemplo, puedes utilizar comandos para lanzar una instancia de Amazon EC2, conectar una instancia de Amazon EC2 a un grupo de Auto Scaling específico y mucho más.

//////
kits de desarrollo de software (SDK)
/////
Otra opción para acceder a los servicios de AWS y administrarlos son los kits de desarrollo de software (SDK). Los SDK te facilitan el uso de los servicios de AWS a través de una API diseñada para tu lenguaje de programación o plataforma. Los SDK te permiten utilizar los servicios de AWS con sus aplicaciones existentes o crear aplicaciones completamente nuevas que se ejecutarán en AWS.

Para ayudarte a empezar a utilizar los SDK, AWS proporciona documentación y código de muestra para cada lenguaje de programación compatible. Entre los lenguajes de programación compatibles se incluyen C++, Java, .NET y muchos más.

//////////
COMO APROVISIONAR RECURSOS DE AWS
/////////

Muy bien, sigamos hablando sobre cómo interactuar con AWS. Tenemos la AWS Management Console, la CLI y los SDK, que te permiten aprovisionar y administrar tus entornos de AWS. Para aprovisionar un recurso, puedes iniciar sesión en la consola y hacerlo con clics, escribir comandos o escribir programas para hacerlo. Hay otras formas de administrar tus entornos de AWS con herramientas de administración, como AWS Elastic Beanstalk o AWS CloudFormation. 

AWS Elastic Beanstalk es un servicio que ayuda a aprovisionar entornos basados en Amazon EC2. En lugar de hacer clic en la consola o escribir varios comandos para crear las redes, instancias EC2, el escalado y Elastic Load Balancers, puedes proporcionar el código de tu aplicación y la configuración que quieras al servicio AWS Elastic Beanstalk, que, con esa información, crea el entorno. Con Elastic Beanstalk, también es fácil almacenar configuraciones del entorno para volver a implementarlas fácilmente. AWS Elastic Beanstalk ofrece la comodidad de no tener que aprovisionar y administrar todo esto por separado, al tiempo que permite ver y controlar los recursos subyacentes. Así, puedes centrarte en tus aplicaciones en lugar de en la infraestructura. 

Otro servicio que puedes usar para crear implementaciones automatizadas y repetibles es AWS CloudFormation. AWS CloudFormation es una herramienta de infraestructura como código que permite definir distintos recursos de AWS de forma declarativa mediante documentos basados en texto JSON o YAML, llamados plantillas de CloudFormation. Un formato declarativo como este te permite definir lo que quieres crear sin especificar los detalles de cómo crearlo. CloudFormation te permite definir qué quieres y el motor de CloudFormation se encarga de los detalles, y hace las llamadas a las API para crear lo que hayas definido. 

Además, no se limita a soluciones básicas de EC2. CloudFormation se puede usar con muchos recursos de AWS distintos como almacenamiento, bases de datos, análisis o machine learning. Una vez definidos los recursos en una plantilla de CloudFormation, CloudFormation la analizará y aprovisionará en paralelo estos recursos que has definido. CloudFormation gestiona las llamadas a las API del backend de AWS. Puedes utilizar la misma plantilla de CloudFormation en varias cuentas o regiones y creará entornos idénticos en ellas. Así, hay menos margen de error, ya que es un proceso automatizado. 

En resumen, la AWS Management Console es ideal para aprender y como referencia visual. Es manual, así que, en sí, no es la mejor opción para automatizar. En su lugar, puedes usar la CLI para programar tus interacciones con AWS mediante el terminal, los SDK para escribir programas que interactúen con AWS, o herramientas de administración como AWS Elastic Beanstalk o AWS CloudFormation.


////////
AWS Elastic Beanstalk
/////////

Con AWS Elastic Beanstalk, el usuario proporciona ajustes de código y configuración, y Elastic Beanstalk implementa los recursos necesarios para realizar las siguientes tareas:

-Ajuste de la capacidad.
-Equilibrio de carga.
-Escalado automático.
-Seguimiento del estado de las aplicaciones.

////////
AWS CloudFormation
////////
Con AWS CloudFormation, puedes tratar tu infraestructura como código. Esto significa que puedes crear un entorno escribiendo líneas de código en lugar de utilizar la AWS Management Console para aprovisionar recursos individualmente.

AWS CloudFormation proporciona tus recursos de forma segura y repetible, lo que te permite crear con frecuencia tu infraestructura y aplicaciones sin tener que realizar acciones manuales ni escribir scripts personalizados. Determina las operaciones correctas que deben realizarse al administrar la pila y deshace los cambios automáticamente si detecta errores.

///////
Resumen del módulo 3
En el módulo 3 se han tratado los siguientes conceptos:

Regiones y zonas de disponibilidad.
Ubicaciones perimetrales y Amazon CloudFront.
AWS Management Console, AWS CLI y SDK.
AWS Elastic Beanstalk.
AWS CloudFormation.

///
Cuántas cosas increíbles. Hemos abarcado muchos temas. No solo hemos hablado sobre la infraestructura global de AWS. 

También hemos hablado sobre cómo los clústeres lógicos de los centros de datos constituyen las zonas de disponibilidad que, a su vez, forman regiones que están por todo el mundo. Luego, hablamos de elegir las regiones y zonas de disponibilidad que quieras usar y sobre la recomendación de siempre implementar la infraestructura en al menos dos zonas de disponibilidad. Y de que algunos servicios de AWS, como Elastic Load Balancing, Amazon SQS y Amazon SNS lo hacen por ti. 

Hablamos de las ubicaciones perimetrales y de cómo implementarles contenido para acelerar las entregas a tus clientes. Incluso hemos abordado soluciones como AWS Outposts, útiles para usar infraestructura de AWS directamente en tus centros de datos. 

Otro tema visto es cómo aprovisionar recursos de AWS con medios como la AWS Management Console, los SDK, la CLI, AWS Elastic Beanstalk o AWS CloudFormation, donde ya sabes cómo se configura la infraestructura como código. 

Espero que ahora sepas lo disponible que está AWS en todo el mundo y lo fácil que es comenzar a aprovisionar recursos.


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
Introducción al módulo 4
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Describir los conceptos básicos de las redes.
Describir la diferencia entre los recursos de redes públicas y privadas. 
Explicar una puerta de enlace privada virtual utilizando una situación real. 
Explicar una red privada virtual (VPN) utilizando una situación real.
Describir los beneficios de AWS Direct Connect. 
Describir los beneficios de las implementaciones híbridas. 
Describir las capas de seguridad utilizadas en una estrategia de TI.
Describir los servicios que utilizan los clientes para interactuar con la red global de AWS.


////
Si volvemos al ejemplo de la cafetería como cuenta de AWS, ahora mismo todo debería ir bien. Pero ¿y si tuviéramos algunos clientes con prisa que quieren hacer sus pedidos directamente a los baristas en lugar de en la caja? Bueno, no tiene sentido permitir que cada cliente pueda interactuar con los baristas, ya que ellos se centran en preparar las bebidas con cafeína. Entonces, ¿qué hacemos? 

Así es. Repite conmigo: "Amazon Virtual Private Cloud", o VPC, como le llamamos nosotros. VPC te permite aprovisionar una sección lógicamente aislada de la nube de AWS donde puedes lanzar recursos de AWS en la red virtual que indiques. Estos recursos pueden ser públicos para que tengan acceso a Internet, o privados, sin acceso a Internet, generalmente para servicios de backend como bases de datos o servicios de aplicaciones. La agrupación pública y privada de recursos se conoce como subredes y son rangos de direcciones IP de tus VPC. 

Ahora, en nuestra cafetería, tenemos varios tipos de empleados y uno de ellos es el cajero. Reciben los pedidos de los clientes y, por eso, queremos que los clientes interactúen con ellos, así que los metemos en lo que llamamos una subred pública. Por lo tanto, pueden hablar con los clientes, que serían como Internet. Pero respecto a nuestros baristas, queremos que se centren en hacer café y no interactúen directamente con los clientes, así que los metemos en una subred privada. 

Bien, veamos el siguiente vídeo en el que nos adentraremos en las redes. 


/////////
Conectividad con AWS
///////
Una VPC, o nube virtual privada, es, básicamente, tu propia red privada en AWS. La VPC te permite definir el rango de IP privadas para tus recursos de AWS y añadir elementos como instancias EC2 y ELB a esa VPC. 

Pero los recursos no se añaden así sin más a la VPC. Debes añadirlos a distintas subredes. Las subredes son fragmentos de direcciones IP de la VPC que te permiten agrupar recursos. Las subredes, junto con las reglas de redes, que veremos luego, controlan si los recursos están disponibles de forma pública o privada. Lo que aún no hemos comentado es que hay varias formas de controlar qué tráfico entra en tu VPC. Es decir, en algunas VPC, quizá tengas recursos para Internet a los que el público pueda acceder, como un sitio web público. 

Sin embargo, en otros casos, quizá tengas recursos a los que quieres que solo accedan quienes inicien sesión en tu red privada. Puede tratarse de servicios internos, como una aplicación de recursos humanos o una base de datos backend. Primero, hablemos de recursos para el público. Para permitir que el tráfico del Internet público entre y salga de tu VPC, debes adjuntar a esa VPC lo que se denomina puerta de enlace de Internet (IGW). 

Una puerta de enlace de Internet es como un acceso para el público. Volvamos a la cafetería. Sin una puerta principal, los clientes no pueden entrar y pedir café, así que ponemos una para que los clientes puedan entrar y salir de la cafetería a través de ella. La puerta de este ejemplo es como una puerta de enlace de Internet. Sin ella, no se puede acceder a los recursos que hay en la VPC. 

Ahora hablemos de una VPC con recursos internos privados. No queremos que quien sea desde cualquier sitio acceda a estos recursos. Así que no queremos una puerta de enlace de Internet adjunta a la VPC, sino una puerta de enlace privada que solo permita entrar a quienes vengan de una red admitida, no del Internet público. Esta puerta privada se denomina puerta de enlace privada virtual y te permite crear una conexión de VPN entre una red privada, como tu centro de datos propio o una red corporativa interna, y tu VPC. 

Volviendo a la cafetería, sería como tener una ruta de autobús privada desde mi edificio hasta allí. Si quiero ir a tomar un café, me identifico en el edificio autenticando mi identidad y hago la ruta secreta con el bus hasta la cafetería interna a la que solo los del edificio pueden ir. 

Por lo tanto, si quieres crear una conexión de VPN cifrada a tus recursos de AWS internos privados, debes adjuntar una puerta de enlace privada virtual a tu VPC. Ahora el problema de la ruta supersecreta del bus es que va por vías públicas. Puede verse envuelto en atascos o ir más lento debido a que los demás también están circulando. Lo mismo ocurre con las conexiones de VPN. Son privadas y están cifradas, pero siguen utilizando una conexión a Internet normal con un ancho de banda que comparten muchas personas que usan Internet. Así que lo que hacemos para que la ruta sea más fiable y no haya riesgo de ralentización es crear una puerta mágica separada que conecte directamente el estudio (sonido mágico) con la cafetería. Nadie más en la carretera nos retrasará gracias a esta puerta directa que nadie más puede usar. ¿Cómo? ¿No tienes una puerta mágica secreta para ir a tu cafetería favorita? Vale, sigamos. (Se cierra la puerta mágica). La solución ideal es una conexión privada, pero exclusiva, que no se comparta con nadie más. Que tenga la menor latencia posible y, a la vez, la mayor seguridad posible. 

Con AWS, puedes conseguirla utilizando AWS Direct Connect. Direct Connect te permite crear una conexión de fibra totalmente privada y exclusiva entre tus centros de datos y AWS. Trabajarás con un socio de Direct Connect en tu zona para crear esa conexión porque, al igual que mi puerta mágica, AWS Direct Connect te proporciona una línea física que conecta las redes a tu VPC de AWS. Esto te ayudará a satisfacer exigencias normativas y de conformidad, y a eludir cualquier problema posible con el ancho de banda. También debes saber que una VPC puede tener varios tipos de puertas de enlace adjuntas para varios tipos de recursos. Todos en la misma VPC, pero en subredes distintas. 

Gracias por asistir. Yo me quedo aquí pidiendo cafés a través de mi puerta mágica. ¡Nos vemos!

////////
Amazon Virtual Private Cloud (Amazon VPC)
///////

Imagine los millones de clientes que utilizan los servicios de AWS. Además, imagine los millones de recursos que han creado dichos clientes, como las instancias de Amazon EC2. Sin límites en torno a todos estos recursos, el tráfico de red podría fluir entre ellos sin restricciones. 

Un servicio de redes que se puede utilizar para establecer límites en torno a los recursos de AWS es Amazon Virtual Private Cloud (Amazon VPC).

Amazon VPC permite aprovisionar una sección aislada de la nube de AWS. En esta sección aislada, puedes lanzar recursos en una red virtual definida. Dentro de una Virtual Private Cloud (VPC), puedes organizar los recursos en subredes. Una subred es una sección de una VPC que puede contener recursos como instancias de Amazon EC2.

///////////
Puerta de enlace de Internet
/////////
Para permitir que el tráfico público de Internet acceda a tu VPC, debes conectar una puerta de enlace de Internet a la VPC.

Una puerta de enlace de Internet es una conexión entre una VPC e Internet. Podemos imaginar que es como la puerta que utilizan los clientes para entrar a la cafetería. Sin una puerta de enlace de Internet, nadie puede acceder a los recursos de tu VPC.

///
¿Qué ocurre si tienes una VPC que incluye solo recursos privados?
///

/////////
Puerta de enlace privada virtual
////////

Para acceder a los recursos privados de una VPC, puedes utilizar una puerta de enlace privada virtual. 

A continuación se muestra un ejemplo de cómo funciona una puerta de enlace privada virtual. Puedes imaginarte que Internet es como el camino entre tu casa y la cafetería. Supongamos que viajas por esta carretera con un guardaespaldas que te protege. Sigues utilizando la misma carretera que otros clientes, pero con una capa adicional de protección. 

El guardaespaldas es como una conexión de red privada virtual (VPN) que cifra (o protege) tu tráfico de Internet de todas las demás peticiones que lo rodean. 

La puerta de enlace privada virtual es el componente que permite que el tráfico de Internet protegido entre en la VPC. Aunque tu conexión a la cafetería tiene protección adicional, es posible que se produzcan atascos porque estás utilizando la misma carretera que otros clientes.

Una puerta de enlace privada virtual permite establecer una conexión de red privada virtual (VPN) entre la VPC y una red privada, como un centro de datos en las instalaciones o una red corporativa interna. Una puerta de enlace privada virtual permite el tráfico en la VPC solo si procede de una red aprobada.

//////////
AWS Direct Connect
///////

AWS Direct Connect es un servicio que permite establecer una conexión privada dedicada entre un centro de datos y una VPC.  

Supongamos que hay un edificio de apartamentos con un pasillo que conecta directamente el edificio con la cafetería. Solo los residentes del edificio de apartamentos pueden utilizar este pasillo. 

Este pasillo privado proporciona el mismo tipo de conexión dedicada que AWS Direct Connect. Los residentes pueden entrar en la cafetería sin necesidad de utilizar la vía pública compartida con otros clientes.

La conexión privada que proporciona AWS Direct Connect ayuda a reducir los costes de red y aumentar la cantidad de ancho de banda que puede viajar a través de tu red.

///////
Subredes y listas de control de acceso a la red :
///////

Hablemos de la VPC. Es como una robusta fortaleza donde nada entra o sale sin permiso explícito. La VPC tiene una puerta de enlace que solo permite el tráfico dentro o fuera de la VPC. Pero eso solo abarca el perímetro y es solo una parte de la seguridad de red en la que deberías centrarte como parte de tu estrategia de TI. 

AWS tiene muchas herramientas para cada capa de seguridad: seguridad de redes y de aplicaciones, identidad de usuarios, autenticación y autorización, denegación de servicio distribuido (DDoS) o prevención de estos ataques, integridad de datos, cifrado y más. Vamos a hablar de algunas de estas piezas clave. Para saber más sobre seguridad, visita los enlaces que se indican en esta página para obtener más información y formación sobre cómo asegurar la infraestructura como si fuera la receta de croquetas de tu abuela. Un tesoro a buen recaudo. Hoy quiero hablar de algunos aspectos del fortalecimiento de redes analizando lo que sucede en la VPC. La única razón técnica para utilizar subredes en una VPC es controlar el acceso a puertas de enlace. Las subredes públicas tienen acceso a la puerta de enlace de Internet; las subredes privadas, no. Pero las subredes pueden controlar los permisos de tráfico. Los paquetes son mensajes de Internet y cada paquete que cruza los límites de la subred se comprueba con algo llamado lista de control de acceso a la red o ACL de red (NACL). Esta comprobación sirve para ver si el paquete tiene permisos para salir o entrar en la subred en función de quién lo envió y cómo intenta comunicarse. 

Las ACL de red son como agentes de control de pasaportes. Quien esté en la lista de admitidos podrá entrar. Quien no esté en la lista o esté en la lista de no admitidos no podrá entrar. Las ACL de red comprueban el tráfico que entra y sale de su subred, como los agentes de control de pasaportes. La lista se comprueba cuando alguien entra en un país y cuando sale. Que dejen entrar a alguien no significa necesariamente que le vayan a dejar salir. El tráfico aprobado se puede enviar y el tráfico potencialmente dañino, como los intentos de controlar sistemas mediante solicitudes administrativas, se bloquea antes de alcanzar el objetivo. Así, los piratas no pueden acceder. 

Parece un buen sistema de seguridad, pero no soluciona los problemas de control de redes porque las ACL de red solo pueden evaluar un paquete si cruza el límite de la subred, ya sea al entrar o salir. No evalúa si un paquete puede llegar a una instancia EC2 específica o no. A veces, tendrás varias instancias EC2 en una misma subred, pero pueden tener reglas distintas sobre quién puede enviar los mensajes y a qué puerto se les permite enviarlos. Por lo tanto, también necesitas seguridad de red en instancias. 

Para proteger el acceso a instancias tenemos grupos de seguridad. Cuando se lanza una instancia EC2, va directamente al grupo de seguridad. De forma predeterminada, el grupo de seguridad no permite ningún tráfico hacia la instancia. Los puertos están bloqueados; todas las direcciones IP que envían paquetes están bloqueadas. Es muy seguro, pero no muy útil. Si quieres que una instancia acepte tráfico desde el exterior, como un mensaje de una instancia de frontend o de Internet, evidentemente, puedes modificar el grupo de seguridad para que acepte ese tipo de tráfico. En un sitio web, aceptarías el tráfico basado en la web o HTTPS, pero no otros tipos de tráfico, como solicitudes de sistemas operativos o administrativas. 

Si las NACL son agentes de control de pasaportes, los grupos de seguridad son como el portero de un edificio y el edificio sería la instancia EC2 en este ejemplo. El portero mira la lista para comprobar que quien quiera entrar al edificio pueda, pero no revisa la lista cuando esta persona sale. Con los grupos de seguridad, se permite la entrada de tráfico concreto y, de forma predeterminada, también la salida de todo el tráfico. 

Ahora estarás pensando: "Acaba de describir dos motores distintos que hacen exactamente lo mismo... permitir lo bueno y bloquear lo malo". La diferencia clave entre un grupo de seguridad y una ACL de red es que el grupo de seguridad tiene estado. Es decir, que recuerda a quien permite entrar o salir. La ACL de red no tiene estado. O sea, no recuerda nada y comprueba cada paquete que cruza la frontera, sean cuales sean las circunstancias. Es importante entender esta metáfora. Así que quiero ilustrar el camino de ida y vuelta de un paquete de una instancia a otra en una subred diferente. Esta gestión del tráfico no tiene en cuenta el contenido del paquete. De hecho, ni siquiera abre el sobre, no puede. Lo único que hace es comprobar si el remitente está en la lista de admitidos. 

Muy bien. Empecemos por la instancia A. Enviamos un paquete de la instancia A a la instancia B en una subred distinta. La misma VPC, pero subredes distintas. La instancia A envía el paquete. Lo primero que ocurre es que el paquete cumple con el límite del grupo de seguridad de la instancia A. De forma predeterminada, el tráfico saliente de un grupo de seguridad se admite. Así que puedes pasar por delante los porteros y marcharte. El paquete consiguió pasar el grupo de seguridad de la instancia A. Ahora debe salir del límite de la subred. En la frontera, debe pasar por el control de pasaportes, la NACL. A la NACL no le importa lo que permitió el grupo de seguridad. Tiene su propia lista de quién puede pasar y quién no. Si se permite la dirección de destino, puedes continuar tu viaje tranquilamente.

El paquete ha salido de la subred original y ahora va a la subred de destino, donde se aloja la instancia B. En esta subred de destino hay otro control de pasaportes. Que el paquete haya podido salir del país de origen no significa que pueda entrar en el país o, en este caso, subred de destino. Ambos tienen agentes de inmigración con sus propias listas de comprobación. Debes estar admitido en ambas listas o te rechazarán en la frontera. Resulta que el paquete está en la lista de admitidos de esta subred, así que puede entrar por la NACL en la subred. Ya casi está. Ahora el paquete se acerca a la instancia de destino, la B. Cada instancia EC2 tiene su grupo de seguridad. Para entrar en esta instancia, el portero tiene que comprobar si al paquete se le permite entrar y está en la lista. El paquete ha llegado a la instancia de destino. 

Una vez finalizada la transacción, es hora de volver a casa. Es el patrón de tráfico de retorno. Es lo más interesante porque aquí es donde entra en juego la naturaleza con y sin estado de los diferentes motores. Como todavía hay que comprobar el paquete en todos los puntos de control, los grupos de seguridad permiten por defecto el tráfico de retorno. No tienen que revisar listas para comprobar lo que sale. Permiten automáticamente que el tráfico de retorno pase sea como sea. En el control de pasaportes del límite de la subred, estas NACL no recuerdan el estado. No les importa que el paquete haya entrado. Puede estar en una lista de no salir. Cada entrada y salida se comprueba con la lista correspondiente. La dirección de devolución del paquete debe estar en la lista de admitidos para cruzar la frontera. Ahora llega a la frontera de la subred de origen, pero también tiene que pasar por control de migración, la NACL. Con los controles sin estado siempre se comprueba la lista. 

El paquete pasa la NACL de la subred, lo que significa que el paquete logró volver a la instancia A, pero el grupo de seguridad, el portero, sigue a cargo aquí. Pero la diferencia clave es que este grupo tiene estado. Este grupo de seguridad reconoce el paquete de antes, así que no necesita comprobar si tiene permitida la entrada. Por fin en casa. 

Puede parecer que hemos dedicado un gran esfuerzo a enviar un paquete de una instancia a otra y a devolverlo. Puede que les preocupe la sobrecarga de red que esto pueda ocasionar. Pero estos intercambios ocurren instantáneamente, es parte del funcionamiento de las redes de AWS. Para saber sobre la tecnología que hace todo eso posible, puedes inscribirte en otras formaciones muy distintas a esta. Una buena seguridad de red aprovechará las ACL de red y los grupos de seguridad porque una seguridad completa es clave para las arquitecturas modernas.

Para más información sobre el papel de las subredes dentro de una VPC, mira el siguiente ejemplo de la cafetería.

En primer lugar, los clientes realizan sus pedidos al cajero. El cajero pasa los pedidos al camarero. Este proceso permite que la cola siga funcionando sin problemas a medida que llegan más clientes. 

Supongamos que algunos clientes intentan saltarse la cola del cajero y realizar sus pedidos directamente al camarero. Esto interrumpe el flujo de tráfico y hace que los clientes accedan a una parte de la cafetería que está restringida para ellos.

Para solucionar esto, los propietarios de la cafetería dividen el área del mostrador colocando al cajero y al camarero en puestos de trabajo separados. El puesto de trabajo del cajero está orientado al público y está diseñado para recibir clientes. La zona del camarero es privada. El camarero puede seguir recibiendo pedidos del cajero pero no directamente de los clientes.

Esto es similar a cómo pueden utilizarse los servicios de red de AWS para aislar recursos y determinar exactamente cómo fluye el tráfico de red.

En la cafetería, el área del mostrador equivaldría a una VPC. El área del mostrador se divide en dos áreas separadas para el puesto de trabajo del cajero y el puesto de trabajo del camarero. En una VPC, las subredes son áreas separadas que se utilizan para agrupar recursos.

//////////
Subredes
////////

Una subred es una sección de una VPC en la que se pueden agrupar recursos en función de las necesidades operativas o de seguridad. Las subredes pueden ser públicas o privadas.

- Una subred es una sección de una VPC en la que se pueden agrupar recursos en función de las necesidades operativas o de seguridad. Las subredes pueden ser públicas o privadas.

- Una subred es una sección de una VPC en la que se pueden agrupar recursos en función de las necesidades operativas o de seguridad. Las subredes pueden ser públicas o privadas.

En una VPC, las subredes pueden comunicarse entre sí. Por ejemplo, podrías tener una aplicación que incluyera instancias de Amazon EC2 de una subred pública que se comunicaran con bases de datos ubicadas en una subred privada.

///////////
Tráfico de red en una VPC
/////////

Cuando un cliente solicita datos de una aplicación alojada en la nube de AWS, su petición se envía como un paquete. Un paquete es una unidad de datos enviada a través de Internet o de una red. 

Entra en una VPC a través de una puerta de enlace de Internet. Antes de que un paquete pueda entrar en una subred o salir de ella, se comprueban los permisos. Estos permisos indican quién ha enviado el paquete y cómo intenta comunicarse el paquete con los recursos de una subred.

El componente de la VPC que comprueba los permisos de paquetes de subredes es una lista de control de acceso a la red (ACL).

/////////
Listas de control de acceso a la red (ACL)
////////

Una lista de control de acceso a la red (ACL) es un firewall virtual que controla el tráfico entrante y saliente a nivel de subred.

Por ejemplo, sal de la cafetería e imagina que estás en un aeropuerto. En el aeropuerto, los viajeros intentan entrar en otro país. Puedes imaginarte a los viajeros como paquetes y al agente de control de pasaportes como una ACL de red. El agente de control de pasaportes comprueba las credenciales de los viajeros cuando entran y salen del país. Si un viajero está en una lista aprobada, puede pasar. Pero si no está en la lista aprobada o están explícitamente en una lista de viajeros prohibidos, no puede entrar.

Cada cuenta de AWS incluye una ACL de red predeterminada. Al configurar la VPC, puedes utilizar la ACL de red predeterminada de tu cuenta o crear ACL de red personalizadas. 

De forma predeterminada, la ACL de red predeterminada de tu cuenta permite todo el tráfico entrante y saliente, pero puedes modificarlo añadiendo tus propias reglas. En el caso de las ACL de red personalizadas, todo el tráfico entrante y saliente se deniega hasta que se agregan reglas para especificar qué tráfico se va a permitir. Además, todas las ACL de red tienen una regla de denegación explícita. Esta regla garantiza que si un paquete no coincide con ninguna de las demás reglas de la lista, se deniega.

///////
Filtrado de paquetes sin estado
//////

Las ACL de red realizan un filtrado de paquetes sin estado. No recuerdan nada y comprueban los paquetes que cruzan el borde de la subred en cada sentido: entrantes y salientes. 

Recuerda el ejemplo anterior de un viajero que quiere entrar en otro país. Esto es similar a enviar una petición desde una instancia de Amazon EC2 hacia Internet.

Cuando una respuesta del paquete para esa petición vuelve a la subred, la ACL de red no recuerda la petición anterior. La ACL de red comprueba la respuesta del paquete con su lista de reglas para determinar si se debe permitir o denegar.

Una vez que un paquete ha entrado en una subred, debe tener evaluados sus permisos para los recursos de la subred, como las instancias de Amazon EC2. 

El componente de la VPC que comprueba los permisos de paquetes de una instancia de Amazon EC2 es un grupo de seguridad.

///////
Grupos de seguridad
//////

Un grupo de seguridad es un firewall virtual que controla el tráfico entrante y saliente de una instancia de Amazon EC2.

De forma predeterminada, un grupo de seguridad deniega todo el tráfico entrante y permite todo el tráfico saliente. Puedes agregar reglas personalizadas para configurar qué tráfico permitir o denegar.

Por ejemplo, supongamos que te encuentras en un edificio de apartamentos con un portero que recibe a los invitados en el vestíbulo. Puedes imaginarte a los invitados como paquetes y al portero como un grupo de seguridad. A medida que llegan los invitados, el portero comprueba una lista para asegurarse de que pueden entrar en el edificio. Sin embargo, el portero no vuelve a comprobar la lista cuando los invitados salen del edificio.

Si tienes varias instancias de Amazon EC2 dentro de una subred, puedes asociarlas al mismo grupo de seguridad o utilizar grupos de seguridad distintos para cada instancia.


////////
Filtrado de paquetes con estado
///////

Los grupos de seguridad realizan un filtrado de paquetes con estado. Recuerdan las decisiones anteriores tomadas con los paquetes entrantes.

Volvamos al ejemplo del envío de una solicitud desde una instancia de Amazon EC2 a Internet. 

Cuando una respuesta de paquete para esa petición vuelve a la instancia, el grupo de seguridad recuerda la petición anterior. El grupo de seguridad permite que la respuesta continúe, independientemente de las reglas del grupo de seguridad entrante.

Tanto las ACL de red como los grupos de seguridad permiten configurar reglas personalizadas para el tráfico de la VPC. Conforme sigues aprendiendo más sobre la seguridad y las redes de AWS, asegúrate de que tiene claras las diferencias entre las ACL de red y los grupos de seguridad.

///////

Redes globales
////////

Hemos hablado mucho sobre cómo interactuar con la infraestructura de AWS. Pero, ¿cómo interactúan tus clientes con la infraestructura de AWS? Pues bien, si tienes un sitio web alojado en AWS, los clientes suelen entrar en el sitio web a través de su navegador, pulsan Intro, ocurre algo mágico y el sitio se abre. 

Pero, ¿cómo funciona esta magia? Bueno, al igual que esta moneda mágica que tengo aquí. Le dan un bocado y vuelve. Bueno, no es exactamente así, pero voy a hablar de dos servicios que tienen que ver con el sitio web. El primero es Route 53. Route 53 es el servicio de nombres de dominio (DNS) de AWS y es altamente disponible y escalable. Pero, un momento, ¿sabes qué es un DNS? Es como un servicio de traducción. Pero en lugar de traducir de un idioma a otro, traduce nombres de sitios web a direcciones IP (protocolo de Internet) que los equipos pueden leer. 

Por ejemplo, cuando escribimos la dirección de un sitio web en el navegador, este contacta con Route 53 para obtener la dirección IP del sitio, por ejemplo, 192.1.1.1, que dirige nuestro equipo o navegador a esa dirección. Más específicamente, Route 53 puede dirigir el tráfico a distintos puntos de enlace usando varias políticas de enrutamiento, como el basado en latencia, el DNS de geolocalización, la geoproximidad o el turno rotativo ponderado. Con el DNS de geolocalización, el tráfico se dirige en función de la ubicación del cliente. El tráfico procedente de Norteamérica se dirigirá a la región de Oregón y el procedente de Irlanda, a la región de Dublín, por ejemplo.

Incluso puedes usar Route 53 para registrar nombres de dominio y, así, comprar y administrar tus propios nombres de dominio directamente en AWS. 

Hablando de sitios web, hay otro servicio que puede ayudar a acelerar la entrega de activos de sitios web a los clientes: Amazon CloudFront. Recordarás que hablamos de las ubicaciones perimetrales al principio, que ofrecen contenido lo más cercano posible a los clientes, y parte de eso es la red de entrega de contenido (CDN). Recordemos: una CDN es una red que ayuda a entregar contenido perimetral a los usuarios según su ubicación geográfica. Volvamos al ejemplo de Norteamérica e Irlanda. Imaginemos que un usuario en Seattle quiere acceder a un sitio web. Para acelerar esto, alojamos el sitio en Oregón e implementamos los activos estáticos, como imágenes y GIF, en CloudFront en Norteamérica. Esto significa que reciben contenido lo más cerca posible, Norteamérica en este caso, cuando acceden al sitio. Pero a los usuarios irlandeses no tiene sentido entregarles los activos desde Oregón, ya que la latencia no es favorable. Así que implementamos esos activos estáticos en CloudFront, pero esta vez en la región de Dublín. Esto significa que pueden acceder al mismo contenido, pero desde una ubicación más cercana, lo que a su vez mejora la latencia. 

Espero que te alegre saber de estos dos servicios. Gracias. Ahora desapareceré como este pañuelo rojo. ¡Tachán!

/////////
Sistema de nombres de dominio (DNS)
///////

Supongamos que UnaEmpresa tiene un sitio web alojado en la nube de AWS. Los clientes introducen la dirección web en su navegador y pueden acceder al sitio web. Esto ocurre debido a la resolución del sistema de nombres de dominio (DNS). La resolución DNS implica que un servidor DNS se comunique con un servidor web.

Puedes pensar en DNS como la guía telefónica de Internet. La resolución DNS es el proceso de traducir un nombre de dominio a una dirección IP.

//
Por ejemplo, supongamos que quieres visitar el sitio web de UnaEmpresa.

- Al introducir el nombre de dominio en el navegador, esta petición se envía a un servidor DNS.

- El servidor DNS solicita al servidor web la dirección IP que corresponde al sitio web de UnaEmpresa.

- El servidor web responde proporcionando la dirección IP del sitio web de UnaEmpresa, 192.0.2.0.

////////
Amazon Route 53
///////

Amazon Route 53 es un servicio web DNS. Ofrece a los desarrolladores y las empresas una forma fiable de dirigir a los usuarios finales a aplicaciones de Internet alojadas en AWS. 

Amazon Route 53 conecta las peticiones de los usuarios a la infraestructura que se lanza en AWS (como instancias de Amazon EC2 y equilibradores de carga). Puede dirigir a los usuarios a la infraestructura fuera de AWS.

Otra característica de Route 53 es la capacidad de administrar los registros DNS de los nombres de dominio. Se pueden registrar nuevos nombres de dominio directamente en Route 53. También se pueden transferir registros DNS para nombres de dominio existentes administrados por otros registradores de dominio. Esto permite administrar todos los nombres de dominio en una única ubicación.

En el módulo anterior aprendiste sobre Amazon CloudFront, un servicio de entrega de contenido. En el siguiente ejemplo se describe cómo trabajan juntos Route 53 y Amazon CloudFront para entregar contenido a los clientes.

Ejemplo: cómo Amazon Route 53 y Amazon CloudFront entregan contenido

//
Supongamos que la aplicación de UnaEmpresa se lanza en varias instancias de Amazon EC2. Estas instancias se encuentran en un grupo de Auto Scaling que se adjunta a un Application Load Balancer.

- Un cliente solicita datos de la aplicación accediendo al sitio web de UnaEmpresa.

- Amazon Route 53 utiliza la resolución DNS para identificar la dirección IP correspondiente de UnaEmpresa.com, 192.0.2.0. Esta información se devuelve al cliente.

- La petición del cliente se envía a la ubicación perimetral más cercana a través de Amazon CloudFront.

- Amazon CloudFront se conecta al Application Load Balancer, que envía el paquete entrante a una instancia de Amazon EC2.


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 5

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Resumir el concepto básico de almacenamiento y bases de datos.
Describir las ventajas de Amazon Elastic Block Store (Amazon EBS).
Describir las ventajas de Amazon Simple Storage Solution (Amazon S3).
Describir las ventajas de Amazon Elastic File System (Amazon EFS).
Resumir varias soluciones de almacenamiento.
Describir las ventajas de Amazon Relational Database Service (RDS).
Describir las ventajas de Amazon DynamoDB.
Resumir varios servicios de base de datos.

/////////
Almacenes de instancias y Amazon Elastic Block Store
///////

Cuando usas Amazon EC2 para lanzar las aplicaciones, estas necesitan acceso a la CPU, la memoria, la red y el almacenamiento. Las instancias EC2 te dan acceso a todos esos componentes. Y ahora, centrémonos en el acceso al almacenamiento. Las aplicaciones en uso suelen requerir acceso al almacenamiento en bloques. 

El almacenamiento en bloques es como un lugar para guardar archivos. Un archivo es un conjunto de bytes almacenados en bloques de un disco. Cuando se actualiza un archivo, no se sobrescriben todos los bloques. Se actualizan solo las piezas que cambian. Por eso es un almacenamiento eficiente cuando se trabaja con aplicaciones, como bases de datos, software de empresa o sistemas de archivos. 

Cuando utilizas tu portátil o equipo personal, accedes a almacenamiento en bloques. En ese caso, el almacenamiento es el disco duro. Las instancias EC2 tienen discos duros y los hay de varios tipos. 

Cuando lanzas una instancia EC2, según el tipo de instancia EC2 que hayas lanzado, podría ofrecerte almacenamiento local llamado volumen de almacén de instancias. Estos volúmenes se adjuntan físicamente al host donde se lanzan tus instancias EC2. Puedes escribir en él igual que en un disco duro normal. 

El problema aquí es que, como el volumen está adjunto al host físico subyacente, si detienes o terminas la instancia EC2, todos los datos escritos en ese volumen se eliminarán. Esto se debe a que, si comienza la instancia desde un estado de parada, puede que la instancia EC2 comience en otro host en el que no exista ese volumen. Recordemos que las instancias EC2 son máquinas virtuales y, por lo tanto, el host subyacente puede alternar entre detener y comenzar una instancia.

Debido a lo efímero o temporal de los volúmenes de almacén de instancias, son útiles si no es un problema que se puedan perder los datos que se escriben en la unidad. Por ejemplo, archivos temporales, datos provisionales u otros que se puedan volver a crear fácilmente. 

Recomiendo no escribir datos importantes en las unidades que vienen con instancias EC2. Sé que suena inseguro porque, obviamente, necesitas dónde escribir datos que se conserven fuera del ciclo de vida de una instancia EC2. Nadie quiere que se elimine toda una base de datos cada vez que se detenga una instancia. No te preocupes, para eso hay un servicio llamado Amazon Elastic Block Store (EBS). 

Con EBS puedes crear discos duros virtuales, que llamamos volúmenes de EBS, que puedes adjuntar a instancias EC2. Son independientes de los volúmenes locales del almacén de instancias y no tienen vínculo directo con el host en el que se lanza la EC2. Así, los datos que escriban en un volumen de EBS se conservan entre las paradas y los comienzos de la instancia EC2. 

Hay volúmenes de EBS de varios tamaños y tipos. Para solicitar uno, debes definir el tamaño, el tipo y las configuraciones necesarias. Luego aprovisionas el volumen y lo adjuntas a la instancia EC2. Una vez hecho esto, puedes configurar las aplicaciones para escribir en el volumen. Listo. Si detienes y comienzas la instancia EC2, los datos del volumen se conservan. 

Como los volúmenes de EBS son para tener un disco duro que sea persistente en el que las aplicaciones puedan escribir, es importante tener esos datos a buen recaudo. EBS permite hacer copias de seguridad incrementales llamadas instantáneas. Es importante hacer periódicamente instantáneas de los volúmenes de EBS. Así, si alguna vez se daña una unidad, no se perderán los datos. Además, los datos de las instantáneas se pueden restaurar.

/////////
Almacenes de instancias
////////

Los volúmenes de almacenamiento a nivel de bloque se comportan como discos duros físicos.

Un almacén de instancias proporciona almacenamiento temporal a nivel de bloque para una instancia de Amazon EC2. Un almacén de instancias es almacenamiento en disco que está conectado físicamente al equipo de alojamiento de una instancia EC2 y, por lo tanto, tiene la misma vida útil que la instancia. Cuando termina la instancia, se pierden los datos del almacén de instancias.

///
Almacenes de instancias
Para revisar un ejemplo de cómo funcionan los almacenes de instancias, selecciona Comenzar.

1 Se lanza una instancia de Amazon EC2 con un almacén de instancias adjunto.
2 La instancia se detiene o termina.
3 Se eliminan todos los datos del almacén de instancias adjunto.

//
Resumen
Las instancias de Amazon EC2 son servidores virtuales. Si inicias una instancia a partir de un estado detenido, la instancia podría iniciarse en otro host, donde el volumen del almacén de instancias utilizado anteriormente no existe. Por lo tanto, AWS recomienda los almacenes de instancias para casos prácticos que impliquen datos temporales que no necesites a largo plazo.

//
Amazon Elastic Block Store (Amazon EBS) es un servicio que proporciona volúmenes de almacenamiento a nivel de bloque que puede utilizar con instancias de Amazon EC2. Si detienes o terminas una instancia de Amazon EC2, todos los datos del volumen de EBS adjunto permanecen disponibles.

Para crear un volumen de EBS, define la configuración (como el tamaño y el tipo de volumen) y aprovisiónalo. Después de crear un volumen de EBS, se puede adjuntar a una instancia de Amazon EC2.

Dado que los volúmenes de EBS son para datos que deben persistir, es importante hacer una copia de seguridad de dichos datos. Se pueden hacer copias de seguridad progresivas de volúmenes de EBS creando instantáneas de Amazon EBS.

/////
Instantáneas de Amazon EBS
/////

Una instantánea de EBS es una copia de seguridad progresiva. Esto significa que la primera copia de seguridad realizada de un volumen copia todos los datos. En las copias de seguridad posteriores, solo se guardan los bloques de datos que han cambiado desde la instantánea más reciente. 

Las copias de seguridad progresivas son distintas a las copias de seguridad completas, en las que todos los datos de un volumen de almacenamiento se copian cada vez que se realiza una copia de seguridad. La copia de seguridad completa incluye datos que no han cambiado desde la copia de seguridad más reciente.

/////////
Amazon Simple Storage Service
/////////

En este vídeo hablaremos de Amazon Simple Storage Service (S3). Seguramente has adivinado qué es un servicio de almacenamiento. Sí y es… sencillo. La mayoría de las empresas tienen datos que hay que almacenar en algún lugar. En el ejemplo de la cafetería podrían ser recibos, imágenes, documentos de Excel, vídeos de formación para empleados o archivos de texto, entre otros. S3 es útil para almacenar estos archivos, ya que es un almacén de datos que permite guardar y recuperar una cantidad ilimitada de datos a cualquier escala. 

Los datos se almacenan como objetos, pero en lugar de guardarse en un directorio de archivos, se almacenan en buckets. Los archivos de su disco duro serían los objetos. Y los directorios de archivos serían los buckets. El tamaño máximo de los objetos que pueden cargar es cinco terabytes. También se pueden crear versiones de objetos para protegerlos de que se eliminen accidentalmente. Así, siempre se conservarán las versiones anteriores de los objetos como un rastro documental. Incluso se pueden crear varios buckets y almacenarlos en varias clases o niveles de datos. Después, es posible crear permisos para limitar quién puede ver o incluso acceder a los objetos. 

Incluso se puede organizar datos en diferentes niveles. Estos niveles ofrecen mecanismos para distintos usos del almacenamiento como datos a los que hay que acceder con frecuencia o datos de auditoría que deben conservarse durante varios años. Y ahora hablemos del servicio. 

El primer nivel se llama S3 Standard y ofrece once nueves de durabilidad. Es decir, un objeto almacenado aquí tiene un porcentaje del 99,999999999… —vamos, muchos nueves— de probabilidad de permanecer intacto pasado un año. Es muy alta. Además, los datos se almacenan de modo que AWS puede soportar la pérdida simultánea de datos en dos almacenamientos independientes, ya que los datos se almacenan en al menos tres instalaciones. Hay varias copias en distintas ubicaciones. S3 también se usa para alojar sitios web estáticos. Un sitio web estático es una colección de archivos HTML y cada archivo es como una página física del sitio real. Para almacenarlo, simplemente hay que cargar los HTML, los recursos web estáticos y todo lo demás en un bucket, y marcar la casilla pertinente para alojarlo como un sitio estático. Luego se puede introducir la URL del bucket y... ¡tachán! Sitio web instantáneo. Decimos estático, pero eso no significa que no pueda tener animaciones o elementos móviles. En resumen, sería un servicio idóneo para poner en marcha el blog de la cafetería. 

La siguiente clase de almacenamiento se denomina S3 Infrequent Access o S3-IA. Se usa para datos a los que se accede con menos frecuencia, pero que requieren un acceso rápido. Es perfecto para almacenar copias de seguridad, archivos de recuperación de desastres o cualquier objeto que deba almacenarse a largo plazo. 

Hay otra clase o nivel de almacenamiento aplicable al ejemplo que puse de datos de auditoría. Imaginemos que tenemos que conservar los datos varios años para auditorías y recuperarlos con rapidez no es esencial. Se puede usar Amazon S3 Glacier para archivar esos datos. Usar Glacier es tan fácil como mover datos a él o crear almacenes y luego llenarlos de archivos. Y si, por normativas, tienes que conservar datos durante un periodo concreto, puedes aplicar una política de bloqueo de almacenes de S3 Glacier y bloquear el almacén. Puedes especificar controles —como escribir una vez y leer muchas (WORM)— en la política y bloquearla para que no se pueda editar. Una vez bloqueada, la política no se puede modificar. Hay tres opciones de recuperación, que van de minutos a horas, y se puede cargar directamente a Glacier o usar las políticas de S3 Lifecycle. 

De hecho, no creo haber mencionado las políticas de Lifecycle. Son políticas que puedes crear y que puedes mover datos automáticamente entre niveles. Imaginemos que hay que mantener un objeto en S3 Standard durante 90 días y luego pasarlo a S3-IA durante los próximos 30 días. Después de esos 120 días, queremos pasarlo a S3 Glacier. Con las políticas de Lifecycle, creamos esa configuración sin cambiar el código de la aplicación y el objeto cambiará de sitio automáticamente. Es otro ejemplo de servicio administrado de AWS que ayuda a aligerar trabajo para que puedas centrarte en otras necesidades empresariales. 

Y atención: hay otras clases de almacenamiento disponibles como S3 Infrequent Access One Zone o S3 Glacier Deep Archive. ¡Feliz almacenamiento!

/////////
Almacenamiento de objetos
////////

En el almacenamiento de objetos, cada objeto consta de datos, metadatos y una clave.

Los datos pueden ser una imagen, un vídeo, un documento de texto o cualquier otro tipo de archivo. Los metadatos contienen información sobre qué son los datos, cómo se usan, el tamaño del objeto, etc. La clave de un objeto es su identificador único.

///////////
Amazon Simple Storage Service (Amazon S3)
//////////

Amazon Simple Storage Service (Amazon S3) es un servicio que proporciona almacenamiento a nivel de objeto. Amazon S3 almacena datos como objetos en buckets.

Puedes cargar cualquier tipo de archivo en Amazon S3, como imágenes, vídeos, archivos de texto, etc. Por ejemplo, puedes utilizar Amazon S3 para almacenar archivos de copia de seguridad, archivos multimedia de un sitio web o documentos archivados. Amazon S3 ofrece espacio de almacenamiento ilimitado. El tamaño máximo de archivo de un objeto de Amazon S3 es de 5 TB.

Al cargar un archivo en Amazon S3, puedes establecer permisos para controlar la visibilidad y el acceso al mismo. También puedes utilizar la característica de control de versiones de Amazon S3 para realizar un seguimiento de los cambios en los objetos a lo largo del tiempo.

////////////
Clases de almacenamiento de Amazon S3
//////////

Con Amazon S3, solo se paga por lo que se usa. Puedes elegir entre una variedad de clases de almacenamiento para seleccionar la que mejor se adapte a tus necesidades empresariales y económicas. Al seleccionar una clase de almacenamiento de Amazon S3, ten en cuenta los dos factores siguientes:

Con qué frecuencia planea recuperar los datos.
Qué disponibilidad necesita para los datos.
Para más información sobre las clases de almacenamiento de Amazon S3, selecciona el símbolo + que aparece junto a cada categoría.

/////////
S3 Standard
–
Diseñado para los datos a los que se accede con frecuencia.
Almacena datos en un mínimo de tres zonas de disponibilidad.
S3 Standard proporciona alta disponibilidad para los objetos. Esto lo convierte en una buena opción para una amplia gama de casos prácticos, como sitios web, distribución de contenido y análisis de datos. S3 Standard tiene un precio más alto que otras clases de almacenamiento destinadas al almacenamiento de archivos y datos a los que se accede con poca frecuencia.

////////
S3 Standard-Infrequent Access (S3 Standard-IA)
–
Ideal para datos a los que se accede con poca frecuencia.
Similar a S3 Standard, pero con un precio de almacenamiento inferior y un precio de recuperación superior.
S3 Standard-Infrequent Access es ideal para los datos a los que se accede con poca frecuencia, pero para los que se requiere una alta disponibilidad cuando sea necesario. Tanto S3 Standard como S3 Standard-Infrequent Access almacenan datos en un mínimo de tres zonas de disponibilidad. Proporciona el mismo nivel de disponibilidad que S3 Standard, pero con un precio de almacenamiento inferior y un precio de recuperación superior.


//////////
S3 One Zone-Infrequent Access (S3 One Zone-IA)
–
Almacena datos en una única zona de disponibilidad.
Tiene un precio de almacenamiento inferior al de S3 Standard-Infrequent Access.
En comparación con S3 Standard y S3 Standard-Infrequent Access, que almacenan datos en un mínimo de tres zonas de disponibilidad, S3 One Zone-Infrequent Access almacena datos en una única zona de disponibilidad. Esto la convierte en una buena opción como clase de almacenamiento si se cumplen las siguientes condiciones:

Quieres ahorrar costes de almacenamiento.
Puedes reproducir fácilmente los datos en caso de que se dé un error en la zona de disponibilidad.

//////////
S3 Intelligent-Tiering
–
Ideal para datos con patrones de acceso desconocidos o cambiantes.
Requiere una pequeña tarifa mensual de seguimiento y automatización por objeto.
En la clase de almacenamiento de S3 Intelligent-Tiering, Amazon S3 supervisa los patrones de acceso de los objetos. Si no has accedido a un objeto durante 30 días consecutivos, Amazon S3 lo traslada automáticamente al nivel de acceso poco frecuente, S3 Standard-Infrequent Access. Si accedes a un objeto en el nivel de acceso poco frecuente, Amazon S3 lo traslada automáticamente al nivel de acceso frecuente, S3 Standard.

////////////
S3 Glacier
–
Almacenamiento de bajo precio diseñado para archivar datos.
Posibilidad de recuperar objetos en unos minutos o unas horas.
S3 Glacier es una clase de almacenamiento de bajo precio ideal para archivar datos. Por ejemplo, podrías utilizar esta clase de almacenamiento para almacenar registros de clientes archivados o fotos y archivos de vídeo antiguos.

////////
S3 Glacier Deep Archive
–
Clase de almacenamiento de objetos de menor precio ideal para archivar.
Posibilidad de recuperar objetos en un plazo de 12 horas.
A la hora de decidir entre Amazon S3 Glacier y Amazon S3 Glacier Deep Archive, considera la rapidez con la que necesitas recuperar objetos archivados. Los objetos almacenados en la clase de almacenamiento de S3 Glacier se pueden recuperar en cuestión de minutos o de unas horas. En cambio, los objetos almacenados en la clase de almacenamiento S3 Glacier Deep Archive se pueden recuperar en un plazo de 12 horas.

///////////
Comparativa entre Amazon EBS y Amazon S3
//////////

AWS Cloud Practitioner: ¡Te damos la bienvenida al combate de almacenamientos! (Campana) En la esquina de almacenamiento en bloques, con un peso de hasta 16 tebibytes cada uno, con la capacidad única de soportar que se terminen tus instancias de Amazon EC2, son sólidos, son duros, ¡son Amazon Elastic Block Storage! 

En la esquina de almacenamiento regional, con un almacenamiento ilimitado, objetos individuales de hasta 5000 gigabytes, especializados en escribir una vez y leer muchas, son 99, coma 9 9 9 9 9 9 9 9 9 por ciento duraderos, ¡son Amazon Simple Storage Service!  

Cara a cara, cada clase presume del mejor diseño distribuido dinámicamente según distintas necesidades. ¿Qué clase de almacenamiento saldrá victoriosa de esta batalla épica? Para saber quién gana, debes aclarar qué necesitas. 

Primer asalto. (Campana) Imaginemos que tienes un sitio web de análisis fotográfico donde los usuarios cargan una foto y la aplicación les dice a qué animales se parecen. Seguramente tienes millones de imágenes de animales que hay que indexar y que posiblemente vean miles de personas a la vez. S3 es perfecto para este caso. S3 ya está habilitado para la web. Cada objeto tiene una URL con permisos de acceso para ver o administrar imágenes que ya puede controlar. Se distribuye regionalmente, así que tiene once nueves de durabilidad para no preocuparse por estrategias de copia de seguridad. S3 es esa estrategia. Además, ahorra muchos costes frente el mismo almacenamiento en EBS con la ventaja adicional de ser sin servidor. No necesita instancias de Amazon EC2. El juez ha decidido que S3 ha ganado este asalto. 

Pero espera: segundo asalto. (Campana) Si tuvieras un vídeo de 80 gigabytes y lo estuvieras editando, para saber cuál es la mejor opción, tenemos que conocer la diferencia entre almacenamiento de objetos y en bloques. El de objetos trata los archivos como objetos completos y separados. Es ideal para documentos imágenes y archivos de vídeo que se cargan y consumen como objetos enteros, pero que cada vez que uno de estos objetos cambia, hay que volver a cargar el archivo. No hay actualizaciones delta. El almacenamiento en bloques lo divide en partes pequeñas o bloques. Es decir, ese archivo de 80 gigabytes, cuando editas una parte de ese vídeo y guardas ese cambio, el motor solo actualiza los bloques correspondientes a esos bits. Si haces muchos cambios pequeños, el almacenamiento elástico en bloques, EBS, es la solución perfecta. Si usaras S3, siempre que guardaras cambios, el sistema tendría que cargar los 80 gigabytes una y otra vez. EBS gana el segundo asalto. 

Es decir, si usas objetos completos o haces cambios ocasionales, S3 es la opción ganadora. Si haces tareas de lectura, acceso o cambios complejos, sin duda EBS gana por KO. El ganador depende de la carga de trabajo. Cada servicio es adecuado para unas necesidades específicas. Una vez sepas lo que necesitas, sabrás qué servicio es tu campeón.

////////////
Amazon Elastic File System
///////////

Entre los servicios de almacenamiento tenemos Amazon Elastic File System, al que también llamamos EFS. Es un sistema de archivos administrado. Es habitual que las empresas tengan sistemas de archivos compartidos en sus aplicaciones. Por ejemplo, posiblemente tengan varios servidores que analizan muchos datos almacenados en un sistema de archivos compartido. Esos datos suelen alojarse en centros de datos en sus instalaciones. En esos centros de datos, hay que asegurarse de que el almacenamiento sea suficiente para la cantidad de datos, de hacer copias de seguridad, del almacenamiento redundante y de administrar los servidores que alojan esos datos. 

Con AWS, no tienen que preocuparse por comprar todo ese hardware ni de las tareas que supone mantener el sistema en funcionamiento. Con EFS pueden mantener sus sistemas de archivos y dejar que AWS se encargue de las tareas de escalado y replicación. EFS les permiten tener varias instancias accediendo a los datos de EFS a la vez. Se escala vertical y horizontalmente, según sea necesario, sin que tengan que hacer nada. ¿A que suena bien? -Seguramente estén pensando en que EBS también almacena archivos a los que se puede acceder desde EC2. ¿Cuál es la diferencia?

(Campana) AWS Cloud Practitioners: ¡bienvenidos!

Basta. No es necesario. La respuesta es muy sencilla. Los volúmenes de EBS se adjuntan a instancias EC2 y son un recurso a nivel de zona de disponibilidad (AZ). Para adjuntar EC2 a EBS, deben estar en la misma AZ. Pueden guardar archivos, operar una base de datos o almacenar aplicaciones allí. Es un disco duro. Si aprovisiona un volumen EBS de dos terabytes y lo llena, no se escala automáticamente para ofrecer más almacenamiento. Eso en cuanto a EBS. Amazon EFS puede tener varias instancias leyendo y escribiendo a la vez. 

Pero no es solo un disco duro en blanco en el que escribir. Es un sistema de archivos para Linux. También es un recurso regional: cualquier instancia EC2 de la región puede escribir en el sistema EFS. A medida que se escriben más datos, EFS se escala automáticamente. No hay que aprovisionar más volúmenes.

////////
Almacenamiento de archivos
////////

En el almacenamiento de archivos, varios clientes (como usuarios, aplicaciones, servidores, etc.) pueden acceder a los datos almacenados en carpetas de archivos compartidos. En esta estrategia, un servidor de almacenamiento utiliza almacenamiento en bloques con un sistema de archivos local para organizar los archivos. Los clientes acceden a los datos a través de rutas de archivos.

En comparación con el almacenamiento en bloques y el almacenamiento de objetos, el almacenamiento de archivos es ideal para casos prácticos en los que un gran número de servicios y recursos necesitan acceder a los mismos datos al mismo tiempo.

///
Amazon Elastic File System (Amazon EFS) es un sistema de archivos escalable que se utiliza con los servicios en la nube de AWS y los recursos en las instalaciones. A medida que se agregan y se eliminan archivos, Amazon EFS aumenta y se reduce automáticamente. Puedes escalar en función de la demanda a petabytes sin alterar las aplicaciones.

//////
Comparación entre Amazon EBS y Amazon EFS
/////

Selecciona cada tarjeta para darle la vuelta.

1- Amazon EBS:
Un volumen de Amazon EBS almacena datos en una única zona de disponibilidad. 
Para adjuntar una instancia de Amazon EC2 a un volumen de EBS, tanto la instancia de Amazon EC2 como el volumen de EBS deben ubicarse en la misma zona de disponibilidad.

2 - Amazon EFS:
Amazon EFS es un servicio regional. Almacena datos transversalmente en varias zonas de disponibilidad. 
El almacenamiento duplicado permite acceder a los datos simultáneamente desde todas las zonas de disponibilidad de la región donde se encuentra un sistema de archivos. Además, los servidores en las instalaciones pueden acceder a Amazon EFS mediante AWS Direct Connect.



///////////
Amazon Relational Database Service
//////////

Estamos almacenando datos de la cafetería en varios sistemas, pero nos damos cuenta de que necesitamos relacionar varios tipos de datos. Con relacionar me refiero a que, por ejemplo, si un cliente pide la misma bebida varias veces, quizá podríamos ofrecerle un descuento promocional en su próxima compra. Necesitamos hacer un seguimiento de esta relación en algún sitio. En este caso, la mejor opción es un sistema de administración de bases de datos relacionales (RDBMS). Con este sistema, almacenamos los datos de forma que se relacionan con otros. 

Por ejemplo, la entrada o el registro del cliente lo guardamos en una tabla de clientes. La entrada de su dirección postal la almacenamos en la tabla de direcciones correspondiente. Luego, relacionamos ambos datos mediante un atributo común y podemos consultar los datos de ambas tablas. 

Los datos se suelen consultar realizando consultas en SQL. Esto es aplicable a varios sistemas de bases de datos. Hablando de esos sistemas, ¿cuáles son los más populares compatibles con AWS? MySQL, PostgreSQL, Oracle, Microsoft SQL Server y muchos más. Si tienes un entorno en tus instalaciones, probablemente usas uno de esos sistemas y lo más seguro es que estén alojados en tu centro de datos. 

Pero, ¿hay forma de pasarlos fácilmente a la nube? La respuesta es "sí", haciendo lo que llamamos lift and shift para migrar la base de datos y usarla en Amazon EC2. Tendrías el control de las mismas variables que en el entorno de tus instalaciones, como el SO, la memoria, la CPU y la capacidad de almacenamiento. Es un paso rápido a la nube y puedes migrar el sistema siguiendo procesos estándar o con una solución como Database Migration Service, de la que hablaremos en otro vídeo. 

La otra opción para tener tus bases de datos en la nube es usar un servicio más administrado llamado Amazon Relational Database Service (RDS). Es compatible con los motores de bases de datos más usados como los que he mencionado, pero ofrece más beneficios. Incluye parches automatizados, copias de seguridad, redundancia, conmutación por error y recuperación de desastres, cosas que sueles administrar tú. Esto la convierte en una opción muy atractiva para los clientes de AWS, ya que les permite centrarse en problemas empresariales y no en mantener bases de datos. Si administras bases de datos, esto te puede llevar mucho tiempo y resultar complejo. 

¿Cómo te facilitamos aún más la ejecución de cargas de trabajo de bases de datos en la nube? Vamos un paso más allá y migramos o implementamos en Amazon Aurora. Es la solución más administrada para bases de datos relacionales. Está disponible en MySQL y PostgreSQL, y por una décima parte del precio de las bases de datos comerciales. Es una base de datos muy rentable. Sus beneficios incluyen réplicas de datos en varios lugares para tener 6 copias en todo momento. También se pueden implementar hasta 15 réplicas de lectura para descargar las lecturas y escalar el rendimiento. Además, se hacen continuamente copias de seguridad en S3, así que siempre tendrás una lista para restaurar. Y recuperación a un momento dado, para que puedas recuperar datos de un periodo específico. 

Con esto quedan resumidas las bases de datos relacionales. 

////
Bases de datos relacionales
/////

En una base de datos relacional, los datos se almacenan de forma que se relacionan con otros datos. 
Un ejemplo de base de datos relacional podría ser el sistema de administración de inventarios de la cafetería. Cada registro de la base de datos incluiría datos de un solo artículo, como el nombre del producto, tamaño, precio, etc.
Las bases de datos relacionales utilizan lenguaje de consulta estructurada (SQL) para almacenar y consultar datos. Esta estrategia permite almacenar los datos de una forma fácilmente comprensible, coherente y escalable. Por ejemplo, los propietarios de la cafetería pueden escribir una consulta SQL para identificar a todos los clientes cuya bebida comprada con mayor frecuencia es un café con leche mediano.

Ejemplo de datos de una base de datos relacional:
ID	Nombre del producto	Tamaño	Precio
1	Café molido tostado medio	355 ml	5,30 USD

2	Café molido tostado oscuro	591 ml	9,27 USD


///////
Amazon Relational Database Service
//////
Amazon Relational Database Service (Amazon RDS) es un servicio que permite operar bases de datos relacionales en la nube de AWS.
Amazon RDS es un servicio administrado que automatiza tareas como aprovisionamiento de hardware, configuración de bases de datos, aplicación de parches y copias de seguridad. Con estas capacidades, puedes dedicar menos tiempo a realizar tareas administrativas y más a utilizar los datos para innovar en tus aplicaciones. Puedes integrar Amazon RDS con otros servicios para satisfacer tus necesidades empresariales y operativas, como el uso de AWS Lambda para consultar la base de datos desde una aplicación sin servidor.
Amazon RDS proporciona distintas opciones de seguridad. Muchos motores de base de datos de Amazon RDS ofrecen cifrado en reposo (protección de los datos mientras se almacenan) y cifrado en tránsito (protección de los datos mientras se envían y se reciben).

/////////
Motores de base de datos Amazon RDS
/////////

Amazon RDS está disponible en seis motores de base de datos, que optimizan la memoria, el rendimiento o la entrada/salida (E/S). Los motores de base de datos compatibles incluyen los siguientes:

Amazon Aurora.
PostgreSQL.
MySQL.
MariaDB.
Oracle Database.
Microsoft SQL Server.

//////
Amazon Aurora
/////

Amazon Aurora es una base de datos relacional de clase empresarial. Es compatible con bases de datos relacionales MySQL y PostgreSQL. Es hasta cinco veces más rápida que las bases de datos MySQL estándar y hasta tres veces más rápida que las bases de datos PostgreSQL estándar.
Amazon Aurora ayuda a reducir los costes de la base de datos reduciendo las operaciones innecesarias de entrada/salida (E/S), al tiempo que garantiza que los recursos de la base de datos sigan siendo fiables y estén disponibles. 
Considera utilizar Amazon Aurora si tus cargas de trabajo requieren alta disponibilidad. Replica seis copias de los datos en tres zonas de disponibilidad y realiza copias de seguridad continuas de los datos en Amazon S3.

////////////////

Amazon DynamoDB
/////////////////

Hablemos de Amazon DynamoDB. En su nivel más básico, DynamoDB es una base de datos. Una base de datos sin servidor, así que no hay que administrar las instancias subyacentes ni la infraestructura que usa. 

Con DynamoDB se pueden crear tablas. Una tabla de DynamoDB es un lugar donde almacenar y consultar datos. Estos se organizan en dos elementos. Los elementos tienen atributos. Los atributos son las características de los datos. Ya tengas un solo elemento o dos millones en una tabla, DynamoDB se encarga de administrar el almacenamiento subyacente. No tienes que preocuparte por el escalado del sistema, ni horizontal ni vertical. 
DynamoDB almacena de modo redundante en cada zona de disponibilidad y copia los datos en varias unidades, sin que tengas que hacer nada. Esto reduce mucho la carga de operar una base de datos de alta disponibilidad. Además de poder escalarlo muchísimo, DynamoDB es de alto rendimiento. Su tiempo de respuesta es de milisegundos. Además, si tienes aplicaciones con posiblemente millones de usuarios, poder escalar y ofrecer tiempos de respuesta fiables y mínimos es importante. 
DynamoDB no es una base de datos al uso, en el sentido de que no utiliza el popular lenguaje de consulta llamado SQL. Las bases de datos relacionales, como las MySQL estándar, requieren un esquema y un lugar bien definidos, que podrían consistir en una tabla o varias relacionadas entre sí, y los datos se consultan con SQL. Es una opción adecuada en muchos casos y tradicionalmente ha sido el tipo de base de datos estándar. 

Sin embargo, estos tipos de bases de datos SQL rígidas pueden tener problemas para rendir y escalar en situaciones exigentes. El esquema rígido también hace que no pueda haber variación en los tipos de datos que almacenan en una tabla. Por lo tanto, no son idóneos para conjuntos de datos menos rígidos a los que se acceda muy rápido. 
Para esto, es mejor usar bases de datos NoSQL (no relacionales). DynamoDB es no relacional. Las bases de datos no relacionales suelen tener esquemas simples y flexibles, no complejos ni rígidos, con varias tablas que se relacionen entre sí. 

Con DynamoDB, puedes agregar y eliminar atributos de los elementos de la tabla cuando quieras. No todos los elementos de la tabla tienen que tener los mismos atributos. Es ideal para conjuntos de datos con elementos que tienen variaciones. 
Debido a esta flexibilidad, no admite consultas SQL complejas. Las consultas se deben basar en un pequeño subconjunto de atributos designados como claves. Por eso, las consultas que se hacen a bases de datos no relacionales suelen ser más sencillas y se centran en una colección de elementos de una tabla, no en elementos de varias tablas. Este patrón de consulta, junto con otros factores, incluido cómo está diseñado el sistema subyacente, permite que DynamoDB responda muy rápido y sea muy escalable. 

Recapitulemos: DynamoDB es una base de datos NoSQL no relacional. Está diseñada para un fin. Es decir, se usa para casos concretos y no es adecuada para cualquier carga de trabajo. Responde en milisegundos. Está totalmente administrada y es muy escalable. Un ejemplo increíble es el Prime Day de 2019. En esas 48 horas, hubo 7,11 billones de llamadas a la API de DynamoDB y hasta 45,4 millones de solicitudes por segundo. Una escalabilidad impresionante, todo sin la administración de bases de datos subyacente. Es bastante guay.

///////
Bases de datos no relacionales
////////

En una base de datos no relacional se crean tablas. Una tabla es un lugar en el que se pueden almacenar y consultar datos.

Las bases de datos no relacionales a veces se denominan bases de datos NoSQL porque utilizan estructuras no compuestas por filas y columnas para organizar los datos. Un tipo de estrategia estructural para las bases de datos no relacionales son los pares de valor de clave. Con los pares de valor de clave, los datos se organizan en elementos (claves) y los elementos tienen atributos (valores). Piense en los atributos como características diferentes de sus datos.

En una base de datos de valor de clave, se puede añadir o eliminar atributos de los elementos de la tabla en cualquier momento. Además, no todos los elementos de la tabla tienen que tener los mismos atributos. 

Ejemplo de datos de una base de datos no relacional:

Valor	Clave
 1	Nombre: Álvaro Fernández
	Dirección: 123 Cualquier calle
1
	Bebida favorita: café con leche medio
1



2	Nombre: María Gómez

2	Dirección: 100 Calle principal

2	Fecha de nacimiento: 5 de julio de 1999


/////////
Amazon DynamoDB
//////////

Amazon DynamoDB es un servicio de base de datos de valor de clave. Ofrece un rendimiento de milisegundos de un dígito a cualquier escala.
Para más información sobre las características de DynamoDB, selecciona cada tarjeta flash para darle la vuelta.

// 
Sin servidor:

DynamoDB no tiene servidor, lo que significa que no tienes que aprovisionar, aplicar parches ni administrar servidores. 
Tampoco tienes que instalar, mantener ni operar software.

//
Escalado automático:

A medida que el tamaño de la base de datos se reduce o aumenta, DynamoDB escala automáticamente para ajustarse a los cambios de capacidad y, al mismo tiempo, mantener un rendimiento uniforme.
Esto lo convierte en una opción adecuada para casos prácticos que requieran un alto rendimiento durante el escalado.

////
(Música animada) AWS Cloud Practitioner: ¡Te damos la bienvenida La Liga de las Bases de Datos! (Campana) En la esquina relacional, diseñada para ahorrar trabajo pesado de todo tipo a administradores de bases de datos, con alta disponibilidad y recuperación automáticas, tú controlas los datos, tú controlas el esquema, tú controlas la red… Es… ¡Amazon RDS! (Campana) ¡Sí! 

En la esquina NoSQL, con un par clave-valor que no requiere esquemas avanzados, puede funcionar como la base de datos global con solo tocar un botón. Tiene un rendimiento enorme, posibilidad de escalado a petabytes y acceso granular a la API… Es…¡Amazon DynamoDB! 

Cara a cara. Cada una está diseñada para mejorar los nuevos y emocionantes entornos que tienes pensados. ¿Qué base de datos saldrá victoriosa en este combate entre gigantes? Una vez más, el ganador dependerá de tus necesidades. 

Primer asalto. (Campana) Las bases de datos relacionales llevan con nosotros desde que las empresas usan equipos. Poder crear análisis complejos de datos distribuidos en varias tablas es la fortaleza de cualquier sistema relacional. En este asalto, si tenemos un sistema de administración de cadena de suministro comercial cuyos puntos débiles debemos encontrar, RDS es el claro ganador porque está diseñado para el análisis empresarial. Al necesitar uniones relacionales complejas, este primer asalto lo gana RDS. 

Segundo asalto. (Campana) Imaginemos, básicamente, cualquier otro uso. Te resultará raro, pero, a pesar de lo que los proveedores de bases de datos independientes te hayan dicho, la mayoría de los usos que se dan a bases de datos relacionales caras no tienen nada que ver con relaciones complejas. De hecho, mucho de lo que se introduce en estas bases de datos acaba siendo tablas de consulta. 

En este asalto, imaginemos que tenemos una lista de contactos, nombres, números de teléfono, correos electrónicos e ID de empleados. Una sola tabla sirve para eso. Podríamos usar una base de datos relacional, pero lo que hace que estas bases de datos sean geniales, es decir, su compleja funcionalidad, ocasiona sobrecostes y retrasos si no se aprovecha. Aquí las bases de datos no relacionales como Dynamo DB ganan por KO. Al ahorrar sobrecostes, DynamoDB te permite crear bases de datos potentes e increíblemente rápidas sin una funcionalidad relacional compleja. DynamoDB es el ganador indiscutible. (Música de fondo) 
Una vez más, el ganador depende de la carga de trabajo de tu empresa. Cada servicio es adecuado para unas necesidades específicas. Una vez identifiques tus necesidades, sabrás cuál es tu servicio ganador. (Aplausos)

/////////
Amazon Redshift
////////

Hemos hablado mucho de los tipos de flujo de trabajo que requieren datos fiables y actualizados con rapidez. Bases de datos que puedan gestionar miles de transacciones por segundo, y almacenamiento muy disponible y de larga duración. Pero, a veces, las necesidades de nuestra empresa no tienen que ver con lo que sucede ahora, sino con lo que ya ha sucedido. Para este análisis de datos se usa un tipo de bases de datos distinto. Podríamos recurrir al planteamiento general de una sola base de datos para todo, pero las modernas, creadas para ingerir muy rápido datos en tiempo real y procesar consultas, pueden no ser adecuadas. 

Voy a explicarlo. Para procesar la velocidad de lectura/escritura en tiempo real, las bases de datos relacionales en su mayoría suelen funcionar muy bien a determinadas capacidades. La cantidad de contenido que almacena. El reto de los análisis de historiales, de los datos que responden preguntas como: "muéstrame cómo ha mejorado la producción desde que comenzamos", es la recopilación continua de datos. 

De hecho, con la telemetría moderna y el auge del IoT, el volumen de datos abrumará incluso a las bases de datos relacionales tradicionales más robustas. Y no solo eso. Además del volumen de datos, la variedad puede ser otro problema. Si tus proyectos son de inteligencia empresarial (BI), con datos procedentes de varios almacenamientos de datos, como los sistemas de inventario, finanzas y ventas minoristas, una consulta a varias bases de datos parece una buena opción, pero las bases de datos tradicionales no las procesan fácilmente. 

Si los datos son demasiado complejos para las bases relacionales tradicionales, toca adentrarse en el mundo de los almacenamientos de datos. Los almacenamientos de datos están diseñados específicamente para este tipo de big data, en los que se necesitas análisis de historiales en lugar de análisis operativos. 

Ahora bien, un historial puede ser reciente. Por ejemplo: "Muéstrame los datos de las ventas de la última hora de todas las tiendas". Esos datos son los que son. No vamos a vender más en la última hora porque eso ya quedó en el pasado. Algo distinto sería: "¿Cuántas bolsas de café nos quedan en inventario ahora mismo?". Es un dato que puede cambiar continuamente. Si lo que tu empresa necesita es consultar datos del pasado, un almacenamiento de datos será la solución adecuada para esa línea de BI. 

Hay muchas soluciones de almacenamiento de datos en el mercado. Si ya estás usando la que quieres en AWS, solo hay que transferir los datos. Pero puede que sigas teniendo que hacer todas las típicas tareas necesarias para que el almacenamiento de datos esté a punto, sea resiliente y escale continuamente. ¿No sería genial que tu equipo de almacenamiento de datos pudiera centrarse en los datos, en lugar de en mantener y alimentar el motor? 

Presentamos Amazon Redshift, data warehousing como servicio. Es ampliamente escalable. Los nodos de Redshift de varios petabytes son muy comunes. De hecho, junto con Amazon Redshift Spectrum, puedes realizar directamente una sola consulta SQL en exabytes de datos no estructurados de lagos de datos. 

Pero, además de poder gestionar conjuntos de datos muchísimo más grandes, Redshift se vale de innovaciones para ofrecer un rendimiento 10 veces mayor que el de bases de datos tradicionales a la hora de gestionar este tipo de cargas de trabajo de BI. 

No voy a entrar en detalles de cómo funciona. Disponemos de formación que puedes hacer para aprender cómo está diseñado y por qué puede ofrecer esos resultados excelentes. Lo importante es que sepas que, si necesitas soluciones de BI de big data, Redshift permite comenzar con una sola llamada a la API. Menos tiempo esperando resultados y más tiempo obteniendo respuestas.

//////////
Amazon Redshift
/////////

Amazon Redshift es un servicio de data warehousing que se puede utilizar para análisis de big data. Ofrece la capacidad de recopilar datos de muchas fuentes y ayuda a comprender las relaciones y tendencias de los datos.

//////////
AWS Database Migration Service
/////////////

Hemos hablado de bases de datos y de sus opciones en AWS. Pero, ¿y si tienes una base de datos que ya está en tus instalaciones o en la nube? ¿Entonces tienes que empezar desde cero? ¿O AWS tiene una forma mágica de ayudarte a migrar las bases de datos? 

Por suerte, AWS ofrece un servicio llamado Amazon Database Magic… perdón, Amazon Database Migration Service (DMS), para ayudarte precisamente con eso. DMS ayuda a los clientes a migrar sus bases de datos a AWS de forma segura y sencilla. Lo que hace es migrar datos de una base de datos fuente a otra de destino. Lo mejor es que la base de datos fuente sigue estando operativa durante la migración, lo que reduce el tiempo de inactividad de las aplicaciones que dependen de ella. Mejor aún: las bases de datos fuente y de destino no tienen que ser del mismo tipo. 

Pero empecemos con bases de datos del mismo tipo. Esta migración se llama homogénea y puede ser de MySQL a Amazon RDS for MySQL, de Microsoft SQL Server a Amazon RDS for SQL Server o de Oracle a Amazon RDS for Oracle. El proceso es muy sencillo, ya que las estructuras de esquema, tipos de datos y código de base de datos de fuente y destino son compatibles. 

La base de datos fuente puede estar en tus instalaciones, funcionar en instancias de Amazon EC2 o ser una base de datos de Amazon RDS. El destino puede ser una base de datos en Amazon EC2 o Amazon RDS. En este caso, creas una tarea de migración con conexiones a las bases de datos fuente y de destino. Después, la migración empieza con un solo clic. AWS Database Migration Service se encarga del resto. 
(Suspiro) El segundo tipo de migración es el que se hace cuando las bases de datos fuente y de destino son de tipos distintos. A esta migración se le llama heterogénea y es un proceso de dos pasos. Como las estructuras de esquema, tipos de datos y código de base de datos de fuente y destino son distintos, primero tenemos que convertirlos con AWS Schema Conversion Tool. Esto convertirá el esquema y código fuente para que coincidan con los del destino. El siguiente paso es usar DMS para migrar datos de la fuente a la base de datos de destino. 

Pero estos no son los únicos usos de DMS. También sirve para migrar bases de datos para desarrollo o pruebas, consolidar bases de datos o replicar continuamente bases de datos. 

Migrar para desarrollo y pruebas sirve para que los desarrolladores hagan pruebas con datos de producción sin afectar a los usuarios de producción. En este caso, se usa DMS para migrar una copia de la base de datos de producción a un entorno de desarrollo o prueba, ya sea una vez o de forma continua. 

Consolidar bases de datos consiste en tener varias y combinarlas en una base de datos central. Por último, replicar continuamente datos se hace usando DMS para este mismo propósito. Se hace para la recuperación de desastres o debido a separación geográfica. 
Para obtener más información al respecto, consulta nuestra sección de recursos. Y eso es todo, amigos, DMS en resumidas cuentas.

////////////
AWS Database Migration Service (AWS DMS)
////////////

AWS Database Migration Service (AWS DMS) permite migrar bases de datos relacionales, bases de datos no relacionales y otro tipo de almacenes de datos.

Con AWS DMS, trasladas datos entre una base de datos de fuente y una base de datos de destino. Las bases de datos fuente y destino pueden ser del mismo tipo o de distintos tipos. Durante la migración, la base de datos fuente permanece operativa, lo que reduce el tiempo de inactividad de cualquier aplicación que se basa en la base de datos. 

Por ejemplo, supongamos que tienes una base de datos MySQL almacenada en las instalaciones en una instancia de Amazon EC2 o en Amazon RDS. Considera la base de datos MySQL como tu base de datos fuente. Con AWS DMS, puedes migrar los datos a una base de datos destino, como una base de datos de Amazon Aurora.

//////////
Otros casos prácticos de AWS DMS
//////////

Selecciona cada carta para darle la vuelta.

---Desarrollo y migración de bases de datos de prueba:
Permitir a los desarrolladores probar aplicaciones con datos de producción sin que afecte a los usuarios de producción

---Consolidación de bases de datos:
Combinación de varias bases de datos en una única base de datos

--- Replicación continua:
Envío de copias continuas de sus datos a otras fuentes de destino en lugar de realizar una migración única.

//////////////
Servicios de base de datos adicionales
/////////////

Antes de terminar con bases de datos y almacenamiento, quiero volver al tema con el que empezamos: elegir la base de datos y la plataforma de almacenamiento adecuadas para tus necesidades en vez de ajustar los datos a las necesidades de la base de datos. No importa lo que un proveedor de bases de datos diga: no existe una base de datos que sirva para todo. Ya hemos hablado de muchos tipos de bases de datos y AWS ofrece aún más tipos para atender necesidades empresariales concretas, pero no nos da tiempo. No obstante, recuerda que están ahí si los necesitas.

Por ejemplo, hemos hablado de DynamoDB, ideal para bases de datos de pares clave-valor. Pero, ¿y si necesitas algo más que pequeños atributos? ¿Y si necesitas un sistema completo de administración de contenido? Presentamos Amazon DocumentDB, idóneo para administrar contenido, catálogos y perfiles de usuario. 

¿Y si también quieres analizar una red social? Los datos de este tipo de redes, de quién está conectado con quién… son muy difíciles de gestionar con una base de datos relacional al uso. Amazon Neptune es una base de datos de gráficos para redes sociales y motores de recomendación, ideal también para detectar fraudes. Quizá tienes una cadena de suministro que hay que supervisar para garantizar que no se pierda nada. 

O tienes registros bancarios o financieros que requieren un 100 % de inmutabilidad. Habrá quienes digan: "justo de eso va el blockchain". Eh…puede. Ahora bien, si necesitas una solución de blockchain, mira por dónde, puedes usar Amazon Managed Blockchain. Aunque probablemente no sea lo que realmente necesitas. Resuelve parte de la ecuación, pero también descentraliza considerablemente, cosa que no gusta nada a los reguladores financieros. Lo que realmente necesitas es un libro mayor inmutable, como Amazon Quantum Ledger Database (QLDB). Es un sistema inmutable de registro en el que no se pueden eliminar entradas de las auditorías. 

Las bases de datos son geniales, pero, si se pueden hacer más rápidas, ¿no serían mejores? Evidentemente, no lo preguntaría si no tuviéramos aceleradores que se pudieran usar en numerosas situaciones únicas. Una solución es agregar capas de caché a las bases de datos para mejorar la velocidad de lectura de las solicitudes habituales de milisegundos a microsegundos. Amazon ElastiCache puede proporcionar esas capas de caché para ahorrarle a tus equipos las tediosas tareas de lanzamiento, aumento y mantenimiento. Está disponible en versiones para Memcached y Redis. 

Si utilizas DynamoDB, prueba DAX, el acelerador de DynamoDB, una capa de caché nativa diseñada para mejorar la velocidad de lectura de los datos no relacionales. 

Lo importante es saber que AWS quiere asegurarse de que utilizas la herramienta más adecuada.

////////////
Servicios de base de datos adicionales
////
Para obtener más información, selecciona el símbolo + que aparece junto a la categoría correspondiente.

////
Amazon DocumentDB
–
Amazon DocumentDB es un servicio de base de datos de documentos compatible con cargas de trabajo de MongoDB. (MongoDB es un programa de base de datos de documentos).

//////
Amazon Neptune
–
Amazon Neptune es un servicio de base de datos de gráficos. 
Puedes utilizar Amazon Neptune para crear y lanzar aplicaciones que funcionen con conjuntos de datos altamente conectados, como motores de recomendaciones, detección de fraude y gráficos de conocimiento.


////////
Amazon Quantum Ledger Database (Amazon QLDB)
–
Amazon Quantum Ledger Database (Amazon QLDB) es un servicio de base de datos de libro mayor. 
Puedes utilizar Amazon QLDB para revisar un historial completo de todos los cambios que se han realizado en los datos de la aplicación.

//////////
Amazon Managed Blockchain
–
Amazon Managed Blockchain es un servicio que puede utilizar para crear y administrar redes de blockchain con marcos de referencia de código abierto.
El blockchain es un sistema de libro mayor distribuido que permite que varias partes realicen transacciones y compartan datos sin una autoridad central.

/////////
Amazon ElastiCache
–
Amazon ElastiCache es un servicio que añade capas de almacenamiento sobre las bases de datos para ayudar a mejorar los tiempos de lectura de las peticiones comunes.
Es compatible con dos tipos de almacenes de datos: Redis y Memcached.


//////////
Acelerador de Amazon DynamoDB
–
Amazon DynamoDB Accelerator (DAX) es una caché en memoria para DynamoDB. 
Ayuda a mejorar los tiempos de respuesta de milisegundos de un dígito a microsegundos.







///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 6

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Explicar los beneficios del modelo de responsabilidad compartida.
Describir la autenticación multifactor (MFA).
Diferenciar entre los niveles de seguridad de AWS Identity and Access Management (IAM).
Explicar los principales beneficios de AWS Organizations.
Describir las políticas de seguridad a nivel básico.
Resumir los beneficios de la conformidad de AWS.
Explicar los servicios de seguridad adicionales de AWS a nivel básico.




////////////////////////////////
Ya vamos profundizando más en nuestra cuenta de AWS. Todo va bien. Ahora abordaremos las medidas de seguridad que tenemos. Es decir, quiero describir los mecanismos de seguridad que ofrecemos en la nube de AWS, como la responsabilidad compartida. 

Con este modelo, AWS controla la seguridad de la nube y los clientes controlan la seguridad en la nube. AWS controla los centros de datos, la seguridad de sus servicios y todos los niveles de esta sección. La siguiente parte son las cargas de trabajo de los clientes de AWS en la nube, cuya protección es responsabilidad de esos clientes. Es algo que compartimos con los clientes para garantizar la seguridad en la nube. 
Echemos un vistazo a los demás servicios de seguridad, mecanismos y características que AWS ofrece en este módulo. Ojo al dato. 


///////////////
Modelo de responsabilidad compartida
/////////////////

Cuando se trata de proteger sus empresas en AWS, es importante que se pregunten: "¿quién es el último responsable de la seguridad?". ¿Es la opción 1: el cliente? ¿O es la opción 2: AWS? Y la respuesta correcta es: sí. Ambos. Ambos son los últimos responsables de garantizar la seguridad. 
Ahora bien, si algún experto en seguridad está viendo esto, probablemente esté pensando que dos entidades distintas no pueden asumir la responsabilidad final de un mismo objeto, y que eso no es seguridad, sino ilusiones. En AWS estamos totalmente de acuerdo. Pero nosotros no consideramos el entorno del cliente como un solo objeto. Lo vemos como un conjunto de partes que están unas encima de las otras. AWS es responsable de la seguridad de algunos de los objetos. Responsable al 100 % de ellos. Y ustedes son responsables al 100 % de la seguridad de los demás. Esto es lo que se conoce como modelo de responsabilidad compartida. 

Es como el seguro de una casa. La constructora hizo la casa con cuatro paredes y una puerta. Es su responsabilidad asegurarse de que las paredes sean fuertes y las puertas, sólidas. En cambio, es responsabilidad del propietario de la vivienda cerrar con llave las puertas. 
Es así de sencillo en AWS. Tomemos EC2, por ejemplo. EC2 está en unas instalaciones físicas, un centro de datos que debe estar protegido. Tiene una red y un hipervisor que admiten sus instancias y sus sistemas operativos individuales. En ese sistema operativo, tienen su aplicación, que contiene sus datos. En EC2 y todos los servicios de AWS, existe una pila similar de partes unas encima de las otras. AWS es responsable de unas y ustedes, de las demás. 

Empecemos por la capa física. Esta está hecha de hierro y hormigón, tiene vallas y guardias de seguridad. Tiene que ser propiedad de alguien. Alguien tiene que vigilar el perímetro físico a todas horas. Ese alguien es AWS. Encima de la capa física, tenemos nuestra red e hipervisor. No voy a entrar en detalles sobre cómo lo protegemos, pero, en resumen, hemos reinventado esas tecnologías para hacerlas más rápidas, fuertes y totalmente seguras. 
Pero no tienen por qué fiarse de nuestra palabra. Muchos auditores externos han revisado el código y cómo creamos la infraestructura, y pueden facilitarles los documentos necesarios para sus estructuras de conformidad de seguridad. Además de todo eso, en EC2 pueden elegir qué sistema operativo quieren utilizar. 

Esta es la línea mágica divisoria que divide nuestra responsabilidad, la responsabilidad de AWS y  su responsabilidad. Este es su sistema operativo. Es 100 % su responsabilidad. AWS no tiene accesos secretos a sus sistemas. Solo ustedes disponen de la única clave de cifrado para iniciar sesión en la raíz de este SO o para crear cuentas de usuario. Al igual que una empresa constructora no guardaría copias de la llave de su puerta, AWS no puede entrar en su sistema operativo. De hecho, si alguien de AWS les llama y les piden la clave del sistema operativo, no es AWS. 

Eso significa que es responsabilidad de sus equipos de operaciones mantener el sistema operativo parcheado. Si AWS descubre que hay vulnerabilidades nuevas en su versión de Windows, por ejemplo, podemos notificar al propietario de la cuenta, pero no podemos parchear. Esto es algo muy bueno en cuanto a seguridad. Quiere decir que nadie puede implementar nada que dañe el sistema, solo pueden hacerlo sus equipos. Además en ese sistema operativo pueden lanzar las aplicaciones que quieran. Ustedes son los propietarios. Ustedes las mantienen. 

Lo que nos lleva a la parte más importante de la pila: sus datos. Datos: esto siempre está bajo su control. A veces, posiblemente quieran que todo el mundo pueda consultarlos, como las imágenes de una tienda en línea. Otras veces, como en el caso de la banca o la sanidad, posiblemente no. AWS proporciona a todos las herramientas que necesitan para poner sus datos a disposición de las personas autorizadas, de todo el mundo, o de una sola persona en condiciones específicas. O incluso bloquearlos para que nadie pueda acceder a ellos. Además, permite usar un cifrado ubicuo. Así, incluso si por accidente dejan abierta la puerta principal, todo lo que verá el intruso será contenido cifrado ilegible. 

La responsabilidad compartida de AWS consiste en asegurarse de que ambas partes sepan exactamente cuáles son sus tareas. En resumen, AWS es responsable de la seguridad de la nube y ustedes son responsables de la seguridad en la nube. Así, pueden disponer de un entorno fiable.




/////////////////
El modelo de responsabilidad compartida de AWS
////////////////

A lo largo de este curso hemos visto diversos recursos que se pueden crear en la nube de AWS. Estos recursos incluyen instancias de Amazon EC2, buckets de Amazon S3 y bases de datos de Amazon RDS. ¿Quién es responsable de mantener seguros estos recursos: tú (el cliente) o AWS?

La respuesta es ambos. El motivo es que el entorno de AWS no se trata como un único objeto. Más bien, se trata como una colección de piezas que se apoyan unas en otras. AWS es responsable de algunas piezas del entorno y tú (el cliente) de otras. Este concepto se conoce como modelo de responsabilidad compartida.

Se divide en responsabilidades del cliente (comúnmente denominadas "seguridad en la nube") y responsabilidades de AWS (comúnmente denominadas "seguridad de la nube").

Se puede pensar en este modelo como algo parecido a la división de responsabilidades entre el propietario y el constructor de una vivienda. El constructor (AWS) es responsable de construir la casa y garantizar que esté construida de forma sólida. Como propietario de la vivienda, es responsabilidad del cliente asegurar todo lo que hay en la casa vigilando que las puertas estén cerradas con llave. 

Para más información, selecciona el símbolo + que aparece junto a cada categoría.

/////////
Clientes: Seguridad en la nube
–
Los clientes son responsables de la seguridad de todo lo que crean y ponen en la nube de AWS.
Al utilizar los servicios de AWS, tú, el cliente, mantienes un control total sobre tu contenido. El cliente es responsable de administrar los requisitos de seguridad de su contenido, incluido qué contenido decides almacenar en AWS, qué servicios de AWS utilizas y quién tiene acceso a ese contenido. También controlas cómo se conceden, administran y revocan los derechos de acceso.

Los pasos de seguridad que des dependerán de factores tales como los servicios que utilizas, la complejidad de tus sistemas y las necesidades operativas y de seguridad específicas de tu empresa. Entre los pasos se incluyen la selección, configuración y aplicación de parches de los sistemas operativos que se utilizarás en instancias de Amazon EC2, la configuración de grupos de seguridad y la administración de cuentas de usuario. 


//////////
AWS: Seguridad de la nube
–
AWS es responsable de la seguridad de la nube.
AWS opera, administra y controla los componentes en todas las capas de la infraestructura. Esto incluye áreas como el sistema operativo host, la capa de virtualización e incluso la seguridad física de los centros de datos desde los que operan los servicios. 

AWS es responsable de proteger la infraestructura global que lanza todos los servicios ofrecidos en la nube de AWS. Esta infraestructura incluye regiones de AWS, zonas de disponibilidad y ubicaciones perimetrales.
AWS administra la seguridad de la nube, específicamente la infraestructura física que aloja tus recursos, que incluyen lo siguiente:

Seguridad física de los centros de datos.
Hardware e infraestructura de software.
Infraestructura de red.
Infraestructura de virtualización.
Aunque no puedes visitar los centros de datos de AWS para ver esta protección de primera mano, AWS proporciona varios informes de auditores de terceros. Estos auditores han verificado la conformidad de una variedad de estándares y regulaciones de seguridad informática.


///////////////////
Permisos y acceso de usuario
//////////////////

En la cafetería, cada empleado tiene una identidad. Entran a trabajar por la mañana e inician sesión en el sistema para fichar, usar los registros y administrar los sistemas de la cafetería todos los días. Tenemos cajas registradoras, el equipo que ayuda a que la cafetería funcione. Cada persona tiene acceso único a estos sistemas en función de quiénes son. 
Si Rudy está en caja recibiendo pedidos y Blaine está en la oficina comprobando el inventario en el equipo, cada uno tiene un inicio de sesión y un conjunto de permisos diferentes. Rudy puede usar la caja, pero, si quisiera iniciar sesión en el sistema de inventario, no podría hacerlo. 

Es recomendable definir el ámbito de permisos de cada usuario en AWS de manera similar. Cuando creas una cuenta en AWS, te conviertes en el usuario raíz de la cuenta. Este usuario raíz es el propietario de la cuenta de AWS y tiene permiso para hacer todo lo que quiera en la cuenta. Es como ser el propietario de la cafetería.
En este ejemplo, supongamos que soy la propietaria de la cafetería. Puedo entrar en la cafetería, usar mis credenciales para usar la caja, el sistema de inventario o cualquier otro sistema de la cafetería. No me pueden restringir. Como usuario raíz de AWS, puedes acceder y controlar cualquier recurso de la cuenta. Activar bases de datos, instancias EC2, servicios de cadenas de bloque o, literalmente, lo que quieras. Como es un usuario tan potente, te recomendamos que, en cuanto crees una cuenta en AWS e inicies sesión con tu usuario raíz, actives la autenticación multifactor (MFA) para asegurarte de que necesitas no solo el correo y la contraseña para iniciar sesión, sino también un token aleatorio. 

Perfecto. Pero incluso con la MFA activada, no es recomendable acceder con el usuario raíz para todo. Yo, como propietaria de la cafetería, no doy mi nivel de acceso a todos los empleados. Rudy, el de la caja, no puede acceder al sistema de inventario. Controla el acceso de forma granular mediante el servicio de AWS Identity and Access Management (IAM). 
En IAM, puedes crear usuarios de IAM. Una vez creado, no tendrá ningún permiso por defecto. El usuario ni siquiera puede iniciar sesión en la cuenta de AWS al principio; no tiene absolutamente ningún permiso. No puede lanzar instancias EC2. Ni crear S3 buckets. Nada. Tienes que dar permiso explícitamente al usuario para hacer cualquier cosa en la cuenta. Recuerda: de forma predeterminada, se deniegan todas las acciones. Debes permitir explícitamente cualquier acción de cualquier usuario. Da a la gente acceso solo a lo que necesita y a nada más. Este concepto se denomina principio de mínimo privilegio. 

Cómo concedes o deniegas permisos se asocia a lo que se denomina políticas de IAM para usuarios de IAM. Una política de IAM es un documento JSON que describe qué llamadas a la API puede o no hacer un usuario. Veamos un breve ejemplo. Aquí pueden ver una declaración de permisos donde el valor del efecto es "Permitir", el de la acción es "s3:ListBucket", y el recurso es un ID único de un S3 Bucket. Si adjunto esta política a un usuario, ese usuario podría ver el bucket "coffee_shop_reports", pero no realizar ninguna otra acción en esta cuenta. Solo hay dos valores posibles para el efecto en cualquier política. Permitir o denegar. Para la acción, pueden indicar cualquier llamada a la API de AWS. Para el recurso, puedes indicar a qué recurso de AWS se destina esa llamada a la API. Como la persona de negocios que eres, no tienes que escribir estas políticas, pero se usan en todas partes en tus cuentas de AWS. 

Para facilitar la administración de usuarios y sus permisos, puedes organizarlos en grupos de IAM. Los grupos son agrupaciones de usuarios. Puedes adjuntar una política a un grupo y todos los usuarios de ese grupo tendrán esos permisos. Si tenemos varios cajeros en la cafetería, en lugar de dar acceso a cada uno a la caja, podemos conceder acceso a todos y, después, agregar  cada cajero al grupo. Es la misma idea de los grupos de IAM. 

Vale. Hasta ahora, con IAM, eres el usuario raíz, que puede hacer cualquier cosa. Tienes usuarios que se pueden organizar en grupos. Y también tienes políticas, que son documentos que describen permisos que, después, puedes adjuntar a usuarios o grupos. Hay otra identidad importante en IAM: se denomina rol. 
Para comprender el concepto, volvamos a la cafetería. Como sabemos, Blaine trabaja en la tienda y, dependiendo de la cantidad de personal del día, podría estar en caja o gestionar el sistema de inventario, o podría ser quien limpie tras el cierre, sin acceder a ningún sistema. Yo, como propietaria, tengo autoridad para asignar estos roles a Blaine. Sus responsabilidades y acceso varían y lo hacen día a día. El hecho de que trabajara ayer revisando el inventario en el sistema no significa que deba hacerlo en cualquier momento. Su rol en el trabajo cambia y es de naturaleza temporal. El mismo concepto existe en AWS. Pueden crear identidades en AWS que se denominan roles. 

Los roles tienen permisos asociados que permiten o deniegan acciones. Y estos roles se pueden asumir de forma temporal. Es como un usuario, pero sin nombre de usuario ni contraseña. Más bien es una identidad que se puede asumir para tener permisos temporales. Los roles se usan para conceder acceso temporal a recursos de AWS, a usuarios, a identidades externas, a las aplicaciones e incluso a otros servicios de AWS. Cuando una identidad asume un rol, abandona todos los permisos que tenía y asume los de ese rol. Para no tener que crear usuarios de IAM para cada persona de sus organizaciones, pueden federar usuarios en su cuenta. Esto significa que podrían usar sus credenciales corporativas habituales para iniciar sesión en AWS asignando sus identidades corporativas a roles de IAM. Eso es AWS IAM: autenticación y autorización como servicio.



//////////////
AWS Identity and Access Management (IAM)
/////////////

AWS Identity and Access Management (IAM) permite administrar el acceso a los servicios y recursos de AWS de forma segura.   
IAM proporciona la flexibilidad de configurar el acceso en función de las necesidades operativas y de seguridad específicas de tu empresa. Esto se consigue mediante una combinación de funciones de IAM, que se analizan detalladamente en esta lección como puedes ver a continuación:

Usuarios, grupos y roles de IAM.
Políticas de IAM.
Autenticación multifactor.
También aprenderás las prácticas recomendadas para cada una de estas características.

//////////
Usuario raíz de la cuenta de AWS
//////////

Cuando crea por primera vez una cuenta en AWS, comienza con una identidad conocida como usuario raíz. 
Al usuario raíz se accede iniciando sesión con la dirección de correo electrónico y la contraseña que hayas utilizado para crear tu cuenta de AWS. Puedes pensar en el usuario raíz como si fuera el propietario de la cafetería. Tiene acceso completo a todos los servicios y recursos de AWS de la cuenta.


///////////
Usuarios de IAM
/////////

Un usuario de IAM es una identidad que se crea en AWS. Representa a la persona o aplicación que interactúa con los servicios y recursos de AWS. Consiste en un nombre y credenciales.
De forma predeterminada, cuando creas un nuevo usuario de IAM en AWS, no tendrá permisos asociados. Para permitir que el usuario de IAM realice acciones específicas en AWS como lanzar una instancia de Amazon EC2 o crear un bucket de Amazon S3, debes otorgarle los permisos necesarios.



///////////
Políticas de IAM
////////////

Una política de IAM es un documento que permite o deniega permisos a los servicios y recursos de AWS.  
Las políticas de IAM permiten personalizar los niveles de acceso de los usuarios a los recursos. Por ejemplo, puedes permitir que los usuarios accedan a todos los buckets de Amazon S3 de tu cuenta de AWS o solo a un bucket específico.


//////////
Ejemplo: política de IAM
/////////////////

A continuación se muestra un ejemplo de cómo funcionan las políticas de IAM. Supongamos que el propietario de la cafetería tiene que crear un usuario de IAM para un cajero recién contratado. El cajero necesita acceso a los recibos guardados en un bucket de Amazon S3 con el ID: AWSDOC-EXAMPLE-BUCKET.
En este ejemplo, la política de IAM permite una acción específica dentro de Amazon S3: ListObject. La política también menciona un ID de bucket específico: AWSDOC-EXAMPLE-BUCKET. Cuando el propietario adjunta esta política al usuario de IAM del cajero, le permitirá ver todos los objetos del bucket AWSDOC-EXAMPLE-BUCKET. 

Si el propietario quiere que el cajero pueda acceder a otros servicios y realizar otras acciones en AWS, el propietario debe adjuntar políticas adicionales para especificar estos servicios y acciones.

Supongamos que la cafetería ha contratado a algunos cajeros más. En lugar de asignar permisos a cada usuario de IAM individual, el propietario coloca a los usuarios en un grupo de IAM.



////////////////
Grupos IAM
///////////////

Un grupo de IAM es una conjunto de usuarios de IAM. Cuando se asigna una política de IAM a un grupo, a todos los usuarios del grupo se les conceden los permisos especificados por la política.

Este es un ejemplo de cómo podría funcionar en la cafetería. En lugar de asignar permisos a los cajeros de uno en uno, el propietario puede crear un grupo de IAM llamado "Cajeros". El propietario puede añadir usuarios de IAM al grupo y, a continuación, adjuntar permisos a nivel de grupo.
La asignación de políticas de IAM a nivel de grupo también facilita el ajuste de los permisos cuando un empleado se transfiere a otro puesto. Por ejemplo, si un cajero pasa a ser especialista de inventario, el propietario de la cafetería lo elimina del grupo de IAM "Cajeros" y lo añade al grupo de IAM "Especialistas de inventario". Esto garantiza que los empleados solo tengan los permisos necesarios para su rol actual.

¿Qué ocurre si un empleado de una cafetería no ha cambiado de puesto de forma permanente, sino que cambia entre diferentes estaciones de trabajo a lo largo del día? Este empleado puede obtener el acceso que necesita a través de los roles de IAM.

///////////////
Roles de IAM
//////////////

En la cafetería, un empleado cambia entre diferentes estaciones de trabajo a lo largo del día. Dependiendo del personal de la cafetería, este empleado podría desempeñar varias tareas: trabajar en la caja registradora, actualizar el sistema de inventario, procesar pedidos en línea, etc. 

Cuando el empleado necesita cambiar a una tarea diferente, deja su acceso a una estación de trabajo y obtiene acceso a la siguiente estación de trabajo. El empleado puede cambiar fácilmente entre estaciones de trabajo pero, en todo momento, tiene acceso solo a una estación de trabajo. Este mismo concepto existe en AWS con roles de IAM.

Un rol de IAM es una identidad que se puede adoptar para obtener acceso temporal a los permisos. 

Para que un usuario, una aplicación o un servicio de IAM pueda adoptar un rol de IAM antes se le deben conceder permisos para cambiar a ese rol. Cuando alguien adopta un rol de IAM, abandona todos los permisos anteriores que tenía bajo un rol anterior y adopta los permisos del nuevo rol.


Ejemplo: roles de IAM
Para ver un ejemplo de cómo se pueden utilizar los roles de IAM en la cafetería, selecciona Comenzar.
Ejemplo: roles de IAM
Para ver un ejemplo de cómo se pueden utilizar los roles de IAM en la cafetería, selecciona Comenzar.

Paso 1

En primer lugar, el propietario concede al empleado permisos para cambiar a un rol para cada estación de trabajo de la cafetería.

Ejemplo: roles de IAM
Para ver un ejemplo de cómo se pueden utilizar los roles de IAM en la cafetería, selecciona Comenzar.

INICIAR 
Paso 1

rJzrsK0az-AyZ07f-missing_img.png
En primer lugar, el propietario concede al empleado permisos para cambiar a un rol para cada estación de trabajo de la cafetería.


Paso 2
El empleado comienza su día asumiendo el rol de "Cajero". Esto le otorga acceso al sistema de caja registradora.
Más tarde, el empleado necesita actualizar el sistema de inventario. Adoptan el rol de "Inventario". 
Esto otorga al empleado acceso al sistema de inventario y también revoca su acceso al sistema de caja registradora.



///////////////////////////
Autenticación multifactor
/////////////////////////

¿Alguna vez ha iniciado sesión en un sitio web que requiere que proporcione varios datos para verificar su identidad? Es posible que haya tenido que proporcionar su contraseña y, a continuación, una segunda forma de autenticación, como un código aleatorio enviado a su teléfono. Este es un ejemplo de autenticación multifactor.
En IAM, la autenticación multifactor (MFA) proporciona una capa adicional de seguridad para su cuenta de AWS.

///
Cómo funciona la autenticación multifactor
Para revisar los pasos relacionados con la autenticación multifactor, seleccione Comenzar.

Cómo funciona la autenticación multifactor
Para revisar los pasos relacionados con la autenticación multifactor, seleccione Comenzar.

INICIAR 
Paso 1
En primer lugar, cuando un usuario inicia sesión en un sitio web de AWS, introduce su ID de usuario y su contraseña de IAM.

Cómo funciona la autenticación multifactor
Para revisar los pasos relacionados con la autenticación multifactor, seleccione Comenzar.

INICIAR 
Paso 1
ApnC09tp4dVjrKtB-Image24.png
En primer lugar, cuando un usuario inicia sesión en un sitio web de AWS, introduce su ID de usuario y su contraseña de IAM.


Paso 2
Ilustración de un token de hardware
A continuación, se solicita al usuario una respuesta de autenticación desde su dispositivo MFA de AWS. Este dispositivo podría ser una clave de seguridad de hardware, un dispositivo de hardware o una aplicación MFA en un dispositivo como un smartphone.

///
Cuando el usuario se ha autenticado correctamente, puede acceder a los servicios o recursos de AWS solicitados.
Puede habilitar MFA para el usuario raíz y los usuarios de IAM. Como práctica recomendada, habilite MFA para el usuario raíz y todos los usuarios de IAM de su cuenta. De este modo, puede mantener su cuenta de AWS a salvo del acceso no autorizado.


////////////////////

AWS Organizations
/////////////////////

La primera vez que uses la nube de AWS, lo más probable es que empieces con una cuenta de AWS y metas todo allí. La mayoría empieza así, pero a medida que la empresa crece o comienzas el cambio a la nube, es importante separar tareas. Por ejemplo, que tus desarrolladores tengan acceso a recursos de desarrollo, que el personal de contabilidad acceda a datos de facturación o tener unidades de negocio separadas para que cada una pueda probar los servicios de AWS sin afectar a las demás. Así se van creando cuentas, una por cada persona que se incorpore a la empresa. Hasta que, un día, descubres que tienen una maraña de cuentas de AWS y eso no es precisamente bueno. 

Por ejemplo, tendrías que supervisar las cuentas A, F y G, y quizá la cuenta B tiene los permisos incorrectos y la cuenta C accede a datos de facturación y conformidad. Una forma de poner orden y definir los permisos de cada persona para desempeñar funciones concretas y en qué cuenta es usar un servicio de AWS denominado AWS Organizations. 

Para ponerlo fácil, Organizations es como una ubicación central para gestionar cuentas de AWS. Puedes gestionar facturación, acceso, conformidad y seguridad, y compartir recursos entre tus cuentas de AWS. Veamos algunas características clave de AWS Organizations. ¿Te parece? 
Primero: administración centralizada de todas las cuentas de AWS. Volvamos al ejemplo de las cuentas de AWS: A, B, C, F y G. Ahora puedes combinarlas en una organización que permite gestionarlas de forma centralizada y... ¡pum! Resulta que encuentras las cuentas D y E mientras tanto. 

Segundo: facturación unificada de todas las cuentas miembro. Es decir, puedes usar la cuenta principal de tu organización para consolidar y pagar todas las cuentas miembro. Otra ventaja de esta facturación son los descuentos por volumen. Efectivamente, dinero. 

Tercero: puedes implementar grupos jerárquicos en las cuentas según tus necesidades presupuestarias, de conformidad o de seguridad. Es decir, puedes agrupar cuentas en unidades organizativas (OU) como si fueran unidades de negocio (BU). Por ejemplo, si tienes cuentas que deben acceder solo a los servicios de AWS que cumplen ciertos requisitos normativos, puedes meter esas cuentas en una OU. O, si tienes cuentas que corresponden a la OU de desarrolladores, puedes agruparlas según ese criterio. 

Una de las características clave de las que hablaremos es que tienes el control de los servicios de AWS y las acciones de la API a las que cada cuenta puede acceder como administrador principal de la organización. Puedes usar algo denominado políticas de control de servicios, o SCP, para especificar la cantidad máxima de permisos de las cuentas de la organización. En resumen, con SCP puedes restringir a qué servicios, recursos y acciones de la API de AWS pueden acceder los usuarios y los roles de cada cuenta miembro.


///////////////
AWS Organizations
///////////////

Supongamos que tu empresa tiene varias cuentas de AWS. Puedes utilizar AWS Organizations para unificar y administrar varias cuentas de AWS en una ubicación central.
Al crear una organización, AWS Organizations crea automáticamente una raíz, que es el contenedor principal de todas las cuentas de su organización. 
En AWS Organizations, puedes controlar de forma centralizada los permisos de las cuentas de la organización mediante políticas de control de servicios (SCP). Las SCP permiten imponer restricciones a los servicios, recursos y acciones de API individuales de AWS a las que pueden acceder los usuarios y roles de cada cuenta.



/////////////
Unidades organizativas
////////////

En AWS Organizations, puedes agrupar las cuentas en unidades organizativas (UO) para facilitar la administración de cuentas con requisitos empresariales o de seguridad similares. Cuando se aplica una política a una unidad organizativa, todas las cuentas de la unidad organizativa heredan automáticamente los permisos especificados en la política.  

Al organizar cuentas separadas en unidades organizativas, se puede aislar con mayor facilidad las cargas de trabajo o las aplicaciones que tienen requisitos de seguridad específicos. Por ejemplo, si tu empresa tiene cuentas que solo pueden acceder a los servicios de AWS que cumplen determinados requisitos reglamentarios, puedes colocar estas cuentas en una unidad organizativa. A continuación, se puede adjuntar una política a la unidad organizativa que bloquea el acceso a todos los demás servicios de AWS que no cumplen los requisitos normativos.


/////
Ejemplo: AWS Organizations
Para ver un ejemplo de cómo una empresa podría utilizar AWS Organizations, selecciona Comenzar.

Paso 1
Imagina que tu empresa tiene cuentas de AWS independientes para los departamentos de finanzas, tecnologías de la información (TI), recursos humanos (RR. HH. ) y legal. Decides consolidar estas cuentas en una única organización para poder administrarlas desde una ubicación central. Al crear la organización, se establece la raíz.
Al diseñar la organización, se tienen en cuenta las necesidades empresariales, de seguridad y reglamentarias de cada departamento. Esta información se utiliza para decidir qué departamentos se agrupan en las UO.


Paso 2
Los departamentos de finanzas y TI tienen requisitos que no se superponen con los de ningún otro departamento. Incorporas estas cuentas a tu organización para aprovechar beneficios como la facturación unificada, pero no las coloques en ninguna unidad organizativa (UO).

Paso 3
Los departamentos de recursos humanos y legal necesitan acceder a los mismos servicios y recursos de AWS, de modo que hay que colocarlos juntos en una unidad organizativa. Colocarlos en una unidad organizativa te permite adjuntar políticas que se aplican tanto a las cuentas de AWS del departamento de recursos humanos como al de legal.



////////////////////

Conformidad
/////////////////

En cada sector hay estándares específicos que deben respetarse y se hacen auditorías o inspecciones para asegurar que se han cumplido. Por ejemplo, en una cafetería, el inspector de sanidad va a comprobar que todo se ajuste a la legislación y la normativa sanitaria. Igual, puede haber una auditoría fiscal para comprobar que todo se ha gestionado correctamente y que se ha cumplido la ley. 

Se necesitan documentos, registros e inspecciones para aprobar las auditorías y las comprobaciones de conformidad. Hay que hacer algo similar para cumplir la normativa y pasar auditorías en AWS. Dependiendo del tipo de soluciones que alojes en AWS, deberás asegurarte de que cumplen los estándares y la normativa a los que debe ajustarse tu empresa. Si utilizas software que procesa datos de consumidores de la UE, tienes que asegurarte de cumplir con el RGPD. Si lanzas aplicaciones sanitarias en los EE. UU., el diseño de sus arquitecturas deberá cumplir normativa de la HIPAA. 

Sea cual sea la exigencia normativa, necesitarás herramientas para recopilar documentos, registros e inspeccionar el entorno de AWS para comprobar si cumples las normativas aplicables a las que hay que ajustarse. Tengamos en cuenta que AWS ya ha creado una infraestructura del centro de datos y redes aplicando prácticas recomendadas del sector en materia de seguridad y, como clientes de AWS, heredan esas prácticas recomendadas de políticas, arquitectura y procesos operativos de AWS. 

AWS cumple una larga lista de programas de garantía que puedes encontrar en línea. Esto significa que puedes contar con que ya estás cumpliendo parte de la normativa y puedes centrarse en que la cumplan las arquitecturas que crees en AWS. Lo siguiente que debes saber sobre conformidad y AWS es que la región en la que decidas operar podría ayudarte a cumplir la normativa de conformidad. Si, por ley, solo puedes almacenar datos en el país del que proceden, puedes elegir una región que le permita cumplir ese requisito y AWS no replicará automáticamente los datos en las demás regiones. 

Recuerda también que tú eres el propietario de tus datos en AWS. Como se ve en el modelo de responsabilidad compartida de AWS, tienes control total de los datos que almacenas en AWS. Puedes aplicar mecanismos de cifrado distintos para proteger los datos, que varían según el servicio. Si necesitas estándares concretos para el almacenamiento de datos, puedes idear una forma de cumplir esos requisitos aplicando tus soluciones en AWS o usando las que hay disponibles en muchos de los servicios. En muchos de ellos, la protección de datos se puede activar en la configuración del recurso. 

AWS también ofrece documentos técnicos, entre otros, que puedes descargar y usar en tus informes de conformidad. Como no eres quien gestiona el centro de datos, puedes pedirle a AWS documentación que demuestre que se siguen las prácticas recomendadas de seguridad y conformidad. 

Puedes acceder a estos documentos mediante el servicio AWS Artifact. Con AWS Artifact, puedes acceder a informes de conformidad realizados por terceros que han validado numerosos estándares de conformidad. En el Centro de Conformidad de AWS encontrarás toda la información al respecto en un solo lugar. Verás qué servicios permiten cumplir normativas y materiales como el documento técnico de seguridad y riesgos de AWS, que debes leer para asegurarte de que conoces la seguridad y conformidad con AWS. 

Para corroborar tu conformidad con respecto a AWS, recuerdaque la responsabilidad es compartida. La plataforma subyacente es segura y AWS puede facilitar documentos sobre los tipos de requisitos de conformidad que cumple a través de servicios como AWS Artifact y documentos técnicos. Pero, aparte de eso, lo que crees en AWS es responsabilidad tuya. Tú controlas la arquitectura de aplicaciones y las soluciones que creaa, y debes hacerlo considerando la conformidad, la seguridad y la responsabilidad compartida.

///////////////////////
AWS Artifact
/////////////////////

Según el sector de tu empresa, es posible que debas respetar estándares específicos. Una auditoría o inspección garantizará que la empresa cumple esos estándares.

AWS Artifact es un servicio que proporciona acceso bajo demanda a los informes de seguridad y conformidad de AWS y a determinados acuerdos en línea. AWS Artifact consta de dos secciones principales: AWS Artifact Agreements y AWS Artifact Reports.

Para más información, selecciona el símbolo + que aparece junto a cada sección.


//////////////////////////////
AWS Artifact Agreements
////////////////////////////
–
Supongamos que tu empresa necesita firmar un acuerdo con AWS en relación con el uso de determinados tipos de información en los servicios de AWS. Puedes hacerlo a través de AWS Artifact Agreements. 

En AWS Artifact Agreements, puedes revisar, aceptar y administrar los acuerdos de una cuenta individual y de todas tus cuentas de AWS Organizations. Se ofrecen diferentes tipos de acuerdos para abordar las necesidades de los clientes que están sujetos a regulaciones específicas, como la Ley de transferibilidad y responsabilidad del seguro sanitario (HIPAA).


////////////////////////////////
AWS Artifact Reports
//////////////////////////////
–
A continuación, supongamos que un miembro del equipo de desarrollo de tu empresa está creando una aplicación y necesita más información sobre la responsabilidad de cumplir con ciertos estándares regulatorios. Puedes aconsejarle que acceda a esta información en AWS Artifact Reports.

AWS Artifact Reports proporciona informes de conformidad de auditores de terceros. Estos auditores han probado y verificado que AWS cumple una serie de estándares y regulaciones de seguridad globales, regionales y específicas del sector. AWS Artifact Reports permanece actualizado con los últimos informes publicados. Puedes proporcionarle a los auditores o reguladores dichos informes de Artifact como prueba de los controles de seguridad de AWS.



/////
A continuación, se enumeran algunos de los informes y regulaciones de conformidad que se pueden encontrar en AWS Artifact. Cada informe incluye una descripción de su contenido y del periodo de validez del informe.


////////////////////////////////////////
Centro de conformidad para clientes
////////////////////////////////////////

El Centro de conformidad para clientes contiene recursos donde obtener más información sobre la conformidad de AWS. 

Ahí puedes leer historias de conformidad de clientes para descubrir cómo las empresas en sectores regulados han resuelto diversos desafíos de conformidad, dirección y auditoría.

También puedes acceder a documentos técnicos sobre conformidad y documentación sobre temas tales como los siguientes:

Respuestas de AWS a las preguntas clave de conformidad.
Información general del riesgo y la conformidad de AWS.
Lista de verificación de seguridad de auditoría.
Además, el Centro de conformidad para clientes incluye una ruta de aprendizaje del auditor. Esta ruta de aprendizaje está diseñada para personas que desempeñan funciones jurídicas y de auditoría y conformidad, y que quieren obtener más información sobre cómo sus operaciones internas pueden demostrar conformidad usando la nube de AWS.


///////////////////////////////////////
Ataques de denegación de servicio
/////////////////////////////////////
D-D-o-S: DDoS, denegación de servicio distribuida. Es un ataque a la infraestructura de la empresa del que ya habrás oído hablar. Quizá tu equipo de seguridad ha creado un plan para ello y sabes que muchas empresas han sido víctimas de esos ataques. Pero, ¿qué es exactamente? Y lo más importante: ¿cómo defenderse de uno? (Suspira) 

La verdad es que necesitaríamos unas 14 horas para explicarlo todo, pero es importante conocer al menos lo básico sobre cómo se llevan a cabo los ataques y cómo AWS puede defender automáticamente tu infraestructura de estos ataques incapacitantes. No tenemos mucho tiempo para abarcarlo todo y el cronómetro empieza ahora. (Tambor de suspense) (Tic tac de reloj) (Suspira) El objetivo de un ataque DDoS es anular la capacidad de su aplicación para funcionar sobrecargando el sistema hasta que no pueda funcionar. (Zumbido) 

Normalmente, (sonido digital de pantalla) la aplicación recibe solicitudes de los clientes y devuelve los resultados. En un ataque DDoS, el villano intenta sobrecargar la capacidad de la aplicación para negar a cualquiera sus servicios. Pero si una sola máquina ataca la aplicación, su ataque no es lo suficientemente potente, así que la parte distribuida del ataque es que usa otras máquinas de Internet para atacar la infraestructura sin saberlo. El villano crea un ejército de bots zombis que atacan su empresa sin saberlo. La clave de un buen ataque, aunque debería llamarlo "poderoso". O sea, es que es aleatoriamente maligno. Bueno, la clave es que el comandante de asalto haga el trabajo mínimo necesario para que la víctima reciba una carga insoportable de trabajo que debe procesar. 

He elegido algunos ejemplos de ataque específicos que funcionan muy bien. (Zumbido) La inundación UDP. (Teclado) (Zumbido) Se basa en las partes útiles de Internet, como el servicio meteorológico nacional. Cualquiera puede enviar una solicitud al servicio meteorológico preguntando: "¿qué tiempo hace?", y la flota de máquinas de ese servicio le enviará una gran cantidad de telemetría, pronósticos y actualizaciones del clima, etc. Así que este ataque es simple. El villano envía una solicitud sencilla: "¿qué tiempo hace?". Pero proporciona una dirección de devolución falsa en la solicitud: tu dirección de devolución. El servicio meteorológico inunda tu servidor con megabytes de pronósticos de lluvia y el sistema se podría paralizar solo ordenando información que nunca pidió.(Zumbido) Este es uno de varios ejemplos de ataques de fuerza bruta de bajo nivel diseñados para agotar tu red. 

Otros ataques son más sofisticados, (sonido digital) como los ataques de HTTP, que parecen clientes normales que piden cosas normales, como búsquedas complicadas de productos, una y otra vez, todo procedente de un ejército de máquinas bot zombis. Demandan tanta atención que los clientes habituales no pueden entrar. 

Incluso hacen cosas terribles como el ataque Slowloris. Sí. Imagina que estás en la fila de la cafetería y la persona de delante tarda siete minutos en hacer su pedido y tú no puedes pedir hasta que esa persona termine y se quite de en medio. (Sonido digital) El ataque Slowloris es exactamente lo mismo. En lugar de una conexión normal, que sería como hacer un pedido, el atacante simula tener una conexión superlenta. (Ininteligible) Ya te imaginas. Mientras tanto, tus servidores de producción están ahí, esperando a que el cliente termine su solicitud para procesarla rápido y devolver el resultado. Pero hasta tener todo el paquete, no pueden pasar al siguiente hilo, que sería el próximo cliente. Algunos atacantes de Slowloris pueden agotar la capacidad de todo el frontend sin ningún esfuerzo. (Zumbido) (Suspira) Podría pasar horas hablando sin parar de la exquisita arquitectura de estos ataques, pero vamos contra reloj y es hora de frenar estos ataques. Lo bueno es que ya sabes la solución. 

Todo de lo que hemos hablado durante el curso no solo es una buena arquitectura, sino que también ayuda a defenderse de casi todos los ataques DDoS sin esfuerzo ni coste adicional. Para el primer ejemplo, los ataques de red de bajo nivel como las inundaciones UDP, la solución es grupos de seguridad. Los grupos de seguridad solo permiten el tráfico de solicitudes adecuadas. Elementos como los informes meteorológicos utilizan un protocolo completamente diferente al que usan tus clientes. Si no está en la lista, no puede llegar al servidor. Además, los grupos de seguridad operan a nivel de la red de AWS, no a nivel de instancia EC2, como un firewall del sistema operativo. 

Los ataques masivos, como inundaciones UDP o ataques de reflexión, simplemente son ignorados por toda la capacidad de regiones de AWS, no solo por la de tus EC2 individuales. En este caso, nuestro tamaño es una gran ventaja para tu protección. No quiero decir que sea imposible sobrecargar AWS, pero la escala necesaria sería demasiado cara para estos villanos. (Sonido digital) ¿Ataques Slowloris? Veamos Elastic Load Balancer. Como ELB gestiona primero la solicitud de tráfico HTTP, espera a que se complete el mensaje, sin importar si tarda mucho o poco, antes de enviarlo al servidor web frontend. 

Se puede intentar sobrecargar, pero, como ELB es escalable funciona a nivel de región, para conseguirlo se tendría que sobrecargar toda la región de AWS. Teóricamente es posible, pero es demasiado caro como para que alguien llegue a hacerlo. (Zumbido) Para los ataques más inteligentes y sofisticados, AWS ofrece herramientas de defensa llamadas AWS Shield con AWS WAF. (Sonido digital) AWS WAF usa un firewall de aplicación web para filtrar el tráfico entrante en busca de rastros de los villanos. Cuenta con una amplia capacidad de machine learning, puede reconocer nuevas amenazas en desarrollo y ayuda a defender tus sistemas contra una lista cada vez mayor de vectores destructivos. (Zumbido) Veamos. Casi se ha acabado el tiempo. 

En resumen, una buena arquitectura está protegida de la mayoría de los ataques y, con AWS Shield Advanced, puedes convertir AWS en tu aliado contra ataques DDoS. Oh. (Tambor de suspense) (Tic tac de reloj)


/////
Los clientes pueden llamar a la cafetería para hacer sus pedidos. Tras contestar cada llamada, un cajero apunta el pedido y se lo entrega al camarero. 

Sin embargo, supongamos que un bromista llama varias veces para hacer pedidos, pero nunca pasa a recoger las bebidas. Esto provoca que el cajero no pueda atender las llamadas de otros clientes. La cafetería puede intentar detener las solicitudes falsas bloqueando el número de teléfono que usa el bromista. 

En esta situación, las acciones del bromista son similares a un ataque de denegación de servicio.


//////////////////////////////////
Ataques de denegación de servicio
////////////////////////////////////////

Un ataque de denegación de servicio (DoS) es un intento deliberado por hacer que un sitio web o una aplicación no estén disponibles para los usuarios.

Por ejemplo, un atacante podría inundar un sitio web o una aplicación con tráfico de red excesivo hasta que el sitio web o la aplicación objetivo se sobrecarguen y ya no puedan responder. Si el sitio web o la aplicación no están disponibles, los usuarios que están realizando peticiones legítimas no pueden usar el servicio.


/////////////////////////////////////
Ataques de denegación de servicio distribuidos
///////////////////////////////////////////////////

Supongamos que el bromista ha conseguido la ayuda de amigos. 

El bromista y sus amigos llaman repetidamente a la cafetería para hacer pedidos, aunque no tengan la intención de recogerlos. Estas solicitudes vienen de diferentes números de teléfono y es imposible que la cafetería los bloquee todos. Además, la afluencia de llamadas ha dificultado cada vez más que se pueda atender las llamadas del resto de los clientes. Esto es similar a un ataque de denegación de servicio distribuido.

Image16.png
En un ataque de denegación de servicio distribuida (DDoS), se utilizan varias fuentes para iniciar un ataque, cuyo objetivo es que un sitio web o una aplicación no estén disponibles. Esto puede proceder de un grupo de atacantes o incluso de un solo atacante. El único atacante puede utilizar varios equipos infectados (también conocidos como "bots") para enviar tráfico excesivo a un sitio web o a una aplicación.

Para ayudar a minimizar el efecto de los ataques DoS y DDoS en sus aplicaciones, puedes utilizar AWS Shield.


///////////////////////
AWS Shield
////////////////

AWS Shield es un servicio que protege las aplicaciones contra ataques DDoS. AWS Shield proporciona dos niveles de protección: Standard y Advanced.

Para más información, selecciona el símbolo + que aparece junto a cada servicio.


/////////////////////////
AWS Shield Standard
////////////////////////
–
AWS Shield Standard protege automáticamente a todos los clientes de AWS sin coste alguno. Protege los recursos de AWS de los tipos de ataques DDoS más comunes y frecuentes.

A medida que el tráfico de red llega a las aplicaciones, AWS Shield Standard utiliza diversas técnicas de análisis para detectar el tráfico malicioso en tiempo real y mitigarlo automáticamente.


//////////////////////////
AWS Shield Advanced
/////////////////////////
–
AWS Shield Advanced es un servicio de pago que proporciona diagnósticos de ataques detallados y la capacidad de detectar y mitigar ataques DDoS sofisticados.

También se integra con otros servicios como Amazon CloudFront, Amazon Route 53 y Elastic Load Balancing. Además, puede integrar AWS Shield con AWS WAF escribiendo reglas personalizadas para mitigar ataques DDoS complejos.


///////////////////////////////////////
Servicios de seguridad adicionales
////////////////////////////////////

Con todas las entradas y salidas de la cafetería, sería aconsejable mejorar la seguridad del café en grano, del equipo y del dinero de la caja. La seguridad del café sería aplicable en el almacén, o cuando los lleve de una tienda a otra. Es normal que no queramos que intrusos tengan acceso al café en grano, ni que huyan llevándose nuestros valiosos equipos. 

Para empezar, hablemos sobre cómo puedes proteger el café en grano, que serían los datos, ya sea almacenados o en tránsito. Para proteger el café, la forma sencilla sería cerrar con llave cuando nos vamos por la noche. En algo así consiste el cifrado, en proteger un mensaje o datos de modo que solo puedan acceder a ellos partes autorizadas. Las partes no autorizadas es menos probable que puedan acceder al mensaje o no podrán acceder en absoluto. Es como el ejemplo de llave y puerta. Si tienen la llave, pueden abrir la puerta. Si no la tienen, no pueden abrirla. 

En AWS hay dos variaciones: cifrado en reposo y cifrado en tránsito. En reposo es cuando los datos están inactivos. Están almacenados sin moverse. Por ejemplo, el cifrado en reposo del servidor está habilitado en los datos de DynamoDB. Eso ayuda a evitar el acceso no autorizado. El cifrado en reposo de DynamoDB también se integra con AWS KMS, o servicio de gestión de claves, para gestionar la clave de cifrado que se usa para cifrar las tablas. Es la llave de la puerta del ejemplo. Sin ella, no puedes acceder a los datos, así que guárdala en un lugar seguro. 

Del mismo modo, en tránsito es aplicable a los datos que se desplazan, por ejemplo, entre A y B. A sería el servicio de AWS y B podría ser un cliente que accede al servicio u otro servicio de AWS. Imaginemos que tenemos una instancia de Redshift en uso y queremos conectarla con un cliente SQL. Usamos la capa de puertos seguros (conexiones SSL) para cifrar datos y podemos usar certificados de servicio para validar y autorizar a un cliente. Así, los datos están protegidos al pasar entre Redshift y nuestro cliente. Esta funcionalidad existe en muchos servicios de AWS como SQS, S3 o RDS, entre otros. 

Hablando de otros servicios, el siguiente que queremos destacar es Amazon Inspector. Inspector ayuda a mejorar la seguridad y la conformidad de las aplicaciones implementadas en AWS llevando a cabo una evaluación de seguridad automatizada de la infraestructura. Ayuda a comprobar si no se han aplicado prácticas recomendadas de seguridad, la exposición de instancias EC2, las vulnerabilidades, etc. El servicio consta de tres partes: una parte de accesibilidad de la configuración de red, un agente de Amazon instalable en instancias EC2 y una evaluación de seguridad que lo agrupa todo. Para usarlo, configura el inspector, inicia el servicio, y aparecerá una lista de posibles problemas de seguridad. Los resultados se muestran en la consola de Amazon Inspector y se presentan una descripción detallada de cada problema de seguridad y un consejo para solucionarlo. Además, puedes recuperar los resultados mediante una API para aplicar la práctica recomendada y corregir esos problemas. 

Otra dimensión de servicio es el de detección de amenazas, conocido como Amazon GuardDuty. Analiza flujos continuos de metadatos generados a partir de tu cuenta y la actividad de red de los eventos de AWS CloudTrail, los registros de flujo de Amazon VPC y los registros DNS. Usa inteligencia de amenazas integrada, como direcciones IP maliciosas conocidas, detección de anomalías y machine learning para identificar las amenazas con mayor precisión. Lo mejor de todo es que funciona de forma independiente de los demás servicios de AWS. Por lo tanto, no afecta al rendimiento ni a la disponibilidad de la infraestructura ni a las cargas de trabajo. 

Hay otros servicios de seguridad como Advanced Shield y Security Hub. Consulta la sección de recursos para más información. Gracias por tu atención.



/////////////////////////////////////////
AWS Key Management Service (AWS KMS)
/////////////////////////////////////

La cafetería tiene muchos artículos como cafeteras, pasteles, dinero en las cajas registradoras, etc. Puedes pensar en estos elementos como si fueran datos. Los propietarios de la cafetería quieren asegurarse de que todos estos artículos estén protegidos, tanto si se encuentran en el trastero como si los transportan de una tienda a otra. 

Del mismo modo, debes asegurarte de que los datos de tus aplicaciones estén protegidos mientras están almacenados (cifrado en reposo) y mientras se transmiten, lo que se conoce como cifrado en tránsito.

AWS Key Management Service (AWS KMS) permite realizar operaciones de cifrado mediante el uso de claves criptográficas. Una clave criptográfica es una cadena aleatoria de dígitos utilizada para bloquear (cifrar) y desbloquear (descifrar) datos. Puedes utilizar AWS KMS para crear, administrar y utilizar claves criptográficas. También puedes controlar el uso de claves en una amplia gama de servicios y aplicaciones.

Con AWS KMS, puedes elegir los niveles específicos de control de acceso que necesitas para las claves. Por ejemplo, se puede especificar qué usuarios y roles de IAM son capaces de administrar las claves. También puedes deshabilitar temporalmente las claves para que nadie las siga utilizando. Las claves nunca salen de AWS KMS y siempre tendrás el control sobre ellas.


///////////
AWS WAF
//////////
AWS WAF es un firewall de aplicaciones web que permite supervisar las peticiones de red que llegan a las aplicaciones web. 

AWS WAF trabaja junto con Amazon CloudFront y un Application Load Balancer. Recuerda las listas de control de acceso a la red que se han tratado en un módulo anterior. AWS WAF funciona de forma similar para bloquear o permitir el tráfico. Sin embargo, lo hace utilizando una lista de control de acceso (ACL) web para proteger tus recursos de AWS. 

A continuación se muestra un ejemplo de cómo utilizar AWS WAF para permitir y bloquear peticiones específicas.

Supongamos que tu aplicación ha estado recibiendo peticiones de red maliciosas de varias direcciones IP. Quieres evitar que estas peticiones sigan accediendo a la aplicación, pero también quieres asegurarte de que los usuarios legítimos puedan seguir accediendo a ella. Para ello, puedes configurar la ACL web para permitir todas las peticiones, excepto las de las direcciones IP especificadas.

Cuando una petición llega a AWS WAF, este comprueba la lista de reglas configuradas en la ACL web. Si una petición no procede de una de las direcciones IP bloqueadas, se permite el acceso a la aplicación.

Sin embargo, si una petición procede de una de las direcciones IP bloqueadas especificadas en la ACL web, se le deniega el acceso.


////////////////////////////////////
Amazon Inspector
/////////////////////////////
Supongamos que los desarrolladores de la cafetería están desarrollando y probando una nueva aplicación de pedidos. Quieren asegurarse de que están diseñando la aplicación siguiendo las prácticas recomendadas de seguridad. Sin embargo, tienen otras aplicaciones que desarrollar, por lo que no pueden dedicar mucho tiempo a realizar evaluaciones manuales. Para realizar evaluaciones de seguridad automatizadas, deciden utilizar Amazon Inspector.

Amazon Inspector ayuda a mejorar la seguridad y la conformidad de las aplicaciones mediante evaluaciones de seguridad automatizadas. Comprueba las vulnerabilidades de seguridad y las desviaciones de las prácticas recomendadas de seguridad de las aplicaciones, como el acceso abierto a instancias de Amazon EC2 y las instalaciones de versiones de software vulnerables. 

Una vez que Amazon Inspector ha realizado una evaluación, proporciona una lista de los resultados de seguridad. La lista ordena por nivel de severidad e incluye una descripción detallada de cada problema de seguridad, así como una recomendación sobre cómo solucionarlo. Sin embargo, AWS no garantiza que siguiendo las recomendaciones proporcionadas se solucionen todos los posibles problemas de seguridad. Según el modelo de responsabilidad compartida, los clientes son responsables de la seguridad de sus aplicaciones, procesos y herramientas utilizadas en los servicios de AWS.


/////////////////////////////
Amazon GuardDuty
/////////////////////

Amazon GuardDuty es un servicio que proporciona detección inteligente de amenazas para tu infraestructura y recursos de AWS. Identifica las amenazas mediante el seguimiento continuo de la actividad de la red y el comportamiento de la cuenta en tu entorno de AWS.


Tras habilitar GuardDuty en su cuenta de AWS, este comienza a supervisar la actividad de la red y de la cuenta. No es necesario implementar ni administrar ningún software de seguridad adicional. GuardDuty analiza continuamente los datos de varias fuentes de AWS, incluidos los registros de flujo de VPC y los registros DNS. 

Si GuardDuty detecta amenazas, los resultados detallados se pueden revisar en la AWS Management Console. Los resultados incluyen los pasos recomendados para la corrección. También se puede configurar funciones de AWS Lambda para que adoptes medidas correctivas automáticamente en respuesta a los resultados de seguridad de GuardDuty.




////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 7
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Resumir las estrategias para supervisar su entorno de AWS.
Describir los beneficios de Amazon CloudWatch.
Describir los beneficios de AWS CloudTrail.
Describir los beneficios de AWS Trusted Advisor.


///////////////////////////////////////////

Amazon CloudWatch
//////////////////////////////////
Estamos haciendo muchos cafés, atendiendo a los clientes y todo parece ir de perlas en la cafetería. Pero a medida que usamos las cafeteras de espreso cada vez más, usamos tazas y abrimos y cerramos constantemente la nevera, sería importante recibir un aviso si algo va mal. Tal vez haya que limpiar o reparar una de las cafeteras. La cuestión es que, como propietario de una empresa, necesitas conocer el estado de los sistemas. ¿Va todo bien? ¿Los clientes no están bien atendidos? ¿Se ha dado a muchos clientes la bebida incorrecta? ¿Reciben todos sus pedidos debidamente? Seguro quieres saber muchas cosas sobre el funcionamiento de la empresa. 

La misma idea se aplica a los sistemas creados en AWS. Necesitas supervisar el estado y el funcionamiento de las soluciones. Por suerte, no necesitas crear una plataforma de seguimiento. Lo hemos hecho por ti. 

Presentamos Amazon CloudWatch. CloudWatch te permite supervisar la infraestructura de AWS y las aplicaciones que utilizas en AWS en tiempo real. El servicio hace un seguimiento y supervisa las métricas. Las métricas son como variables vinculadas a tus recursos. Por ejemplo, la cantidad de espresos que prepara una cafetera o el uso de la CPU de una instancia EC2. 

Veamos cómo funciona tomando como ejemplo la cafetería. Imaginemos que las cafeteras hay que limpiarlas después de cada 100 espresos. CloudWatch nos permite crear una métrica personalizada llamada "Recuento de espresos". Así, cada vez que se llegue a los 100 cafés, se avisará al personal para que limpie la cafetera. Sencillo, ¿verdad? Con CloudWatch puedes lograrlo creando lo que se denomina alarma CloudWatch. Defines el umbral de una métrica para que, cuando se alcance, CloudWatch genere una alerta y desencadene una acción. Es decir, podemos alertar sobre la métrica personalizada, en este caso, llegar a los 100 cafés y luego realizar una acción.

Lo mejor es que las alarmas están integradas con SMS, así que podemos enviar un mensaje al gerente para que limpie la máquina. Puedes crear alarmas personalizadas de métricas a partir de cualquier tipo de recurso de AWS. 
¿Y si queremos agregar todas esas métricas en un solo panel? Podemos usar el panel de CloudWatch. Es como una pantalla que muestra las métricas casi en tiempo real. En el ejemplo, podríamos crear un panel de CloudWatch que nos muestre todas las cafeteras especiales y sus recuentos de espreso para supervisarlas proactivamente. Estos paneles se actualizan automáticamente cuando están abiertos para que consultemos información actualizada de los recursos. 

Por último, ¿cuáles son los beneficios de utilizar un servicio como CloudWatch? El primero es que pueden tener acceso a todas las métricas desde una ubicación central. Esto les permite recopilar métricas y registros de sus recursos y aplicaciones de AWS y de los servicios que se utilizan en AWS y en sus instalaciones, lo que les ayuda a desglosar silos para ver fácilmente información sobre todo el sistema. 

También puedes ver información de las aplicaciones, infraestructura y servicios, lo que significa información sobre toda la pila distribuida, para que puedas correlacionar y ver métricas y registros, lo que permite identificar y resolver problemas rápidamente. Esto, a su vez, significa que puedes reducir el tiempo medio de resolución (MTTR) y mejorar el coste total de propiedad (TCO). En nuestra cafetería, si el MTTR de la limpieza de las cafeteras es más corto, podemos ahorrar TCO gracias a ello. Esto permite liberar recursos clave, como desarrolladores, para que se centren en añadir valor empresarial. 

Y puedes ver datos para optimizar las aplicaciones y los recursos operativos. Por ejemplo, puedes agregar el uso de toda una flota de instancias EC2 para consultar datos de funcionamiento y de uso. Así, nuestro personal puede centrarse en servir café en lugar de en limpiar las cafeteras antes de que sea necesario. Esto es todo. 

Ahora ya sabes en qué consiste CloudWatch. Ahora, si me disculpas, tengo una cita con una cafetera para servirme otro espreso.



///////////////////////////
Amazon CloudWatch
/////////////////////

Amazon CloudWatch es un servicio web que permite supervisar y administrar diversas métricas y configurar acciones de alarma basadas en los datos de esas métricas.

CloudWatch utiliza métricas para representar los puntos de datos de sus recursos. Los servicios de AWS envían métricas a CloudWatch. Luego, CloudWatch utiliza estas métricas para crear gráficos automáticamente que muestran cómo ha cambiado el rendimiento a lo largo del tiempo.

//////////////////////
Alarmas CloudWatch
////////////////////

Con CloudWatch, puedes crear alarmas que realicen acciones automáticamente si el valor de la métrica ha superado un umbral predefinido o queda por debajo de él. 

Por ejemplo, supongamos que los desarrolladores de su empresa utilizan instancias de Amazon EC2 para fines de desarrollo de aplicaciones o pruebas. Si los desarrolladores se olvidan de vez en cuando de detener las instancias, las instancias seguirán funcionando e incurrirán en cargos. 

En este caso, podría crear una alarma CloudWatch que detuviera automáticamente una instancia de Amazon EC2 cuando el porcentaje de utilización de la CPU se hubiera mantenido por debajo de un determinado umbral durante un periodo determinado. Al configurar la alarma, podrías especificar que se recibiera una notificación cada vez que se activara esta alarma.

//////////////////////
Panel de CloudWatch
//////////////////////
La función de panel de CloudWatch permite acceder a todas las métricas de los recursos desde una única ubicación. Por ejemplo, puedes utilizar un panel de control de CloudWatch para supervisar el uso de la CPU de una instancia de Amazon EC2, el número total de peticiones realizadas a un bucket de Amazon S3 y mucho más. Incluso puedes personalizar paneles independientes para distintos fines empresariales, aplicaciones o recursos.


/////////////////////////////
AWS CloudTrail
//////////////////

La caja registradora: uno de los primeros dispositivos de autoauditoría del mundo. El principio es sencillo: confiar, pero verificar. Tu tienda la dirige un empleado en quien confías, pero quieres asegurarse de que el efectivo de la caja coincida con las ventas reales. Por lo tanto, cada transacción se registra y tabula. 

Así, al final del día, sabes cuánto debería haber. Poder auditar las transacciones en TI es fundamental en la mayoría de las estructuras de conformidad. Pero en un centro de datos físico, hay muchos lugares donde alguien puedes, incluso por accidente, hacer cambios sin que se registren. En AWS no ocurre porque todo es programático. 

Presentamos AWS CloudTrail, una completa herramienta de auditoría de API. El motor es sencillo. Cada solicitud que se hace a AWS, ya sea lanzar una instancia EC2, añadir una fila a una tabla de DynamoDB o cambiar los permisos de un usuario, cada solicitud se registra en el motor CloudTrail. El motor registra exactamente quién hizo la solicitud, qué operador, cuándo envió la llamada a la API, dónde estaba, cuál era su dirección IP, cuál fue la respuesta, si ha cambiado algo, cuál es el nuevo estado y si se ha denegado la solicitud. 

Desde la perspectiva de auditoría, es genial. Imagina que estás tratando con un auditor que quiere asegurarse de que nadie de fuera pueda acceder a la base de datos. Está bien. Creas un grupo de seguridad que bloquea el tráfico externo. Pero recordemos que los administradores del nivel de raíz tienen permisos para cambiar esa configuración, ¿no? ¿Cómo le demuestras al auditor que la configuración del grupo de seguridad nunca ha cambiado? La respuesta es CloudTrail. CloudTrail puede guardar esos registros indefinidamente en S3 buckets seguros. Con eso y métodos antimanipulación, como el bloqueo de almacenes, puedes mostrar la procedencia de esos registros de auditoría de seguridad críticos.


/////////////////////////////////
AWS CloudTrail
///////////////////////

AWS CloudTrail registra las llamadas a la API de su cuenta. La información registrada incluye la identidad de la persona que llama a la API, la hora de la llamada a la API, la dirección IP de origen de la persona que llama a la API y mucho más. Puedes imaginarte CloudTrail como un rastro de migas de pan (o un registro de acciones) que alguien ha ido dejando.

Recuerda que puede utilizar las llamadas a la API para aprovisionar, administrar y configurar los recursos de AWS. Con CloudTrail, puedes consultar un historial completo de la actividad de los usuarios y las llamadas a la API de sus aplicaciones y recursos. 

Por lo general, los eventos se actualizan en CloudTrail 15 minutos después de una llamada a la API. Puede filtrar los eventos especificando la hora y la fecha en que se produjo una llamada a la API, el usuario que solicitó la acción, el tipo de recurso que participó en la llamada a la API y mucho más.

Ejemplo: evento de AWS CloudTrail

Supongamos que el propietario de la cafetería navega por la sección AWS Identity and Access Management (IAM) de la AWS Management Console. Descubres que se ha creado una nueva usuaria de IAM llamada María, pero no sabes ni quién, ni cuándo ni cómo la ha creado.

Para responder a estas preguntas, el propietario se desplaza a AWS CloudTrail.

En la sección Historial de eventos de CloudTrail, el propietario aplica un filtro para mostrar solo los eventos de la acción API "CreateUser" en IAM. El propietario localiza el evento de la llamada a la API que ha creado una usuaria de IAM para María. Este registro de eventos proporciona detalles completos sobre lo que ocurrió:

el 1 de enero de 2020 a las 9.00, el usuario de IAM Juan creó una nueva usuaria de IAM (María) a través de la AWS Management Console.


////////////////////////
Información de CloudTrail
/////////////////////////

Dentro de CloudTrail, también puedes habilitar CloudTrail Insights. Esta función opcional permite a CloudTrail detectar automáticamente actividades API inusuales en tu cuenta de AWS. 

Por ejemplo, la información de CloudTrail podría detectar que se han lanzado recientemente en la cuenta un número de instancias de Amazon EC2 mayor de lo habitual. Entonces, podrías revisar todos los detalles del evento para determinar qué acción tomar a continuación.



//////////////////////////
AWS Trusted Advisor
//////////////////////////

Al dirigir una empresa, puede que necesites asesores externos que digan: "este proceso debería simplificarse". O: "tengo consejos para que ahorres en gastos generales". O incluso: "he podido escabullirme, acceder a la caja y abrirla sin que nadie se diera cuenta". Muy mal. 

Con este ejemplo te quiero mostrar que, a veces, es positivo contar con alguien que conozca las prácticas recomendadas del sector y sepa qué buscar, para que te diga qué hay que cambiar para ganar en eficiencia o en seguridad, o para ahorrar. 

AWS tiene un asesor automatizado llamado AWS Trusted Advisor. Puedes usar este servicio en tu cuenta de AWS para evaluar los recursos en función de cinco pilares. Los pilares son: optimización de costes, rendimiento, seguridad, tolerancia a errores y límites de los servicios. Trusted Advisor verifica en tiempo real numerosos aspectos de cada pilar de la cuenta, según prácticas recomendadas de AWS, y compila elementos categorizados para que puedas verlos en la consola de AWS. 

Unas verificaciones se incluyen gratis en la cuenta de AWS, y otras están disponibles según el nivel de tu plan de soporte. Un ejemplo de verificación es si ha activado la autenticación multifactor del usuario raíz. Si no, te avisará. Si no has usado bastante instancias EC2 que podrían desactivarse para ahorrar dinero, o hay volúmenes de EBS de los que no se han hecho copias de seguridad en un periodo razonable, también avisará de ello. Para entenderlo mejor, veamos AWS Trusted Advisor en mi propia cuenta. 

Tengo la sesión abierta y voy a escribir "Trusted Advisor" en la búsqueda. Esto me lleva al panel de Trusted Advisor y, primero, voy a hacer clic en el pilar de optimización de costes para ver lo que ha encontrado. Como verás, se ven tres niveles de elementos. El círculo rojo indica medidas recomendadas. El triángulo naranja indica que se recomienda investigar. Y el cuadrado verde indica que no se detectaron problemas. 

Por suerte, no tengo elementos rojos en la optimización de costes, pero sí tengo algunos naranjas. En la sección de optimización de costes, puedo leer más sobre cada verificación del servicio. En esta cuenta, tengo instancias de RDS inactivas e instancias EC2 y volúmenes de EBS sin aprovechar. Podría decidir escalar verticalmente las instancias para ahorrar costes o, si no las uso en absoluto, puedo decidir eliminar esas instancias y esos volúmenes de EBS. Tendría que investigar un poco para determinar qué debo hacer. 

Ahora, hagamos clic en el pilar de rendimiento. Aquí no tengo advertencias, pero podemos ver qué verifica Trusted Advisor. Como esto, por ejemplo: verifica si hay volúmenes de EBS cuyo rendimiento podría haberse visto afectado por la capacidad de rendimiento de la instancia EC2 a la que se adjunta. 

Seleccionemos ahora el pilar de seguridad. En esta cuenta, puedes ver que hay cuatro alertas de medidas recomendadas. Trusted Advisor me avisa de que mis políticas de contraseñas para los usuarios de IAM son débiles, de que la autenticación multifactor del usuario raíz no está habilitada y de que hay grupos de seguridad que permiten el acceso público a instancias EC2. Todo esto pone en riesgo los recursos de esta cuenta y debe tratarse lo antes posible. 

Pasemos a la tolerancia a errores. Aquí el servicio ha encontrado aspectos insuficientes. Primero, Trusted Advisor indica que hay volúmenes de EBS sin instantáneas en la cuenta. Las instantáneas son copias de seguridad. Sin copias de seguridad, si un volumen de EBS falla, perdería esos datos. 

Otra alerta es que debo tomar medidas para equilibrar las EC2 en las AZ. Es decir, mis instancias EC2 no se han lanzado bien en las AZ. Si una AZ tuviera problemas, mi aplicación podría dejar de funcionar. Implementarlas en varias AZ sería la solución a este problema. 

Por último, los límites de los servicios. Este pilar indica cuándo nos acercamos o vamos a alcanzar los límites de servicio de AWS.  Muchos son límites flexibles. Es decir, son restricciones que se pueden eliminar hasta cierto punto. Es bueno saber cuándo nos acercamos a uno de esos límites y cuándo es hora de enviar una solicitud de soporte a AWS para cambiarlo. En esta cuenta, veo que tengo cinco VPC, que es el límite regional. He alcanzado ese límite de servicio concreto. 

Trusted Advisor puede ayudarte a cumplir con los cinco pilares. Puedes definir alertas para que se envíen por correo a contactos de facturación, operaciones y seguridad cuando se verifique la cuenta. Activen Trusted Advisor para empezar a tomar medidas de optimización en tu cuenta de AWS.



//////////////////
AWS Trusted Advisor
////////////////////

AWS Trusted Advisor es un servicio web que inspecciona tu entorno de AWS y proporciona recomendaciones en tiempo real de acuerdo con las prácticas recomendadas de AWS.

Trusted Advisor compara tus resultados con las prácticas recomendadas de AWS en cinco categorías: optimización de precios, rendimiento, seguridad, tolerancia a errores y Service Limits. Para las comprobaciones de cada categoría, Trusted Advisor ofrece una lista de acciones recomendadas y recursos adicionales para obtener más información sobre las prácticas recomendadas de AWS. 

La orientación proporcionada por AWS Trusted Advisor puede beneficiar a tu empresa en todas las etapas de la implementación. Por ejemplo, AWS Trusted Advisor puede servirte de ayuda al crear nuevos flujos de trabajo y desarrollar nuevas aplicaciones. También puedes usarlo al implementar mejoras continuas en las aplicaciones y los recursos existentes.

//////////////////////////////
Panel de AWS Trusted Advisor
///////////////////////////////

Panel de AWS Trusted Advisor que muestra el número de elementos sin problemas detectados, investigaciones ni acciones recomendadas para las categorías de optimización de precios, rendimiento, seguridad, tolerancia a errores y Service Limits. La optimización de precios muestra un posible ahorro mensual de 7516,85 USD.
Al acceder al panel de Trusted Advisor en la AWS Management Console, puedes revisar las comprobaciones completadas de optimización de precios, rendimiento, seguridad, tolerancia a errores y Service Limits.

Para cada categoría podrás visualizar lo siguiente:


1-La marca de verificación verde indica el número de elementos para los que no ha detectado ningún problema.

2-El triángulo naranja representa el número de investigaciones recomendadas.

3-El círculo rojo representa el número de acciones recomendadas.





////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
Introducción al módulo 8
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Describir los modelos de soporte y precios de AWS.
Describir el nivel gratuito de AWS.
Describir los principales beneficios de AWS Organizations y la facturación unificada.
Explicar los beneficios de AWS Budgets.
Explicar los beneficios de AWS Cost Explorer.
Explicar los principales beneficios de la calculadora de precios de AWS.
Distinguir entre los distintos planes de AWS Support.
Describir los beneficios de AWS Marketplace.


//////////////////////////////////////////////////
Nivel gratuito de AWS
////////////////////////////////

Ya has creado una cuenta de AWS nueva y quieres estrenarla, pero te preocupa agotar su límite de crédito. Bueno, no te preocupes. Si quieres probar algunos servicios de AWS, quizás puedas hacerlo en el nivel grauito. 

Dependiendo del producto que te interese, el nivel gratuito ofrece tres formas de probar servicios. La primera: siempre gratis. El servicio está disponible para todos los clientes de AWS y este nivel no caduca. La segunda: 12 meses gratis. Tienes 12 meses para probar el servicio tras la fecha de registro inicial en AWS, es decir, la creación de la cuenta. Y la tercera: periodos de prueba. Algunos servicios ofrecen una breve prueba gratuita que caduca cuando finaliza dicho periodo. 

Fácil, ¿no? Veamos algunos ejemplos. Empecemos con AWS Lambda, el servicio de computación sin servidor. A fecha de marzo de 2020, permite un millón de invocaciones gratuitas al mes. Es decir, si no superas el millón de invocaciones, te saldrá siempre gratis. El nivel gratuito nunca caduca. Otro ejemplo es S3, nuestro servicio de almacenamiento de objetos. Durante 12 meses puedes almacenar gratis hasta 5 gigabytes. A partir de ahí, tendrás que pagar. Es ideal para probar sitios web estáticos en S3. El último ejemplo es Lightsail, donde puedes implementar pilas de aplicaciones listas para usar. Ofrecemos una prueba de un mes de hasta 750 horas de uso. Es suficiente para implementar y probar un blog de WordPress. Quién sabe, tal vez quieras compartir con el mundo tus recetas de batidos.

Pero antes de divagar, otros servicios que también se incluyen en el nivel gratuito son SageMaker, Comprehend Medical, DynamoDB, SNS, Cognito y muchos más. Si quieres ver la lista completa de 60 servicios (más o menos) consulta la sección de recursos. ¡A explorar el nivel gratuito!


//////////////////////////////////////
Nivel gratuito de AWS
/////////////////////////////////////////

El nivel gratuito de AWS permite comenzar a utilizar determinados servicios sin tener que preocuparse por incurrir en costes durante el periodo especificado. 

Hay tres tipos de ofertas disponibles: 

1- Siempre gratis.
2- 12 meses gratis.
3- Pruebas.

En cada oferta del nivel gratuito, asegúrate de revisar los detalles concretos sobre exactamente qué tipos de recursos se incluyen. 

Para más información, selecciona el símbolo + que aparece junto a cada categoría.

//////////////
Siempre gratis
/////////////
–
Estas ofertas no caducan y están disponibles para todos los clientes de AWS.

Por ejemplo, AWS Lambda permite 1 millón de solicitudes gratuitas y hasta 3,2 millones de segundos de tiempo de computación al mes. Amazon DynamoDB permite 25 GB de almacenamiento gratuito al mes.

///////////////
Siempre gratis
////////////////
–
Estas ofertas no caducan y están disponibles para todos los clientes de AWS.

Por ejemplo, AWS Lambda permite 1 millón de solicitudes gratuitas y hasta 3,2 millones de segundos de tiempo de computación al mes. Amazon DynamoDB permite 25 GB de almacenamiento gratuito al mes.


////////////////////
Pruebas
////////////
–
Las ofertas de prueba gratuita breve comienzan a partir de la fecha en que se activa un servicio concreto. La duración de cada prueba puede variar según un número de días o la cantidad de uso del servicio.

Por ejemplo, Amazon Inspector ofrece una prueba gratuita de 90 días. Amazon Lightsail (un servicio que le permite utilizar servidores privados virtuales) ofrece 750 horas de uso gratuitas durante un periodo de 30 días.



///////////////////////////////////////////
Conceptos respecto a los precios de AWS
/////////////////////////////////////////


///////////
Cómo funcionan los precios de AWS

AWS ofrece una gama de servicios de computación en la nube con precios de pago por uso. 

Para más información, selecciona el símbolo + que aparece junto a cada categoría.

/////////////////
Paga por lo que usas
–
Por cada servicio, pagarás por la cantidad exacta de recursos que utilices realmente, sin necesidad de contratos a largo plazo ni licencias complejas.


/////////////////////////
Reserva para pagar menos
–
Algunos servicios ofrecen opciones de reserva con un descuento significativo, en comparación con los precios de las instancias bajo demanda.

Por ejemplo, supongamos que tu empresa utiliza instancias de Amazon EC2 para una carga de trabajo que debe lanzarse continuamente. Puedes optar por lanzarla en EC2 Instance Savings Plans de Amazon porque el plan te permite ahorrar hasta un 72 % con respecto a la capacidad equivalente de la instancia bajo demanda.


/////////////////////////////////////////////////////////
Reserva para pagar menos
–
Algunos servicios ofrecen opciones de reserva con un descuento significativo, en comparación con los precios de las instancias bajo demanda.

Por ejemplo, supongamos que tu empresa utiliza instancias de Amazon EC2 para una carga de trabajo que debe lanzarse continuamente. Puedes optar por lanzarla en EC2 Instance Savings Plans de Amazon porque el plan te permite ahorrar hasta un 72 % con respecto a la capacidad equivalente de la instancia bajo demanda.



/////////////////////////////////////////////////////
Calculadora de precios de AWS

La calculadora de precios de AWS permite analizar los servicios de AWS y crear una estimación del coste de tus casos prácticos en AWS. Puedes organizar tus estimaciones de AWS por los grupos que definas. Un grupo puede reflejar la organización de la empresa; por ejemplo, proporcionando estimaciones por centro de costes.

Cuando hayas creado una estimación, puedes guardarla y generar un enlace para compartirla con otros.



/////////////
Supongamos que tu empresa está interesada en utilizar Amazon EC2. Sin embargo, todavía no sabes con certeza qué región o tipo de instancia de AWS sería los más rentables para su caso práctico. En la calculadora de precios de AWS, puedes introducir información como el tipo de sistema operativo que necesitas, los requisitos de memoria y los requisitos de entrada/salida (E/S). Con la calculadora de precios de AWS, puedes revisar una comparación estimada de distintos tipos de instancias de EC2 en todas las regiones de AWS.

////
Ejemplos de precios de AWS

En esta sección se presentan algunos ejemplos de precios de los servicios de AWS.


//////////////
AWS Lambda
//////////
Para más información sobre los precios de AWS Lambda, selecciona la pestaña correspondiente.


///////////////////
1) PRECIOS DE AWS LAMBDA:
En el caso de AWS Lambda, se cobra en función del número de solicitudes de las funciones y del tiempo que tardan en lanzarse.

AWS Lambda permite 1 millón de solicitudes gratuitas y hasta 3,2 millones de segundos de tiempo de computación al mes.

Puedes ahorrar en costes de AWS Lambda al inscribirte en un Compute Savings Plan. Un Compute Savings Plan ofrece precios de computación más bajos a cambio de comprometerse a una cantidad constante de uso durante un periodo de 1 o 3 años. Este es un ejemplo de cómo pagar menos cuando se reserva. 


///////////////////////
2) EJEMPLO DE PRECIOS
Si has utilizado AWS Lambda en varias regiones de AWS, puedes ver los cargos detallados por región en la factura.

En este ejemplo, todo el uso de AWS Lambda se ha producido en la región Norte de Virginia. La factura enumera cargos separados por el número de solicitudes de funciones y su duración. 

Tanto el número de solicitudes como la duración total de las mismas en este ejemplo están por debajo de los umbrales del nivel gratuito de AWS, por lo que el propietario de la cuenta no tendría que pagar por el uso de AWS Lambda durante este mes.



////////////////////////////////////
Amazon EC2

Para más información sobre los precios de Amazon EC2, selecciona la pestaña correspondiente.


/////////
PRECIOS DE AMAZON EC2

Con Amazon EC2, solo pagas por el tiempo de computación que utilizas mientras se lanzan las instancias.
Para algunas cargas de trabajo, puedes reducir significativamente los costes de Amazon EC2 mediante instancias de spot. Por ejemplo, supongamos que estás iniciando una tarea de procesamiento por lotes que puede soportar interrupciones. Con una instancia de spot, conseguirías un ahorro de costes de hasta un 90 % cumpliendo los requisitos de disponibilidad de la carga de trabajo.

Puedes conseguir ahorros de costes adicionales en Amazon EC2 si consideras los planes de ahorro y las instancias reservadas.

////////////////
EJEMPLO DE PRECIOS
Los cargos por servicio de este ejemplo incluyen detalles para los siguientes elementos:

Cada tipo de instancia de Amazon EC2 que se ha estado usando.
La cantidad de espacio de almacenamiento de Amazon EBS que se ha aprovisionado.
El tiempo que se ha estado usando Elastic Load Balancing.
En este ejemplo, todas las cantidades de uso se encuentran por debajo de los umbrales del nivel gratuito de AWS, por lo que el propietario de la cuenta no tendría que pagar por el uso de Amazon EC2 este mes.



//////////////////////////////////////////////////////////////////////
Amazon S3

Para más información sobre los precios de Amazon S3, selecciona la pestaña correspondiente.
//////////////////////////////////////////////////////////////////////

1) PRECIOS DE AMAZON S3
Para los precios de Amazon S3, ten en cuenta los siguientes componentes de coste:

Almacenamiento: solo se paga por el almacenamiento que se utiliza. Se cobra una tarifa para almacenar objetos en sus buckets de Amazon S3 según el tamaño de sus objetos, las clases de almacenamiento y el tiempo que ha almacenado cada objeto durante el mes.
Solicitudes y recuperaciones de datos: se paga por las solicitudes realizadas a los objetos y buckets de Amazon S3. Por ejemplo, supongamos que almacenas archivos de fotos en buckets de Amazon S3 y los alojas en un sitio web. Cada vez que un visitante realice una solicitud al sitio web que incluya estos archivos de fotos cuenta para las solicitudes que deberás pagar.
Transferencia de datos: transferir datos entre diferentes buckets de Amazon S3 o desde Amazon S3 a otros servicios de la misma región de AWS es gratis. En cambio, sí pagas por los datos que transfieres a y desde Amazon S3, con algunas excepciones. Las transferencias de datos desde Internet a Amazon S3 o a Amazon CloudFront son gratuitas. De igual manera, las transferencias de datos a una instancia de Amazon EC2 en la misma región de AWS que el bucket de Amazon S3 son gratuitas.
Administración y replicación: pagas por las funciones de administración de almacenamiento que hayas habilitado en los buckets de Amazon S3 de tu cuenta. Estas funciones incluyen inventario de Amazon S3, análisis y etiquetado de objetos.



2) EJEMPLO DE PRECIOS
La cuenta de AWS de este ejemplo ha utilizado Amazon S3 en dos regiones: Norte de Virginia y Ohio. En cada región, los cargos detallados se basan en los siguientes factores:

Número de solicitudes para agregar o copiar objetos en un bucket.
Número de solicitudes para recuperar objetos de un bucket.
La cantidad de espacio de almacenamiento utilizado.
Todo el uso de Amazon S3 en este ejemplo se encuentra por debajo de los umbrales del nivel gratuito de AWS, por lo que el propietario de la cuenta no tendría que pagar por el uso de Amazon S3 durante este mes.



//////////////////////////////////////////////////////////////////////////
Panel de facturación
//////////////////////////////////////////////////////////////////////
Hola, entusiasta de AWS. ¿Te pasa como a mí, que quiero estar al tanto de la información de facturación de mi cuenta de AWS? Entonces te haré una demostración para que sepas dónde buscar. 

Como verás, ya he iniciado sesión y, ahora, vamos a buscar la facturación y hacer clic en la opción que aparece. Y...¡bam! Así accedemos a información útil. Puedes ver el gasto mensual hasta la fecha en el lado derecho y los servicios más usados. Abajo a la izquierda: el gasto actual el previsto y el del último mes. Más abajo, vemos los servicios del nivel gratuito más usados. Incluso se indican los porcentajes de su uso mensual hasta la fecha. Estupendo, ¿verdad? 

Si nos vamos hacia arriba, veremos que tenemos acceso a otras herramientas de facturación como Cost Explorer y Budgets, entre otras. También tenemos acceso a las facturas. Hagamos clic en Bills (Facturas). Se muestran los servicios por los que estamos pagando y, si ampliamos, vemos los costes desglosados por región. Los servicios globales los vemos desglosados así: por ejemplo, si hago clic en Route 53, vemos que es un servicio global y se desglosa de esta manera. Ya lo ves. Es una forma sencilla de comprobar lo que gastas en cada servicio de AWS. ¡Gracias por asistir! 


//
Utiliza el panel de AWS Billing & Cost Management para pagar las facturas de AWS, supervisar su uso y analizar y controlar los costes.

Compara tu saldo actual del mes hasta la fecha con el del mes anterior y obten una previsión del próximo mes según el uso actual.
Consulta el gasto del mes hasta la fecha por servicio.
Comprueba el uso del nivel gratuito por servicio.
Accede a Cost Explorer y crea presupuestos.
Compra y administra planes de ahorro.
Publica informes de AWS Cost and Usage Report.




///////////////////////////////////////////
Facturación unificada
//////////////////////////
Si tenemos varias cafeterías por toda la ciudad, como en nuestro ejemplo, cada una tiene sus propios gastos y beneficios. Sin embargo, todas son propiedad de la misma entidad. Por eso, el dinero fluye hacia y desde una cuenta principal. Si hubiera un técnico de guardia para reparar las cafeteras cuando se averían, esa persona facturaría a la organización, no a la cafetería. 

Apliquemos esa idea a AWS. Es probable que una empresa tenga varias cuentas de AWS y, como ya sabemos, se pueden gestionar con AWS Organizations. Una característica genial de AWS Organizations es la facturación unificada. Al final de cada mes, en lugar de pagar una factura de AWS por cada cuenta, puedes reunir las facturas en una sola para el propietario de la organización. Esto facilita el seguimiento de las facturas. Así, no recibirás 100 facturas si tienes 100 cuentas de AWS. Como en el ejemplo de cafetería, si el técnico visitara 11 de las cafeterías y reparase las cafeteras, nos haría una sola factura para el ciclo de facturación. Esto facilita la gestión de la empresa. 

Así es la facturación unificada de AWS Organizations. Puedes consultar el detalle de las facturas de AWS para saber qué cuenta gastó cuánto, pero todo se unifica en un solo lugar para visualizarlo más fácilmente. Esta característica también ofrece otros beneficios. Uno de ellos es que el uso de los recursos de AWS se agrupa a nivel de organización. AWS ofrece precios por volumen. Puede que una cuenta en concreto registre muy poco uso, pero puedes recibir un descuento por volumen gracias a la suma agregada de todas las cuentas de la organización. Además, si tienes un plan de ahorro o usas instancias reservadas EC2, se pueden compartir entre las cuentas de la organización. Lo mejor es que es una característica gratuita y fácil de usar. Simplifica el proceso de facturación, permite compartir ahorro entre cuentas y no supone una inversión adicional. Genial. 


///////////////////////////////
Facturación unificada
/////////////////////

En uno de los módulos anteriores has aprendido sobre AWS Organizations, un servicio que te permite administrar varias cuentas de AWS desde una ubicación central. AWS Organizations también ofrece la opción de facturación unificada. 

La función de facturación unificada de AWS Organizations permite recibir una única factura de todas las cuentas de AWS de su organización. Al unificar, puedes seguir con facilidad los costes combinados de todas las cuentas vinculadas en tu organización. El número máximo predeterminado de cuentas permitidas para una organización es de cuatro, pero puedes contactar con AWS Support para aumentar la cuota si fuera necesario.

En la factura mensual, puedes revisar los cargos detallados en los que incurre cada cuenta. Esto te permite tener mayor transparencia en las cuentas de la organización y, al mismo tiempo, mantener la comodidad de recibir una sola factura mensual.

Otro beneficio de la facturación unificada es la capacidad de compartir precios de descuento por volumen, planes de ahorro e instancias reservadas en todas las cuentas de tu organización. Por ejemplo, es posible que una cuenta no haga un uso mensual lo suficientemente grande como para poder optar a precios con descuento. Sin embargo, cuando se combinan varias cuentas, su uso agregado puede conseguir un beneficio que se aplica a todas las cuentas.


//
Ejemplo: facturación unificada
Para revisar un ejemplo de facturación unificada, selecciona Comenzar.

//1
Paso 1

Supongamos que eres el encargado de supervisar la facturación de AWS de la empresa. 

La empresa utiliza tres cuentas de AWS para departamentos distintos. En lugar de pagar la factura mensual de cada ubicación por separado, decides crear una organización y agregar las tres cuentas. 

Administra la organización a través de la cuenta principal.


//2
Paso 2

Cada mes, AWS cobra a la cuenta de pagador principal por todas las cuentas vinculadas en una factura unificada. A través de la cuenta principal, también puedes obtener un informe de costes detallado para cada cuenta vinculada. 

La factura unificada mensual también incluye los costes de uso de la cuenta en los que incurre la cuenta principal. Este coste no es un cargo de prima por tener una cuenta principal. 

La factura unificada muestra los costes asociados a cualquier acción de la cuenta principal (como almacenar archivos en Amazon S3 o lanzar instancias de Amazon EC2).

//3
Ejemplo: facturación unificada
Para revisar un ejemplo de facturación unificada, selecciona Comenzar.

INICIAR 
Paso 1

jpNyVRKyVd6tcleK-Image26.png
Supongamos que eres el encargado de supervisar la facturación de AWS de la empresa. 

La empresa utiliza tres cuentas de AWS para departamentos distintos. En lugar de pagar la factura mensual de cada ubicación por separado, decides crear una organización y agregar las tres cuentas. 

Administra la organización a través de la cuenta principal.

123
Paso 2

ZHTIh6bAeEnXwfbq-Image44.png
Cada mes, AWS cobra a la cuenta de pagador principal por todas las cuentas vinculadas en una factura unificada. A través de la cuenta principal, también puedes obtener un informe de costes detallado para cada cuenta vinculada. 

La factura unificada mensual también incluye los costes de uso de la cuenta en los que incurre la cuenta principal. Este coste no es un cargo de prima por tener una cuenta principal. 

La factura unificada muestra los costes asociados a cualquier acción de la cuenta principal (como almacenar archivos en Amazon S3 o lanzar instancias de Amazon EC2).

123
Paso 3

La facturación unificada también te permite compartir descuentos de precios por volumen entre cuentas. 

Algunos servicios de AWS, como Amazon S3, tienen descuentos de precios por volumen que te ofrecen precios más bajos cuanto más utilices el servicio. En Amazon S3, una vez que los clientes han transferido 10 TB de datos en un mes, pagan un precio de transferencia por GB más bajo en los siguientes 40 TB de datos transferidos. 

En este ejemplo aparecen tres cuentas de AWS independientes que han transferido diferentes cantidades de datos en Amazon S3 durante el mes en curso: 

La cuenta 1 ha transferido 2 TB de datos.
La cuenta 2 ha transferido 5 TB.
Y la cuenta 3 ha transferido 7 TB de datos.
Como ninguna cuenta ha superado el umbral de 10 TB, ninguna de ellas puede optar a un precio de transferencia por GB más bajo en los próximos 40 TB de datos transferidos.


/////////////////////////////////////////////
AWS Budgets
//////////////////////////////////////////

A medida que aumentan las implementaciones en AWS, probablemente querrás asegurarte de no te sales del presupuesto. Como en la mayoría de las empresas, querrás supervisar los costes para mantenerte dentro del límite. Te presentamos AWS Budgets. 

Puedes pensar en AWS Budgets como en un presupuesto para gastos personales. Permite fijar presupuestos personalizados para diversos supuestos, como el precio o el uso. Recibirás una alerta cuando los costes o uso superen o se prevé que superen el importe presupuestado. 

Supongamos que mi presupuesto era de 1000 dólares y quiero que me avisen cuando llegue al 80 % de esa cantidad. Budgets hace precisamente eso. El programa te notifica de forma proactiva si vas a superar la cantidad presupuestada en recursos. 

Te voy a enseñar cómo funciona con una demostración. Primero, ve a la sección de facturación de la consola de AWS, haz clic en la opción de presupuestos y en la de crear. Elige un tipo de presupuesto. Yo elegiré el de costes. Nombra el presupuesto. Introduce un importe, supongamos que 1000 dólares, como mencioné anteriormente, y haz clic en botón de configurar alertas. Ahora definimos un umbral de alerta. Pongamos 80 %, lo que significa que recibiremos una alerta cuando alcancemos el 80 % de la cantidad presupuestada. Ahora añadimos una dirección de correo. Voy a ocultarla, que ya recibo bastante spam. Confirmamos el presupuesto y lo creamos. 

Y ahí lo tenemos: nuestro primer presupuesto. ¿Has visto qué fácil? Creo que podemos decir que hemos hecho una buena inversión de tiempo con esta demostración.


///////////////////////////////////////
AWS Budgets
//////////////////////////////
En AWS Budgets se pueden crear presupuestos para planificar el uso de los servicios, los costes de servicio y las reservas de instancias.

La información de AWS Budgets se actualiza tres veces al día. De esta forma, puedes determinar con precisión si su uso se adecua a los importes presupuestados o a los límites del nivel gratuito de AWS.

En AWS Budgets, también se puedne configurar alertas personalizadas cuando su uso supere (o se prevé que supere) el importe presupuestado.

//////////////////////
Ejemplo: AWS Budgets

Supongamos que has establecido un presupuesto para Amazon EC2 y quieres asegurarte de que el uso de Amazon EC2 por parte de tu empresa no supere los 200 USD al mes. 

En AWS Budgets, podrías establecer un presupuesto personalizado para que se te notifique cuando su uso haya alcanzado la mitad de este importe (100 USD). Esta configuración te permitirá recibir una alerta y decidir cómo quieres continuar utilizando Amazon EC2.

Para más información, selecciona el marcador correspondiente.




///////////////////////////////////////

AWS Cost Explorer
//////////////////////////////

Como ya hemos comentado, el modelo de AWS es de coste variable y solo pagas por lo que usas. No se factura un importe fijo al final de cada mes. En su lugar, fluctúa según los recursos que empleas y cómo los empleas. Debido a este modelo de precios, es muy importante poder consultar en detalle lo facturado para saber cómo inviertes el dinero. 

AWS tiene un servicio llamado AWS Cost Explorer, basado en la consola que permite ver y analizar visualmente dónde va el dinero en AWS. Te enseña en qué servicios estás invirtiendo más y permite consultar un historial de 12 meses para ver cómo ha evolucionado el gasto. Así, si ves un aumento del gasto, digamos, en EC2 de octubre a diciembre, puedes consultar esos datos para ver por qué ha ocurrido. 

Veamos AWS Cost Explorer en mi cuenta de AWS. He iniciado sesión en la consola y voy a buscar Cost Explorer. Esto me lleva al panel de gestión de costes y voy a hacer clic en Cost Explorer. Como ves, se muestran los últimos 6 meses de costes asociados a mi cuenta agrupados por servicio. Puedo cambiar el periodo que se muestra a 8 meses y cómo se ven los datos agrupándolos por distintos atributos. Voy a seleccionar Region (Región). Puedo agrupar según otros atributos. 

Una agrupación útil es por etiqueta. Muchos recursos de AWS son etiquetables. Las etiquetas son básicamente pares clave-valor que definimos. Podemos etiquetar una instancia EC2 con el nombre de un proyecto, o una base de datos con ese nombre de proyecto y, a continuación, entrar en AWS Cost Explorer, filtrar por etiqueta y ver todos los gastos asociados a esa etiqueta. Cost Explorer también permite crear informes personalizados. 

Ahora voy a crear un informe sobre el coste diario de enero de este año. Voy a agrupar por servicio. Como ves, el coste de los servicios suele ser el mismo todos los días, salvo el de EC2, que lo usé más unos días que otros. Puedo guardar este informe y consultarlo cuando sea necesario. 

Cost Explorer ofrece informes predeterminados útiles, pero también puedes crear informes personalizados. Esto ayuda a ver el origen de los costes y tomar medidas si es necesario para frenar el gasto. Optimizar costes es una prioridad a la que hay que prestar mucha atención. Cost Explorer te ayudará a avanzar en la dirección correcta. 

///
AWS Cost Explorer
///

AWS Cost Explorer es una herramienta que permite visualizar, comprender y administrar los costes y el uso de AWS a lo largo del tiempo.

AWS Cost Explorer incluye un informe predeterminado de los costes y el uso de los cinco servicios principales de AWS con costes acumulados. Se pueden aplicar filtros y grupos personalizados para analizar los datos. Por ejemplo, puedes ver el uso de recursos en el nivel por hora.

Ejemplo: AWS Cost Explorer
En este ejemplo del panel de AWS Cost Explorer se muestran los costes mensuales de las instancias de Amazon EC2 durante un periodo de seis meses. La barra de cada mes separa los costes de los distintos tipos de instancias de Amazon EC2 (como t2.micro o m3.large). 

Al analizar los costes de AWS a lo largo del tiempo, puedes tomar decisiones fundamentadas sobre los costes futuros y cómo planificar los presupuestos.


///////////////////////////////////////////////////////////////
Planes de AWS Support
///////////////////////////////////////////////////////////////

Una de las ventajas de AWS es que no importa si tu empresa es grande o pequeña porque nunca estarás solo. Startups pequeñas, empresas grandes, del sector público o privado… para cada una tenemos opciones de soporte diseñadas para adaptarse a sus necesidades específicas. 

Para empezar, todos los clientes tienen acceso automático al plan de Basic Support sin coste adicional. Todos tienen acceso a funciones de soporte como atención al cliente ininterrumpida, documentación (también documentos técnicos), foros de soporte, AWS Trusted Advisor y AWS Personal Health Dashboard, una vista personalizada del estado de los servicios de AWS y de las alertas que se activan si ocurre algo con los recursos. Estas funciones son gratuitas para todos, pero, cuando comienzan a trasladar cargas de trabajo críticas a AWS, ofrecemos niveles superiores de soporte para atender esas necesidades. 

El siguiente nivel es Developer Support, que incluye lo del Basic más la posibilidad de enviar correos directamente a atención al cliente, que responderá a su solicitud en un plazo de 24 horas, y en menos de 12 horas si hay incidencias con los sistemas. Este nivel es idóneo si estás experimentando con AWS o estás configurando pruebas, incluidas las de concepto. 

Al poner en marcha cargas de trabajo de producción, a los clientes les suele venir mejor pasarse al nivel de Business Support. Incluye lo anterior, además de Trusted Advisor, es decir, todas las verificaciones disponibles para la cuenta. Ofrece acceso telefónico directo al equipo de soporte, cuyo tiempo máximo de respuesta es de 4 horas si el sistema de producción está afectado y de 1 hora si el sistema de producción está inactivo. Además, como parte del propio nivel, puedes acceder a la gestión de eventos de infraestructura y, por un suplemento, te ayudamos a planear eventos masivos como lanzamientos o campañas publicitarias globales. 

Por último, a las empresas con cargas de trabajo críticas les recomendamos el nivel Enterprise Support. Incluye lo anterior y un tiempo máximo de respuesta de 15 minutos para cargas de trabajo críticas y un gerente técnico de cuenta (TAM) asignado, que coordina el acceso a programas y otros expertos de AWS si corresponde. 

Hablemos más específicamente sobre el trabajo de los TAM. Los TAM forman parte del equipo de soporte personal que se incluye en el nivel Enterprise Support. Este equipo especializado no solo supervisa proactivamente tu entorno y ayuda con optimizaciones, sino que también gestiona eventos de infraestructura, y hace revisiones de operaciones con Well-Architected. 

¿Qué es una revisión con Well-Architected? En resumen, los TAM trabajan con los clientes para revisar arquitecturas bajo el marco de referencia Well-Architected. En las arquitecturas se verifican los cinco pilares del marco de referencia Well-Architected: excelencia operativa, seguridad, fiabilidad, rendimiento eficiente y optimización de costes. Como ves, el trabajo de los TAM es mucho más que gestionar solicitudes de soporte. En AWS Support, se considera al cliente de forma integral, no solo para solucionar incidencias, sino también para facilitarle el éxito. 

Esa es la misión de AWS Support. Para más información sobre AWS Support, incluidas las estructuras de precios de los planes, visita aws.amazon.com/premiumsupport. 

///
AWS Support
////
AWS ofrece cuatro planes de soporte diferentes para ayudarte a solucionar incidencias, reducir los costes y utilizar de forma eficiente los servicios de AWS. 

Puedes elegir entre los siguientes planes de soporte para satisfacer las necesidades de tu empresa:

Basic Support.
Developer Support.
Business Support.
Enterprise Support.

///////////
Basic Support

Basic Support es gratuito para todos los clientes de AWS. Incluye acceso a documentos técnicos, documentación y comunidades de soporte. Con Basic Support, también puedes contactar con AWS si tienes preguntas sobre facturación y aumentos del límite de servicio.

Con este plan, tienes acceso a una selección limitada de comprobaciones de AWS Trusted Advisor. Además, puedes utilizar AWS Personal Health Dashboard, una herramienta que proporciona alertas y orientación sobre correcciones cuando AWS experimenta situaciones que pueden afectarte. 

Si tu empresa necesita soporte más allá del nivel Basic Support, puedes barajar la posibilidad de adquirir el nivel de Developer Support, Business Support o Enterprise Support.

//
Developer Support, Business Support y Enterprise Support
//

Los planes Developer Support, Business Support y Enterprise Support incluyen todas las ventajas de Basic Support, además de la capacidad para abrir un número ilimitado de casos de soporte técnico. Estos tres planes de AWS Support incluyen pagos mensuales y no requieren contratos a largo plazo.

En ese curso solo se mencionan algunos detalles de los planes de AWS Support. En el sitio de AWS Support se encuentra disponible información general completa de lo que se incluye en cada plan, incluidos los precios.

En general, respecto a los precios, el plan Developer Support es el más económico; el plan Business Support tiene un precio intermedio y el plan Enterprise Support es el que tiene el precio más alto. 

Para obtener más información, selecciona el símbolo + que aparece junto a cada categoría.


//
Developer Support
–
Los clientes del plan Developer Support tienen acceso a funciones tales como las siguientes:

Guía de prácticas recomendadas.
Herramientas de diagnóstico del lado del cliente.
Compatibilidad con la arquitectura de creación de bloques, que consiste en una guía sobre cómo utilizar conjuntamente las ofertas, las características y los servicios de AWS.
Por ejemplo, supongamos que tu empresa está estudiando los servicios de AWS. Has oído hablar de distintos servicios de AWS. Sin embargo, no sabes cómo podrías usarlos en conjunto para crear aplicaciones que puedan satisfacer las necesidades del negocio. En este escenario, el soporte para arquitectura de componentes básicos incluido en el plan Developer Support podría ayudarte a identificar oportunidades para combinar servicios y características específicas.

//
Business Support
–
Los clientes con un plan Business Support tienen acceso a funciones adicionales que incluyen lo siguiente:

Guía de casos de uso para identificar las ofertas, las características y los servicios de AWS que mejor se adaptan a sus necesidades específicas.
Todas las comprobaciones de AWS Trusted Advisor.
Soporte limitado para software de terceros, como sistemas operativos comunes y componentes de pila de aplicaciones.
Supongamos que tu empresa tiene el plan Business Support y quiere instalar un sistema operativo de terceros común en sus instancias de Amazon EC2. Puedes ponerte en contacto con AWS Support a fin de obtener ayuda para instalar, configurar y solucionar problemas del sistema operativo. Para temas avanzados como la optimización del rendimiento, el uso de scripts personalizados o la resolución de problemas de seguridad, es posible que sea necesario contactar directamente con el proveedor de software de terceros.


//
Enterprise Support
–
Además de todas las funciones incluidas en los planes Basic Support, Developer Support y Business Support, los clientes con un plan Enterprise Support tienen acceso a funciones como las siguientes:

Guía de arquitectura de aplicaciones, que es una entidad consultiva para ayudarles con casos de uso y aplicaciones específicas de su empresa.
Infrastructure Event Management: un compromiso a corto plazo con AWS Support que ayuda a las empresas a comprender mejor sus casos prácticos. Este también proporciona orientación arquitectónica y de escalado.
Un gerente técnico de cuenta.


////////
Gerente técnico de cuenta (TAM)

El plan Enterprise Support incluye la asistencia de un gerente técnico de cuenta (TAM).

Si tu empresa cuenta con Enterprise Support, el TAM es tu principal punto de contacto en AWS. Proporciona orientación, revisiones arquitectónicas y comunicación continua en tu empresa mientras se planifican, implementan y optimizan las aplicaciones. 

El TAM proporciona experiencia en toda la gama de servicios de AWS. Ayuda a diseñar soluciones que utilicen conjuntamente varios servicios de manera eficiente a través de una estrategia integrada.

Por ejemplo, supongamos que te interesa desarrollar una aplicación que utilice varios servicios de AWS conjuntamente. El TAM podría proporcionar información sobre cómo utilizarlos mejor. A su vez, tiene en cuenta las necesidades específicas que tu empresa espera abordar con la nueva aplicación.


/////////////////////////////////////////////////////////////////
AWS Marketplace
/////////////////////////////////////////////////////////////////

Otra forma importante en la que AWS ayuda a las empresas es a través de AWS Marketplace. AWS Marketplace es un catálogo digital que facilita la búsqueda de software de terceros, y su implementación y gestión en tus arquitecturas de AWS, además de ofrecer numerosas opciones de pago. Esto mejora el proceso de innovación implementando de forma rápida y segura una amplia gama de soluciones y reduciendo el coste total de propiedad. Para entenderlo mejor, quiero hablar de lo que aporta AWS Marketplace y de cómo puede ayudar a mejorar tu velocidad y agilidad en AWS. La primera forma clave en que AWS Marketplace te ayuda es ahorrándote tener que crear, instalar y mantener la infraestructura básica necesaria para utilizar aplicaciones externas. En Marketplace se ofrecen opciones como implementar con un clic, lo que permite adquirir y usar rápidamente productos de miles de vendedores de software justo cuando los necesitas. 

Como sabes, algunos proveedores externos suelen firmar contratos anuales de centros de datos en instalaciones. Quizá te preguntes si sucede lo mismo con AWS. Los proveedores pueden elegir qué opciones ofrecer, pero, en Marketplace, casi todos te permitirá usar las licencias anuales que tengas e implementar ese software en AWS. Pero lo más importante es que la mayoría de los proveedores también ofrecen opciones de pago por uso bajo demanda. Estos planes flexibles de precios ofrecen más opciones para pagar por el software según la forma en que lo uses, para no tener licencias sin usar que añadan costes innecesarios. 

Muchos ofrecen pruebas gratis o planes de inicio rápido para probar y conocer sus ofertas. Al igual que AWS, son conscientes de que la mejor manera de saber si algo te viene bien es probándolo. Incluso las grandes empresas acostumbradas a negociar tarifas y los proveedores de descuentos se pueden beneficiar de Marketplace. Marketplace ofrece características empresariales, como términos y precios individuales para gestionar acuerdos de licencia personalizados, un mercado privado donde crear un catálogo particular de soluciones de software preaprobadas que cumplan tus estándares legales o de seguridad, integración en sistemas de adquisición y herramientas de gestión de costes, por mencionar solo algunos beneficios. Para más información sobre AWS Marketplace, visita aws.amazon.com/marketplace. 

///////////////
AWS Marketplace
/////////////////

AWS Marketplace es un catálogo digital que incluye miles de listings de software de proveedores de software independientes. Puedes utilizar AWS Marketplace para buscar, probar y comprar software que se utilice en AWS. 

En cada listing de AWS Marketplace, puedse acceder a información detallada sobre opciones de precios, soporte disponible y opiniones de otros clientes de AWS.

También puedes analizar soluciones de software por sector y caso práctico. Por ejemplo, supongamos que tu empresa está en el sector sanitario. En AWS Marketplace, puedes revisar los casos de uso que el software le ayuda a abordar, como implementar soluciones para proteger los registros de los pacientes o utilizar modelos de machine learning para analizar el historial médico de un paciente y predecir posibles riesgos para la salud.


///
Categorías de AWS Marketplace:

AWS Marketplace ofrece productos en varias categorías, como productos de infraestructura, aplicaciones empresariales, productos de datos y DevOps.

Dentro de cada categoría, se puede restringir la búsqueda navegando por los listings de productos de las subcategorías. Por ejemplo, las subcategorías de la categoría DevOps incluyen áreas como Desarrollo de aplicaciones, Seguimiento o Pruebas.



////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
Introducción al módulo 9
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Comprender la migración y la innovación en la nube de AWS.
Resumir el AWS Cloud Adoption Framework (AWS CAF). 
Resumir los seis factores clave de una estrategia de migración a la nube.
Describir los beneficios de las soluciones de migración de datos de AWS, como AWS Snowcone, AWS Snowball y AWS Snowmobile.
Resumir el amplio abanico de soluciones innovadoras que ofrece AWS.


//
Parece que ya tenemos claro cómo empezar a usar la nube de AWS, pero, ¿qué pasa si ya tienes implementaciones en entornos locales o has iniciado el cambio a la nube sin AWS? Nos encantaría ayudar, sobre todo porque podrías ahorrar mucho en el proceso. 
Esto nos lleva a la migración y la innovación. Te vamos a enseñar todas las opciones, desde herramientas de migración y el AWS Cloud Adoption Framework hasta la familia Snow, que son dispositivos físicos para migrar datos desde y hacia AWS. 

Por lo tanto, antes de terminar, sigue con nosotros para saber cómo pasar del entorno local o de la nube a AWS y veremos también las 6 claves para la migración.


/////////////////////////////////////////////////////////////////////
AWS Cloud Adoption Framework
/////////////////////////////////////////////////////////////////////

La migración a la nube es un proceso. No basta con chasquear los dedos para alojar todo mágicamente en AWS. Conlleva mucho esfuerzo migrar aplicaciones a AWS y conseguirlo es algo que requiere experiencia. 

Por suerte, muchas personas ya lo han conseguido y no serán las primeras en tener soluciones en AWS. Por eso, hay mucha información disponible sobre cómo alojar en AWS. 

Dicho esto, el cargo que tengas dentro de la empresa condiciona lo que debes saber para la migración o cómo ayudar en el proceso. Si eres un desarrollador, la perspectiva desde tu función será muy distinta de la de un arquitecto en la nube o un analista empresarial o financiero. Las diferentes funciones aportan enfoques diversos sobre la migración, y es recomendable aprovecharlos y asegurarnos de que todos vamos a la par. 

También debemos asegurarnos de contar con el talento adecuado para ayudar con migración, por lo que RR. HH. tendrá que contratar a tiempo para que la migración sea posible. Hay que tener mucho en cuenta, y alguien nuevo en la nube podría no tener presente todas las personas que deben participar en el proceso. 

El equipo de servicios profesionales de AWS ha creado algo llamado AWS Cloud Adoption Framework que puede guiarte a lo largo de este proceso. Este marco se ha creado para asesorar a tu empresa para que migre de forma rápida y fluida a AWS. 

Este marco se organiza en seis áreas centradas en las distintas funciones que toman parte activa en la migración, como las diferentes perspectivas de las que hemos hablado. Cada perspectiva abarca distintas responsabilidades de diferentes grupos. Estas son las de negocios, personal, y dirección, que se centran en las capacidades empresariales; y las perspectivas de plataforma, seguridad y operaciones, que se centran en la capacidad técnica. Un analista de negocios o finanzas entraría en la perspectiva de negocio; RR. HH. entraría en la de personal y un arquitecto en la nube entraría en la de plataforma. 

Cada perspectiva se usa para encontrar lagunas en las capacidades y procesos, que luego se registran como entradas. Estas entradas sirven como base para crear el plan de acción del AWS Cloud Adoption Framework, que se usa para guiar la gestión de cambios de su organización durante el cambio a la nube. Tener un plan de acción adecuado es útil para el proceso. 

Migrar a la nube puede ser complicado, pero no estás solo en esto, cuentas con innumerables recursos para empezar y este marco de adopción es el lugar ideal para consultarlos. 


/////////////////////////////////////////////////////////////////////
Seis perspectivas principales del AWS Cloud Adoption Framework

/////////////////////////////////////////////////////////////////////

En el nivel más alto, AWS Cloud Adoption Framework (AWS CAF) ofrece directrices sobre seis áreas de interés, denominadas perspectivas. Cada perspectiva aborda responsabilidades distintas. El proceso de planificación ayuda a las personas adecuadas de toda la organización a prepararse para los cambios que se avecinan.

En general, las perspectivas de negocio, personal y dirección se centran en las capacidades empresariales, mientras que las perspectivas de plataforma, seguridad y operaciones se centran en las capacidades técnicas.

Para obtener más información, selecciona el símbolo + que aparece junto a cada categoría.


///
Perspectiva de negocio
–
La perspectiva de negocio garantiza que las TI se alinean con las necesidades empresariales y que las inversiones en TI se vinculan a los resultados empresariales clave.

Utiliza la perspectiva de negocio para crear un caso empresarial sólido de adopción de la nube y prioriza las iniciativas de adopción. Asegúrate de que las estrategias y objetivos empresariales se alinean con los de TI.

En esta perspectiva es común encontrar los siguientes roles:

Gerentes de negocio.
Gerentes de finanzas.
Responsables de presupuestos.
Inversores estratégicos.


///
Perspectiva de personal
–
La perspectiva de personal apoya el desarrollo de una estrategia de administración de cambio en toda la organización para cambiar a la nube con éxito.

Utilza la perspectiva de personal para evaluar las estructuras y los roles organizativos, los nuevos requisitos de habilidades y procesos e identificar lagunas. Esto ayuda a priorizar la formación, la plantila y los cambios organizativos.

En esta perspectiva es común encontrar los siguientes roles:

Recursos humanos.
Personal de selección.
Gerentes de personal.


///
Perspectiva de dirección
–
La perspectiva de dirección se centra en las habilidades y los procesos para alinear la estrategia de TI con la estrategia empresarial. Esto garantiza que maximiza el valor empresarial y minimiza los riesgos.

Utiliza la perspectiva de dirección para comprender cómo actualizar las habilidades y los procesos del personal necesarios para garantizar la dirección empresarial en la nube. Administra y calcula las inversiones en la nube para evaluar los resultados empresariales.

En esta perspectiva es común encontrar los siguientes roles:

Chief Information Officer (CIO).
Gerentes de programas.
Enterprise Architects.
Analistas empresariales.
Gerentes de cartera.


///
Perspectiva de plataforma
–
La perspectiva de plataforma incluye principios y patrones para implementar nuevas soluciones en la nube y migrar cargas de trabajo de las instalaciones a la nube.

Utiliza diversos modelos arquitectónicos para comprender y comunicar la estructura de los sistemas de TI y sus relaciones. Describe detalladamente la arquitectura del entorno de estado de destino.

En esta perspectiva es común encontrar los siguientes roles:

Chief Technology Officer (CTO).
Gerentes de TI.
Arquitectos de soluciones.


///
Perspectiva de seguridad
–
La perspectiva de seguridad garantiza que la organización cumpla los objetivos de seguridad de visibilidad, auditabilidad, control y agilidad. 

Utiliza AWS CAF para estructurar la selección e implementación de controles de seguridad que satisfagan las necesidades de la organización.

En esta perspectiva es común encontrar los siguientes roles:

Director de seguridad de la Información (CISO).
Gerentes de seguridad de TI.
Analistas de seguridad de TI.


///
Perspectiva de operaciones
–
La perspectiva de operaciones ayuda a habilitar, lanzar, utilizar, operar y recuperar cargas de trabajo de TI al nivel acordado con los inversores del negocio.

Define cómo se llevan a cabo los negocios diarios, trimestrales y anuales. Alinea y ofrece soporte a las operaciones de la empresa. AWS CAF ayuda a estos inversores a definir los procedimientos operativos actuales e identificar los cambios en los procesos y la formación necesarios para implementar la adopción satisfactoria de la nube.

En esta perspectiva es común encontrar los siguientes roles:

Gerentes de operaciones de TI.
Gerentes de soporte de TI.


////////////////////////////////////////
Estrategias de migración
////////////////////////////////////////

Ha llegado el momento de migrar tu implementación local a AWS. Como dijo Morgan en el vídeo anterior, sería genial que, con solo chasquear los dedos, todos los elementos de tu centro de datos en las instalaciones pasaran mágicamente a AWS de forma optimizada y eficiente. Pero no es así.

Cada aplicación, o grupo de aplicaciones, si están correctamente asociadas, se puede migrar de 6 maneras posibles si es una migración empresarial. Son las 6 claves. Una vez que pases por la fase de descubrimiento y sepas exactamente qué elementos tiene tu entorno, podrás decidir cuál de las 6 claves te viene mejor según el tiempo, el precio, la prioridad y la importancia.

La primera opción es volver a alojar, también conocida como lift and shift. Es fácil para las empresas porque no conlleva ningún cambio. Al menos no al principio. Consiste en pasar las aplicaciones prácticamente tal cual a AWS. Así puede que desaprovechen beneficios. Sin embargo, algunas empresas han notado que, incluso sin optimizar, podrían ahorrar hasta un 30 % de sus costes totales con solo volver a alojar. Además, es más fácil optimizar las aplicaciones después, una vez que están en la nube, porque tu empresa estará más capacitada para hacerlo. La parte difícil, la migración, ya estará completa.

La segunda opción es el redefinir plataforma, o lift, tinker and shift. Es como el lift and shift, pero, en lugar solo migrar, se hacen algunas optimizaciones en la nube. Sin manipular ningún código básico. No conlleva nuevas tareas de desarrollo. Por ejemplo, podrías adaptar tu base de datos de My SQL pasándola a RDS mediante SQL sin tener que cambiar el código. También puedes considerar pasarte a Amazon Aurora. Hacerlo es muy beneficioso para tus equipos de DBA y mejora el rendimiento sin tener que tocar el código.

Antes de comentar más opciones, 2 de las 6 claves no acaban en AWS. La tercera es retirar. Hay partes de tu cartera de TI que ya no necesitas. Hemos descubierto que entre el 10 y el 20 % de las aplicaciones de las empresas o no se utilizan o ya tienen sustitutos activos y funcionales. Puedes aprovechar el plan de migración de AWS para dejar de usar esas aplicaciones y, así, ahorrar costes y esfuerzos importantes a tu personal. A veces es tan sencillo como eso.

La cuarta opción es retener. Puede que algunas aplicaciones estén a punto de quedar obsoletas, pero aún no. Aún es necesario usarlas durante 3 u 8 meses más. Podrían migrarse a AWS, pero, ¿para qué? Solo deberías migrar aquello que le conviene a tu negocio. Además, a medida que pasa el tiempo, es posible que se queden obsoletas y puedas, en última instancia, retirarlas. Vale, volvamos a lo que sí hay que migrar a AWS.

La quinta opción es volver a comprar. Es una opción popular entre las empresas que quieren dejar a sus proveedores de software y empezar de nuevo con la migración. Por ejemplo, finalizar un contrato con un antiguo proveedor de CRM y pasar a uno nuevo. O terminar definitivamente la licencia de una base de datos obsoleta y empezar a usar bases de datos nativas en la nube. Es una idea genial, pero recuerda que significa usar un nuevo paquete de software. Algunos son fáciles de implementar y otros requieren tiempo. Por lo tanto, el gasto inicial total del escalón aumenta, pero los beneficios potenciales podrían ser sustanciales.

La sexta opción es refactorizar. Consiste en escribir código nuevo. Es la opción adecuada para empresas que necesiten añadir características o rendimiento que podrían no ser viables en las instalaciones, pero que ahora están a su alcance. Los cambios drásticos de arquitectura pueden beneficiar mucho a tu empresa, pero supondrá un coste inicial más alto en términos de planificación y recursos humanos.

6 rutas para pasarse a AWS. Una vez que tengas el inventario de todas las partes, elegir la mejor opción para cada una será fundamental para migrar con éxito.


////////////////////////////////////////
Seis estrategias de migración
////////////////////////////////////////

Al migrar aplicaciones a la nube, seis de las estrategias de migración más comunes que puedes implementar son:

Volver a alojar.
Redefinir plataforma.
Refactorizar/rearquitectura.
Volver a comprar.
Retener.
Retirar.
Para más información, selecciona el símbolo + que aparece junto a cada categoría.

///
Volver a alojar
–
Volver a alojar, que también se conoce como lift and shift, implica mover aplicaciones sin realizar cambios.

En el caso de una migración heredada de gran envergadura en la que se busca implementar la migración y escalar rápidamente para satisfacer un caso empresarial, la mayoría de las aplicaciones se vuelven a alojar.


///
Redefinir plataforma
–
Redefinir plataforma, que también se conoce como lift, tinker and shift, implica realizar algunas optimizaciones en la nube para obtener un beneficio tangible.

La optimización se logra sin cambiar la arquitectura principal de la aplicación.


///
Refactorizar/rearquitectura
–
Refactorizar (o rearquitectura) implica volver a imaginar cómo se diseña y se desarrolla una aplicación a través del uso de funciones nativas en la nube. 

La estrategia de refactorizar viene dada por una fuerte necesidad empresarial de añadir características, escalabilidad o rendimiento que de otro modo sería difícil lograr en el entorno existente de la aplicación.


///
Volver a comprar
–
Volver a comprar implica pasar de una licencia tradicional a un modelo de software como servicio.

Por ejemplo, una empresa podría optar por implementar la estrategia de volver a comprar mediante la migración de un sistema de administración de relaciones con los clientes (CRM) a Salesforce.com.


///
Retener
–
Retener consiste en mantener las aplicaciones que son esenciales para el negocio en el entorno de origen. Esto puede incluir aplicaciones que requieren una refactorización importante antes de que se puedan migrar o trabajos que se pueden posponer para más adelante.


///
Retirar
–
Retirar es el proceso de eliminar aplicaciones que ya no son necesarias.



/////////////////////////////////////////////////////
Familia de productos AWS Snow
/////////////////////////////////////////////////////

Algunos de nuestros clientes necesitan traspasar datos a AWS y a la mayoría le gustaría hacerlo de manera eficiente y oportuna. Lo habitual es simplemente copiar los datos necesarios a través de Internet o, mejor aún, una línea Direct Connect, si tienen. Sin embargo, con las limitaciones del ancho de banda, puede tardar días, semanas o meses.

Por ejemplo, con una conexión de red dedicada de 1 gigabyte por segundo se transfiere 1 petabyte de datos en unos 100 días y, en el mundo real, probablemente tarde y cueste más. Por estos comentarios de clientes y para solucionar esta brecha, presentamos la familia de dispositivos AWS Snow.

El primero, que también es nuestra oferta más reciente, se llama AWS Snowcone, admite hasta 8 terabytes de datos y contiene computación en la frontera. Las opciones de esta computación son las instancias de Amazon EC2 y AWS IoT Greengrass. Puedes solicitarlo desde la AWS Management Console. Te lo enviamos, lo conectas, copia sus datos y, por último, nos lo devuelven. Nosotros copiamos los datos en tu cuenta de AWS, normalmente en tu S3 bucket, y, así, todo en su lugar: los datos quedan listos para su uso. Los clientes suelen usar estos dispositivos para enviar terabytes de información, como datos de análisis, bibliotecas de vídeo o imágenes, copias de seguridad y hasta datos de cintas de reemplazo. ¿Quién no tiene terabytes de imágenes de gatos de las que hacer copias de seguridad en la nube de AWS?

Pero, ¿y si 8 terabytes no bastan? No hay problema, tenemos un producto para esa necesidad llamado Snowball Edge. Se presenta en dos versiones: Snowball Edge Compute Optimized y Snowball Edge Storage Optimized. Lo mejor es que encajan en los racks de tus servidores y son agrupables en clústeres para atender mayores exigencias. Cuando los conectes a tu infraestructura, puedes utilizar funciones de AWS Lambda, AMI compatible con Amazon EC2, o incluso AWS IoT Greengrass para procesar datos fácil y rápido. Los clientes suelen enviarlos a ubicaciones remotas, donde es más complicado disponer de mucha potencia de computación. Se suelen usar para capturar secuencias de dispositivos IoT, comprimir imágenes, transcodificar vídeo y hasta para señalización industrial.

El último dispositivo disponible es el más grande de la flota, es el AWS Snowmobile y, como su nombre sugiere, está alojado en un contenedor resistente de casi 14 metros transportado por un camión. ¡Es gigantesco! Alberga 100 petabytes y es ideal para las migraciones más grandes, incluso como para cerrar un centro de datos. Se transporta hasta la ubicación designada, se conecta y aparece como un dispositivo de almacenamiento conectado a la red con una capacidad de hasta 100 petabytes. Es totalmente seguro, resistente al agua, tiene control de temperatura e incluso supresión de incendios y rastreo GPS. ¡Incluso tiene videovigilancia las 24 horas con un equipo de seguridad exclusivo y un vehículo de seguridad escolta durante el transporte! Es increíble.

Además, todos los dispositivos Snow son totalmente seguros tanto en las instalaciones como durante su transporte. El hardware y el software tienen firma criptográfica y todos los datos almacenados se cifran automáticamente mediante claves de 256 bits que tú mismo administrarás y tendrás en posesión. Incluso se puede usar AWS Key Management Service para generar y gestionar claves.

Como siempre, ha sido un placer presentarte un servicio más de AWS. Espero que te haya gustado este episodio de la familia AWS Snow.


////////////////////////////////////
Miembros de la familia de productos AWS Snow

La familia de productos AWS Snow es un conjunto de dispositivos físicos que ayudan a transportar físicamente hasta exabytes de datos tanto dentro de AWS como fuera. 

La familia de productos AWS Snow está compuesta por AWS Snowcone, AWS Snowball y AWS Snowmobile.

Estos dispositivos ofrecen diferentes niveles de capacidad y la mayoría incluyen capacidades de computación integradas. AWS posee y administra los dispositivos de la familia de productos Snow y se integra con la seguridad, el seguimiento, la administración del almacenamiento y las capacidades de computación de AWS.  

Para más información sobre cada categoría, selecciona la pestaña correspondiente.


///
AWS Snowcone:

AWS Snowcone es un dispositivo de transferencia de datos y computación perimetral pequeño, robusto y seguro. 
Cuenta con 2 CPU, 4 GB de memoria y 8 TB de almacenamiento utilizable.


///
AWS Snowball:

AWS Snowball ofrece dos tipos de dispositivos:

Snowball Edge Storage Optimized, adecuado para migraciones de datos a gran escala y flujos de trabajo de transferencias recurrentes, además de la computación local con mayores necesidades de capacidad. 
Almacenamiento: 80 TB de capacidad de unidad de disco duro (HDD) para volúmenes de bloques y almacenamiento de objetos compatible con Amazon S3, y 1 TB de unidad de estado sólido (SSD) SATA para volúmenes de bloque. 
Computación: 40 vCPU y 80 GiB de memoria para admitir instancias sbe1 de Amazon EC2 (equivalente a C5).
Snowball Edge Compute Optimized, que proporciona potentes recursos de computación para casos prácticos como machine learning, análisis de vídeo de movimiento completo, análisis y pilas de computación locales. 
Almacenamiento: capacidad de unidad de disco duro utilizable de 42 TB para almacenamiento de objetos compatible con Amazon S3 o volúmenes de bloques compatibles con Amazon EBS y 7,68 TB de capacidad SSD NVMe utilizable para volúmenes de bloques compatibles con Amazon EBS. 
Computación: 52 vCPU, 208 GiB de memoria y una GPU NVIDIA Tesla V100 opcional. Los dispositivos ejecutan instancias sbe-c y sbe-g de Amazon EC2, que son equivalentes a las instancias C5, M5a, G3 y P3.



///
AWS Snowmobile:

AWS Snowmobile es un servicio de transferencia de datos a escala de exabytes que se utiliza para transferir grandes cantidades de datos a AWS. 

Puede transferir hasta 100 petabytes de datos por cada Snowmobile, un contenedor de transporte resistente de casi 14 metros de largo, arrastrado por un camión semirremolque.



////////////////////////////////////////////////////////
Innovar en AWS
////////////////////////////////////////////////////////

AWS ofrece muchas más opciones de las que tenemos tiempo de mencionar. Por ejemplo, cuando hablamos de migrar a AWS, ni siquiera hablamos de VMware en AWS. La misma infraestructura basada en VMware que se usa localmente puede, en muchos casos, trasladarse a AWS a través de VMware Cloud en AWS. Este es solo uno de los muchos servicios que convierten a AWS en un lugar donde se puede crear e innovar al ritmo de tus ideas.

En cuanto a machine learning e inteligencia artificial, AWS tiene el conjunto más amplio y minucioso de servicios para tus empresas. Puedes elegir entre servicios de IA preentrenados para visión artificial, recomendaciones lingüísticas y pronósticos. Con Amazon SageMaker puedes crear, entrenar e implementar modelos de machine learning a escala, o crear modelos compatibles con todos los marcos de código abierto populares.
Nuestras capacidades se basan en la plataforma en la nube más completa, optimizada para machine learning, con computación de alto rendimiento y que no escatima en seguridad y análisis. Herramientas como Amazon SageMaker y Amazon Augmented AI (Amazon A2I) ofrecen una plataforma de machine learning que cualquier empresa puede usar sin necesidad de contar con un experto en plantilla. O tal vez soluciones de IA listas para su uso como Amazon Lex, el corazón de Alexa.


[Alexa] Hola, Blaine. ¿En qué te puedo ayudar?

…que ayuda a crear bots de chat.

O, por ejemplo, Amazon Textract, que extrae texto y datos de documentos para que sean más útiles para tu empresa en lugar de que se queden guardados en un repositorio.

¿Quieres poner machine learning a disposición de tus desarrolladores? ¿Por qué no probar AWS DeepRacer? Permite a tus desarrolladores probar el aprendizaje por refuerzo, una de las ramas más recientes de algoritmos de machine learning, todo mientras se divierten en un entorno de carreras.

AWS ofrece tecnologías nuevas en, por ejemplo, el Internet de las cosas. Permite a dispositivos conectados comunicarse en todo el mundo.

Hablando de comunicación en todo el mundo, ¿alguna vez has querido tener tu propio satélite? ¿Es muy caro? Puedes usar AWS Ground Station y pagar solo por el tiempo satelital que realmente necesitas.

Podría pasar días hablando de estas nuevas tecnologías. Literalmente días. AWS Training and Certification ofrece clases de formación sobre muchas de estas tecnologías y, cada mes, AWS parece publicar algo aún mejor de lo que hablar.


/////////////
Innovar con los servicios de AWS

Al examinar cómo utilizar los servicios de AWS, es importante centrarse en los resultados deseados. Estás bien equipado para impulsar la innovación en la nube si puedes combinar claramente las siguientes condiciones:

El estado actual.
El estado deseado.
Los problemas que intentas resolver.
Tienes en cuenta algunos de los caminos que podrías explorar en el futuro mientras continúas tu cambio a la nube. 

Para más información, selecciona el símbolo + que aparece junto a cada categoría.


///////////////
Aplicaciones sin servidor
–
En AWS, sin servidor hace referencia a aplicaciones que no requieren que aprovisiones, mantengas ni administres servidores. No tienes que preocuparte por la tolerancia a errores ni por la disponibilidad. AWS se encarga de estas capacidades por ti.


AWS Lambda es un ejemplo de servicio que permite utilizar aplicaciones sin servidor. Si diseñas la arquitectura para activar las funciones de Lambda para lanzar el código, puedes evitar la necesidad de administrar una flota de servidores.


La creación de arquitectura con aplicaciones sin servidor permite a los desarrolladores centrarse en el producto principal en lugar de administrar y operar servidores.


///////////////////
Inteligencia artificial
–
AWS ofrece diversos servicios impulsados por inteligencia artificial (IA). 

Por ejemplo, puedes realizar las siguientes tareas:

Convertir voz en texto con Amazon Transcribe.
Descubrir patrones en texto con Amazon Comprehend.
Identificar actividades en línea potencialmente fraudulentas con Amazon Fraud Detector.
Crear chatbots de voz y texto con Amazon Lex.



////////////////////
Machine learning
//////////////////
–
El desarrollo tradicional de machine learning (ML) es complejo, costoso, lento y propenso a errores. AWS ofrece Amazon SageMaker para eliminar el trabajo difícil del proceso y permite crear, entrenar e implementar modelos de ML rápidamente.

Se puede utilizar ML para analizar datos, resolver problemas complejos y predecir resultados antes de que ocurran.



//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 10
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Resumir los cinco pilares del marco de referencia Well-Architected.  
Explicar los seis beneficios de la informática en la nube.


////////////////////////////////////////////////
El marco de referencia AWS Well-Architected

////////////////////////////////////////////////

El marco Well-Architected está diseñado para que arquitectos, desarrolladores y usuarios de AWS creen infraestructuras seguras, de alto rendimiento, resilientes y eficientes para aplicaciones. Se compone de 5 pilares para garantizar una revisión y un diseño coherentes de arquitecturas. 

El primer pilar es la excelencia operativa. Se centra en el funcionamiento y la supervisión de sistemas para ofrecer valor empresarial y, con ello, mejorar continuamente los procesos y procedimientos. Por ejemplo, automatizar cambios con canalizaciones de implementación o responder a eventos que se desencadenan. 

El segundo es la seguridad. Como sabes, la seguridad es la máxima prioridad de AWS. Este pilar lo lleva a la práctica revisando la integridad de los datos y, por ejemplo, protegiendo sistemas mediante cifrado. 

El tercero es la fiabilidad. Se centra en planes de recuperación, como recuperación de interrupciones de DynamoDB. O de fallos del nodo EC2, en cómo gestionan los cambios para atender las necesidades de empresas y clientes. 

El cuarto es la eficiencia del rendimiento, que implica el uso eficiente de los recursos informáticos. Por ejemplo, usar el Amazon EC2 adecuado a la carga de trabajo y la memoria necesaria para tomar decisiones fundamentadas para mantener una eficiencia ajustada a las necesidades.  

Por último, la optimización de costes, que busca optimizar el coste total, controlar en qué se gasta el dinero y, por ejemplo, comprobar si has sobreestimado el tamaño del servidor EC2. Así podrás reducir costes eligiendo un tamaño más rentable. 

Antes, se evaluaba en función de la infraestructura de AWS con ayuda de un arquitecto de soluciones. Se puede hacer así y te animamos a hacerlo, pero, atendiendo a sugerencias, decidimos lanzar el marco como una herramienta de autoservicio: Well-Architected Tool. Puedes acceder a ella desde la AWS Management Console, crear una carga de trabajo y lanzarla en tu cuenta de AWS para generar un informe que muestre las áreas que abordar. Es como un sistema de semáforo. El verde avisa cuando todo funciona correctamente. El naranja avisa que probablemente debería investigarse algo porque hay margen de mejora, y el rojo advierte que debe revisarse algo porque hay un riesgo. Son áreas en las que la herramienta ha detectado posibles problemas y te presenta un plan para solucionarlo aplicando las prácticas recomendadas establecidas. Ten en cuenta que puedes anular esta configuración cuando quieras si las preguntas no se aplican a tu caso. Es muy personalizable. Un inciso interesante: de donde vengo, Sudáfrica, llamamos robots a los semáforos. 

Si accedemos a la herramienta, veremos algo similar a la siguiente captura de pantalla. Ponemos nombre a la carga de trabajo y aparece en la sección 1. En la sección 2 se ven los pilares y los menús desplegables de las preguntas de cada uno. La sección 3 muestra las preguntas en sí. La 4 es el pilar y la raíz de la pregunta. La 5 contiene antecedentes y la recomendación. La 6 es la respuesta que dan con un conmutador para indicar si la pregunta es aplicable o no. Esto es importante, ya que afecta a la puntuación general. Y no olvidemos la sección 7, donde se presentan vídeos cortos que explican cómo responder a una pregunta en particular. 

Esto ha sido todo sobre el marco Well-Architected y el servicio Well-Architeted Tool. Espero que hayas disfrutado aprendiendo a evaluar las cargas de trabajo. 


///
El marco de referencia AWS Well-Architected

El marco de referencia AWS Well-Architected ayuda a comprender cómo diseñar y operar sistemas fiables, seguros, eficientes y rentables en la nube de AWS. Te proporciona una forma de medir sistemáticamente la arquitectura en función de las prácticas recomendadas y los principios de diseño e identificar áreas de mejora.

//
El marco Well-Architected se basa en cinco pilares:

Excelencia operativa.
Seguridad.
Fiabilidad.
Eficiencia de rendimiento.
Optimización de precios.
Para más información, selecciona el símbolo + que aparece junto a cada categoría.


/////////
Excelencia operativa
–
La excelencia operativa es la capacidad de utilizar y supervisar sistemas para ofrecer valor empresarial y mejorar continuamente los procesos y procedimientos de soporte.  

Los principios de diseño para la excelencia operativa en la nube incluyen realizar operaciones como crear código, anotar documentación, anticipar errores y realizar cambios pequeños y reversibles con frecuencia.


////////////
Seguridad
–
El pilar de seguridad es la capacidad de proteger la información, los sistemas y los activos y, al mismo tiempo, ofrecer valor empresarial mediante evaluaciones de riesgos y estrategias de mitigación. 

Al considerar la seguridad de tu arquitectura, aplica las siguientes prácticas recomendadas:

Automatiza las prácticas recomendadas de seguridad siempre que sea posible.
Aplica seguridad en todas las capas.
Protege los datos en tránsito y en reposo.


/////////////////
Fiabilidad
–
La fiabilidad es la capacidad de un sistema para hacer lo siguiente:

Recuperarse de las interrupciones de la infraestructura o del servicio.
Adquirir recursos informáticos de forma dinámica para satisfacer la demanda.
Mitigar interrupciones como configuraciones erróneas o problemas transitorios de red.
El pilar de fiabilidad implica pruebas de procedimientos de recuperación, escalado horizontal para aumentar la disponibilidad agregada del sistema y recuperación automática ante errores.



/////////////////
Eficiencia de rendimiento
–
La eficiencia de rendimiento es la capacidad de utilizar los recursos de computación de forma eficiente para satisfacer los requisitos del sistema y mantener esa eficiencia a medida que la demanda cambia y evoluciona la tecnología. 

La evaluación de la eficiencia de rendimiento de la arquitectura incluye experimentar con más frecuencia, utilizar arquitecturas sin servidor y diseñar sistemas para poder globalizarse en cuestión de minutos.


/////////////////
Optimización de precios
–
La optimización de precios es la capacidad de utilizar sistemas para ofrecer valor empresarial al precio más bajo.

La optimización de precios incluye la adopción de un modelo de consumo, el análisis y la atribución de inversiones y el uso de Managed Services para reducir el coste de propiedad.


/////////////////////////////////

Beneficios de la nube de AWS
/////////////////////////////////

Bien, ahora ya sabes todo lo necesario sobre AWS, estás en condiciones de crear tu imperio, ¿no? Aunque no sea del todo cierto, ahora deberías comprender bien muchos de los diferentes servicios que AWS tiene para ofrecer y cómo puedes combinarlos como bloques de construcción para crear soluciones flexibles, escalables y fiables en tu empresa. También conoces parte de los términos de AWS. Conocerlos es importante para avanzar en el cambio a la nube. Ahora, cuando leas el blog o documentación de AWS, seguro conocerás muchos de los acrónimos y frases. Algo más que tener en cuenta a medida que avanzas son los seis principales beneficios de usar la nube de AWS. Comenzarás a sopesar qué aplicaciones y soluciones crearás en la nube, y conocer estos beneficios puede ayudar a tomar esas decisiones de manera informada. Empecemos con el primero. 

Esto es muy importante recordarlo. Crear centros de datos tradicionales en instalaciones requiere invertir mucho dinero por adelantado solo para empezar. Necesitas invertir dinero en el espacio físico real del centro de datos, en todo el hardware, en el personal para almacenar y apilar ese hardware y en costes generales para que el centro de datos funcione. Para una empresa mediana o grande, puede suponer cientos de miles o millones de dólares. Luego, independientemente del uso de ese centro de datos, este conlleva un coste fijo que hay que incluir en el presupuesto. Facturar con AWS no tiene nada que ver con ese modelo tradicional que he explicado. Tus facturas en AWS variarán mes a mes, dependiendo de si consumes más o menos recursos. La ventaja es que, si estás empezando, no tienes que invertir un millón de dólares en tu entorno de AWS. Puedes empezar poco a poco, recibir facturas solo por lo que usas y, a medida que uses más recursos, la factura fluctuará con ese crecimiento. Ahora, si tu factura se sale del presupuesto asignado, puedes ahorrar dinero desactivando instancias que no uses, eliminando recursos antiguos en desuso y optimizando las aplicaciones con herramientas como AWS Trusted Advisor para encontrar oportunidades de ahorro. Que la factura haya sido alta un mes no significa que no puedas reducirla el mes siguiente. Eso no ocurre con la facturación de centros de datos en las instalaciones. Es la primera ventaja. 

La siguiente es aprovechar enormes economías de escala. Es sencillo. AWS desarrolla continuamente una capacidad gigante en todo el mundo, y para crear todos esos centros de datos, AWS compra enormes cantidades de hardware. AWS también es experto creando centros de datos eficientes. Compramos hardware a un menor precio debido al enorme volumen, y luego lo instalamos y operamos de manera eficiente. Debido a estos factores, el coste variable puede ser menor que si operas un centro de datos por tu cuenta. 

La siguiente ventaja es no tener que adivinar la capacidad. Para crear un centro de datos tradicional hay que estimar la capacidad que necesitará la empresa. Supongamos que calculas que la cantidad de usuarios será de 10 millones de personas en los próximos 3 años. Así que compras hardware para responder a ese crecimiento y luego (suspira) resulta que solo tienes unos 500 000 usuarios, mucho menos de lo esperado. ¿Y ahora? Ya has pagado ese coste y tienes ese hardware para 10 millones de usuarios. Sobreestimaste la capacidad. 

La otra cara de la moneda es que estimes una capacidad demasiado baja y tengan que ingeniártelas para aumentar la capacidad del centro de datos antes de que los clientes tengan una mala experiencia o los pierdas. Eso lleva tiempo y lo más probable es que no actúes a tiempo, o tengas que hacer un gran esfuerzo para lograrlo. Estimar la capacidad por adelantado puede ser problemático si calculas por encima o por debajo. Con AWS, no hace falta calcular la capacidad. Simplemente aprovisionas los recursos que necesitas ahora y usas los mecanismos de escalado de cada recurso para escalarlos vertical u horizontalmente según tus necesidades diarias. Esto lleva minutos con AWS en lugar de semanas o meses, como con recursos en las instalaciones. El siguiente es mi beneficio favorito. 

Aumentar la velocidad y la agilidad. Con AWS, es fácil probar cosas nuevas. Puedes crear entornos de prueba y experimentar nuevas formas de solucionar problemas. Y si esas soluciones no funcionan, puedes eliminar esos recursos y dejar de generar costes. Los centros de datos tradicionales no ofrecen la misma flexibilidad. Si quieres hacer un experimento, tendrás que comprar e instalar más servidores, y, si falla el experimento, será caro porque ya has comprado el servidor. La flexibilidad de AWS ayuda a impulsar la innovación y facilita el aprovisionamiento de recursos. Crear una base de datos local podría llevar semanas; en AWS, minutos. Como puedes disponer rápido de los recursos que necesitas, puedes llegar al mercado más rápido. Seguimos. 

Cero inversión en operar y mantener de centros de datos. Si la empresa no es de centros de datos, ¿por qué gastar tanto dinero y tiempo en ellos? Deja que AWS se encargue del trabajo pesado y céntrate en lo que aporta valor a tus empresas. ¿Qué hace que tu negocio sea mejor que el de la competencia? AWS permite que te centres en encontrar la respuesta y en ofrecer a tus clientes soluciones innovadoras, en lugar de tener que encargarte del hardware de un centro de datos. Y, por último, pero no menos importante. 

Globalizar tu empresa en minutos. Imaginemos que una empresa en EE. UU. quiere ampliar sus operaciones a Alemania. Tiene centros de datos en EE. UU. que atienden a esta región, pero necesitará otros en Alemania para atender a esa nueva región. Lo normal sería contar con personal en Alemania que gestionara y operara ese centro de datos. Con AWS, se puede replicar la arquitectura en una región de Alemania. Y, si está bien configurada, se puede hacer de modo automatizado con medios como AWS CloudFormation. El tiempo que suele llevar expandirse a una zona secundaria del mundo puede ser de meses o años. Con AWS, solo lleva unos minutos. (Suspiro) 

Eso es todo. Esas son las seis ventajas principales de usar AWS. 

De parte del equipo de AWS, enhorabuena por haber completado el curso AWS Cloud Practitioner Essentials for Business. Si quieres profundizar aún más, consulta nuestra oferta de cursos para seguir aprendiendo sobre los productos y servicios de AWS. 

Te deseamos mucha suerte en tu cambio a la nube. 


///
Beneficios de la informática en la nube

Operar en la nube de AWS ofrece muchas ventajas sobre la informática en entornos en instalaciones o híbridos. 

En esta sección conocerás seis ventajas de la informática en la nube:

Pasar de gasto inicial a gasto variable.
Aprovechar las economías de escala masiva.
Sin calcular capacidades.
Aumentar la velocidad y la agilidad.
Cero dinero invertido en operar y mantener los centros de datos.
Globalizarse en minutos.
Para más información, selecciona el símbolo + que aparece junto a cada categoría.


///
Pasar de gasto inicial a gasto variable
–
Los gastos iniciales incluyen centros de datos, servidores físicos y otros recursos en los que tendrías que invertir antes de utilizar los recursos informáticos. 

En lugar de invertir mucho en centros de datos y servidores antes de saber cómo los vas a utilizar, puedes pagar solo cuando consumas los recursos informáticos.


///
Aprovechar las enormes economías de escala
–
Al utilizar la informática en la nube, puedes lograr un coste variable inferior al que obtendrías por ti mismo. 

Debido a que el uso de cientos de miles de clientes se agrega en la nube, proveedores como AWS pueden conseguir mayores economías de escala. Las economías de escala se traducen en precios de pago por uso más bajos.


///
Sin calcular capacidades
–
Con la informática en la nube, no tienes que predecir cuánta capacidad de infraestructura necesitarás antes de implementar una aplicación.

Por ejemplo, puedes lanzar instancias de Amazon Elastic Compute Cloud (Amazon EC2) cuando sea necesario y pagar solo por el tiempo de computación que utilizas. En lugar de pagar por recursos que no se utilizan o de capacidad limitada, solo puedes acceder a la capacidad que necesitas y realizar una escala vertical u horizontal en respuesta a la demanda.


///
Aumentar la velocidad y la agilidad
–
La flexibilidad de la informática en la nube facilita el desarrollo y la implementación de aplicaciones.  Esta flexibilidad también proporciona a tus equipos de desarrollo más tiempo para experimentar e innovar.


///
Cero inversión en funcionamiento y mantenimiento de centros de datos
–
La informática en la nube en los centros de datos suele requerir que inviertas más dinero y tiempo en administrar la infraestructura y los servidores. Un beneficio de la informática en la nube es la capacidad de centrarte menos en estas tareas y mucho más en tus aplicaciones y clientes.


///
Globalizarse en minutos
–
La presencia global de la nube de AWS te permite implementar aplicaciones rápidamente para clientes de todo el mundo, a la vez que les proporciona una baja latencia.

////////////////////////

Resumen del módulo 10
En el módulo 10 se han tratado los siguientes conceptos:

Los cinco pilares de AWS Well-Architected Framework:
Excelencia operativa.
Seguridad.
Fiabilidad.
Rendimiento eficiente.
Optimización de costes.
Seis ventajas de la informática en la nube:
Pasar de gasto inicial a gasto variable.
Aprovechar las economías de escala masiva.
Sin calcular capacidades.
Aumentar la velocidad y la agilidad.
Cero inversión en el funcionamiento y mantenimiento de centros de datos.
Globalizarse en minutos.
Recursos adicionales

Para más información sobre los conceptos que se han tratado en el módulo 10, revisa estos recursos.

AWS Well-Architected.
Documento técnico: AWS Well-Architected Framework.
Centro de arquitectura de AWS.
Seis beneficios de la informática en la nube.
Blog de arquitectura de AWS.




//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Introducción al módulo 11
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Objetivos de aprendizaje

En este módulo aprenderás lo siguiente:

Determinar los recursos para prepararse para el examen de AWS Certified Cloud Practitioner.
Describir los beneficios de obtener la certificación AWS Certified.


///
Dominios del examen

El examen de AWS Certified Cloud Practitioner incluye cuatro dominios:

1

1
Conceptos de la nube.

2

2
Seguridad y conformidad.

3

3
Tecnología.

4

4
Facturación y precios.

Las áreas tratadas describen cada dominio de la guía del examen para la certificación AWS Certified Cloud Practitioner. Para obtener una descripción de cada dominio, consulta el sitio web de AWS Certified Cloud Practitioner. Te animamos a leer la información de la guía del examen como parte de la preparación.

Cada dominio del examen está ponderado. La ponderación representa el porcentaje de preguntas del examen que corresponden a ese dominio en particular. Se trata de aproximaciones, por lo que es posible que las preguntas del examen no coincidan exactamente con estos porcentajes. El examen no indica el dominio asociado a una pregunta. De hecho, algunas preguntas pueden caer en varios dominios.

Dominio	Porcentaje del examen
Dominio 1: Conceptos de nube	26 %
Dominio 2: Seguridad y compilación	25 %
Dominio 3: Tecnología	33 %
Dominio 4: Facturación y precios	16 %
Total	100 %

Te recomendamos que utilices estos puntos de referencia como guía para determinar cómo gestionar el tiempo de estudio de cara al examen.

Experiencia recomendada

Los candidatos al examen de AWS Certified Cloud Practitioner deben tener una comprensión básica de los servicios de TI y sus usos en la plataforma de la nube de AWS. 

Te recomendamos que tengas al menos seis meses de experiencia en la nube de AWS en cualquier función, incluidos los gestores de proyectos, los gestores de TI, los gestores de ventas, los responsables de la toma de decisiones y los especialistas en marketing. Estas funciones se suman a las correspondientes de los departamentos de finanzas, adquisición y legal.

Detalles del examen

El examen de AWS Certified Cloud Practitioner consta de 65 preguntas que se deben completar en 90 minutos. La puntuación mínima para aprobar es del 70 %.

En el examen se incluyen dos tipos de preguntas: de opción múltiple y de múltiples respuestas.

Una pregunta de opción múltiple tiene una respuesta correcta y tres respuestas incorrectas o distractoras.
Una pregunta de múltiples respuestas tiene dos o más respuestas correctas de entre cinco o más opciones.
En el examen, no hay penalización por intentar acertar. Las preguntas que no se responden se califican como incorrectas. Si no tienes certeza de cuál es la respuesta correcta, siempre es mejor que seguir tu intuición en vez de dejar preguntas sin responder.

El examen permite marcar cualquier pregunta para revisarla antes de enviar el examen. Esto te ayuda a utilizar el tiempo de manera eficiente, sabiendo que siempre puedes volver atrás y comprobar cualquier pregunta sobre la que tuvieras dudas.

Documentos técnicos y recursos

Como parte de la preparación para el examen de AWS Certified Cloud Practitioner, te recomendamos revisar los siguientes documentos técnicos y recursos:

Información general sobre Amazon Web Services.
Cómo funcionan los precios de AWS.
Comparar los planes de AWS Support.

